{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname('spritelu/'))\n",
    "from spriteworld import environment, renderers, sprite, tasks, action_spaces\n",
    "from spriteworld import factor_distributions as distribs, sprite_generators, gym_wrapper as gymw\n",
    "import matplotlib.pyplot as plt, copy, numpy as np, os\n",
    "import multiprocessing as mp\n",
    "import math\n",
    "%matplotlib inline\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "def viz(obs):\n",
    "  plt.figure(figsize=(2,2))\n",
    "  plt.imshow(255 - obs)\n",
    "  \n",
    "  \n",
    "def anim(env, T=100):\n",
    "  fig = plt.figure(figsize=(2,2))\n",
    "  \n",
    "  states = [255 - env.reset()['image']]\n",
    "  \n",
    "  for i in range(T):\n",
    "    a = env.action_space.sample()\n",
    "    state, _, _, _ = env.step(a)\n",
    "    states.append(255 - state['image'])\n",
    "  \n",
    "  im = plt.imshow(states[0], cmap=plt.get_cmap('jet'), vmin=0, vmax=255)\n",
    "  \n",
    "  def updatefig(j):\n",
    "    im.set_array(states[j])\n",
    "    return [im]\n",
    "  \n",
    "  ani = animation.FuncAnimation(fig, updatefig, frames=T, interval=75, repeat_delay=1000)\n",
    "  return ani.to_html5_video()\n",
    "\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SPRITES = 4\n",
    "IMAGEDIM = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = distribs.Product([\n",
    "    distribs.Continuous('x', 0.05, 0.95),\n",
    "    distribs.Continuous('y', 0.05, 0.95),\n",
    "    distribs.Continuous('c0', 25, 230),\n",
    "    distribs.Continuous('c1', 25, 230),\n",
    "    distribs.Continuous('c2', 25, 230),\n",
    "    distribs.Continuous('x_vel', -0.08, 0.08),\n",
    "    distribs.Continuous('y_vel', -0.08, 0.08),\n",
    "    distribs.Discrete('shape', ['square']),\n",
    "    distribs.Discrete('move_noise', [0.]),\n",
    "    distribs.Discrete('scale', [0.15]),\n",
    "  ])\n",
    "\n",
    "sprite_gen = sprite_generators.generate_nonintersecting_sprites(factors, num_sprites=NUM_SPRITES)\n",
    "sprite_gen = sprite_generators.sort_by_color(sprite_gen)\n",
    "\n",
    "# Above code produces random colors but has sensible ordering. \n",
    "# Below line forces fixed colors (bad for generalization, but presumably easier to learn from images)\n",
    "\n",
    "sprite_gen = sprite_generators.fix_colors(sprite_gen, [(250, 125, 0), (0, 255, 125), (125, 0, 255), (255, 255, 255)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<spriteworld.sprite.Sprite at 0x7f321c16d278>,\n",
       " <spriteworld.sprite.Sprite at 0x7f321c16d438>,\n",
       " <spriteworld.sprite.Sprite at 0x7f321c16d160>,\n",
       " <spriteworld.sprite.Sprite at 0x7f321c16d358>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sprite_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_mtx = (np.random.rand(100, 100) - 0.5)*2.\n",
    "fn=lambda a: np.dot(random_mtx[:len(a),:len(a)], a)\n",
    "\n",
    "# WARNING: Because this uses velocity, using images makes it a POMDP! \n",
    "\n",
    "rndrs = {\n",
    "      'image': renderers.PILRenderer(image_size=(IMAGEDIM, IMAGEDIM), anti_aliasing=16),\n",
    "      'disentangled': renderers.VectorizedPositionsAndVelocities(),\n",
    "      'entangled': renderers.FunctionOfVectorizedPositionsAndVelocities(fn=fn),\n",
    "      'mask': renderers.TransitionEntanglementMask(state_size=4, action_size=2),\n",
    "      'mask_abstract': renderers.TransitionEntanglementMask(state_size=1, action_size=1)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'task': tasks.NoReward(),\n",
    "    'action_space': action_spaces.SelectBounce(),\n",
    "    'renderers': rndrs,\n",
    "    'init_sprites': sprite_gen,\n",
    "    'max_episode_length': 5000,\n",
    "    'metadata': {\n",
    "        'name': 'test', #os.path.basename(__file__),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = environment.Environment(**config)\n",
    "env = gymw.GymWrapper(env)\n",
    "viz(env.reset()['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4119256 ,  0.40516937, -0.01353608, -0.05582516],\n",
       "       [ 0.5529326 ,  0.60348064,  0.06707753, -0.0617921 ],\n",
       "       [ 0.7638458 ,  0.14143628,  0.04331376, -0.0521451 ],\n",
       "       [ 0.860783  ,  0.38110185,  0.05638252,  0.00407022]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()['disentangled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.89707252,  1.05041436, -1.22459461,  1.09263102, -1.46214   ,\n",
       "        0.34873547,  0.27287355,  1.22302865,  1.78601896, -0.5042925 ,\n",
       "        0.31635387,  0.10318463,  2.09582231,  1.03031006,  2.21032454,\n",
       "       -0.15425789])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()['entangled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 18)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.step(env.action_space.sample())[0]['mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.step(env.action_space.sample())[0]['mask_abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786 out of 1000 transitions were disentangled\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import block_diag\n",
    "state_block = np.ones((4,4))\n",
    "a = block_diag(*([state_block] * NUM_SPRITES + [np.zeros((2,2))]))\n",
    "\n",
    "total = 0\n",
    "for _ in range(10):\n",
    "  env.reset()\n",
    "  for i in range(100):\n",
    "    if np.all(a == env.step(env.action_space.sample())[0]['mask']):\n",
    "      total +=1\n",
    "\n",
    "print(total, 'out of 1000 transitions were disentangled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"144\" height=\"144\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAEaeW1kYXQAAAKuBgX//6rcRem9\n",
       "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTUyIHIyODU0IGU5YTU5MDMgLSBILjI2NC9NUEVHLTQg\n",
       "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
       "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
       "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
       "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
       "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9NCBsb29r\n",
       "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
       "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
       "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
       "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MTMgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
       "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
       "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAUlZYiE\n",
       "ABD//veBvzLLXyK6yXH5530srM885F0UrNHIYqkIBpEhl87PlFG9RpNLuVNksOKiJueJL8TofrUb\n",
       "HvMU5caaNL7ae2XPi3WErWliLcIRbek910bqLHf2BkIP16TH3lzWejnJ2U/i3qwoS4eW39qPutqv\n",
       "ZxjzeLyGsOTKNl2qKBQ4UfvgOua6poTpwpaMSlB7JiNDnJRC7nAvpHRxHfjx9hyvQDkM4mso24Z3\n",
       "bvqGeb0QEyAMsAeRg201IiwqCcNxkW6aRWzAgcQOUSflwGAXjT2cAG8J2ZWxc7R4Uobis13t3g9w\n",
       "LQzHHWPPKhoK5ziI11ROXum8ANan8bysNxLmylcLVE0JyvtsqiZGcyNkvT1zYVFXc9Twu7vQ+AjI\n",
       "jX0i0mEuWBCuW5IkfN+O0ELUTQ7i6lXxAsb+5HG3To6ucIU6I9xdhS3DV/sGviifKFN+ETdtKSqL\n",
       "jtv2yvSXJ8Ggj8w0tDNZxUJfCYGg/cSmJi3VWMQMdW1s9PaQLpGrG7TVs7HbfzVkmqMWO5E/Zy0p\n",
       "/bA12ejHrpzHfFO4xI0TakqVuJvWOfp50FrFmiUR/1wnR0d+xNP1LSXcX9kCAhC0twexJTGqxiV+\n",
       "AJcsFw47Vxv2Ww/NzpTVIxDgHkkBp5VwvI6nHDqqQZX+vR6sCANQRyd6UqREteHSE1DS9CA9jFTf\n",
       "sP2WN82gMxvHPhheDFaf8UoV/uCenau7M1n2EdW4qZOxfsghh3/rpdGabCi7zJUuUCEgYfItnvSH\n",
       "44e0j0SNmh5ioepd74M/m4ln4obJ8qtfeLtqlVM0mLyCTNWX/3Cojn+Sv2e28pk41SgONiuLanp7\n",
       "RGYz5GLY3n6+m/wjSjCfU3Sh2qj8oj8svlQcK9uPvgI+jtHmkt7S77z4YuX0rFCbb/DyptlTFHTL\n",
       "X6f5fOxqUKT5vG3TTOYDK5TmqT6AkR6aTEq/+u84nhwO9/x8eAwLD7qmXpPHR0A2G8WClL/Tz24Q\n",
       "38DDhP07BQk8gHinbg2DoQTmGlHc3D1bInOWNd3AlhhG5dubX7vJF9MgxH9Hjj6TabeEEwYJR69g\n",
       "kVh3leGid0PXz5d1Pcl9ykCm6ltzC/rOVi2gBe0ssxizVquIMt2JqrPxMXeZQJz+DSH2GojdoIF1\n",
       "4+U3V+iVUIrwmnIJKU00dJBejUcHVyQiHIKt8tEznTgQIwWfouzKKHkFIV6sxeV+QtKWiYaxUMVU\n",
       "QL0sIL9ygU9BQLv+xrzd80NNb9F+mu7/zZFW6GJBJd9eqpdP8vy+RcCNigxT4G9RMYfv26gHUo2N\n",
       "0YJ2+eaQbswEmj88HXnF/jiHAUFn2QvlUVNJQay2wFf8Cb7lrpCk5n6Bi9XSFr61vyZD9NePN8zI\n",
       "0J/Tfw5F0bowyEvicwsBnLeo+MZdw1lfbkRT1kGtXLo9ScTUYQaHWa/Wqz17XqsJ2WSobuQ/j2Ho\n",
       "bZiyvutSS/UlaPk6eZ4mfBd2iib95AE60VqYS4epW8AV5bptLtOGLsF7g+5r8wQyvRkizQuQFYB1\n",
       "SwhmvQcppukbYMQHJbS8EI2xdYbVlUl93iOL7DblHWdgHB0pAjDlnUcExYxgNl7wy3eihczgdKuW\n",
       "8M9vtnGKl+f/9wOezJop1BvEqSsZKUkSOLI8R0gSKmY87QezLE+sBM3VHui5vFcsjRoNM+RcSUgO\n",
       "SqRFnsoBJ+GnAe3zgapBF5Z0DUZkHuKHUMjn1zAYZbp8niwMASgNKP/dZH9ZYDSoTjrZPLnu/BUw\n",
       "UdHVAAACWkGaImxBD/6p4EPsACybCJKv/t8a1a2YsIW73Ac+YAzuF+P7zi8tDvBGgWX6PMlfg/5S\n",
       "F/zGiof/ZVL0QDGrwFFZHiivAN2DL1dFCyfhdGh2Nv0DXU0Hag2dehqwLD+t1jF+qVevVAsXq9tZ\n",
       "GZ+hDF5PIdv9I9IUJtx/Xncp4GWuP1lLS1xtxKC0XvfLvu4ji1lVA/mpXSfYAyxNTptAa1ztuGxB\n",
       "bARcymt4YSvgRbK7tpofty7wDOM3JE6JhWk5Fi8n+vsokEuazvCHTNLp/Ry8cvm/dVxEoOhqw4+G\n",
       "bgAbyc48tQ/c5P8FNkEEEFWInrZRjZ8qhXkhVGPjvbG8ZLnnOVifh/XPqo6qjS7H8Ts6wo7dlsXy\n",
       "KV8KW7NDE6gkdlGXqIM9FDOUln+g4R21n54afqqVrvYWlZbUk9YwntvsxGKAcqKJIshhVk6FONGd\n",
       "OetBo67VC0ELe7+unFTvxjAQUiYFWoQZgBch7UzohY4nnopAAhbYDd1x/aAkJcRN0obbuO9Lv2Iq\n",
       "9WWKwoBh7JK+HJ7W2bjtOerti30w53gotInWhBnGAIYbbHL10V3Z9w1Xp3Ftk2S14ZE/S4Dtt4Gv\n",
       "xOdjEG0rj9BxCdv2s2AD8XOgp40BWnTHCaaTyTyB8AW7VQqA9i9FB0pb0nOcqTWifslTte+b/q6w\n",
       "EvP1mkRd3NapSwnbUc2sxTr9W+u87iInWVc3rQRk98rVZKmz/eSeyt3jrB9eIQ9obsYC5vACUZQg\n",
       "5yoCtLigvFYHWpSvoXJJeD3MLKSRZt7jfxDis662Q9QWSCBdb92AAAAA+AGeQXkM/xQ4fVRKAMk9\n",
       "gAAmN8rfv43taRXsBdrFEwxsCSZn2uT2g1UWyVLjyeoP3w/k7QVzBSGWU7yfcRQ5VTCkqx7Xsu9V\n",
       "dlv9Uajbt0G66iXa+s4EpbMs0tWx1yQZDVdAzdhopYqrTff+920spXzDTDuTgrCH0818s3FwaGf9\n",
       "5XGguDee6aswfoFvrRMo36yNybDuYNd6v/O7CX3tOzwau9dmGWcShZC+jN9JZsUwef9j3oNMaD0H\n",
       "CM3IGJzmsG8v2la20kgCXtv1PJ/n+7onc0dfEhQ6n8cTm4lJLkL//OZitOBI3V5zD7zEGYX/Yi+T\n",
       "0fXyH9grAAACGEGaRjwhkymEEP/+qlW1xkIAaRexdfwjjSy7qa/n28WEgxMiZF2dtzIoB4j5//rd\n",
       "320bFe8nnin9oa2O8FFUgC72m9WbTd5O35WKJ+TiiQ0evuNNyeI3lTJ4qCy/YgXj4QRq+o6/K2Ag\n",
       "vfZbMwZGGpsCbB8EYZwraGPV56GI/SvFSdknjRXS2/cev0OtYrd5qV4/jeWgR7xSF52+eL+hQlKY\n",
       "ysxuHyKxpB2GhATrSFgadlBmL20Ai84i+QCUy0JoLN1dcP5YLFPIlpAJCptVKTZANL8rS/8t8VmZ\n",
       "53PFAoLE9hWWKf1m/pCXT0QqCWKggHfcOtrGV2ubvJexUwbfohgq6IgvYdvJskbT2XROCLLUqYYu\n",
       "6lAxhub1vwyiGGfKjICFeDwTpd7lSZUsYPerp6KxPbw6AU/D+HluhCyBt+8bWU2/viw/WqzQ3cvJ\n",
       "gSowPyhsPDbZPR12tlYjyK3zkpLcivFX5aXVhkH6XRNYqmwNenF5TkrC+LzAxvkTBU9XxfEv9xIq\n",
       "xftvWJ78a7FjyYoZPkGB+luowEdBlGCrEWtd2O7Z/mvGVhSXFHPjijmYuPulXl/sjNAMauJAkoa7\n",
       "NB7J6bYwDIZoAMCCprzISA2SI0/xmCpHxxxw1XnMKL3M7iEz6AlQOlr9l6jXM/f2z4JfgFBs8ZNC\n",
       "mUPyN7FhVPYUHxcjs4ooxikG8Fn3G4Yy6SYyHPmmH4wsAAABS0GeZGpTw38EqVE64Dkh1IfuVJ4v\n",
       "q21z7sfOp0xJMlDqSLkx12+KPsLwSJV2kx8mhGbn60okVSWf3MF08atG+EnohgJZG4KqzElj8x8s\n",
       "khT9t7hMeO1aW6J44umCntfZwTN7bpcZo1e/RBmaJY/ATw5C/ras1FIi7uuI464xPlhyJbZ5Bf4Y\n",
       "Nc9PZ5VQYU8HOOIIgLwW1qr4cYh8bCOeZ5Dc5HNRD+15rYDfUuJTfrFQ8vayjaL65H9gjhq84WsA\n",
       "5JzHbuoiBtVB6B9Fw1eAHoOyjKNZJiRK+NDgnzygwb3JrRRT4VElKVbF8MWZSPUNI4u+sYcEI0O/\n",
       "vkMW1Am+3gi28eJnZJtCpmlrzbJIc5v7+8MqXsNUlpklK+k5O6NWYaqTzL+8bWKp8JTaAyFegQjK\n",
       "LqgLQQx1uGyOdsnrNEoaNmjgHzS4aeOllpsAAAEGAZ6DdEM/BWCHzQUI1gkANW/8cupFgoJJfECH\n",
       "1qBE9M72UW3ToGDuKRmR29sLF+M76xytKvD4vT2/02u3kCj/hwQTpHeiuitMoEvKoVbZTySpX/42\n",
       "1EYaMbWNu5Fw28O1AzD5Yv9QebXLRFHwlVawrbmcmu0U/gsgi3164nMUJPz/+889++rMejZIsA2t\n",
       "xEszJ6MUmsCC9ef5jziatgfjK/P/H0gnUNh8kHGfO/GJ4qEwzC2gZ9N+W5GR13FcNzhpfTg3cUad\n",
       "eZJ6Pbs/R40NTimoBnlakXSyrWisr2nCZH0U4ttbWUs5t9+mj68VSYDV+7MDkeKLrc42NV7SCA1T\n",
       "6LVFgt0rzwAAAQUBnoVqQz8FZsUnh/AHXZIgV3vVZ9/ieSJNjXG+BpFVNTCo+vjILIhL71eOlATr\n",
       "cng4WUM73zvFLyON+mQznhyYJUoh+Ub6GinYTZc0uh82rYbysOOstvtat27yjqDHg4i4yIaNwokn\n",
       "bIuSsu3KwNJFPytPLrty14RZzHvVPb6KpsLXqUTGMbEWZveY0HIZTbv1L43KK8BcHvqr0X0K/CVH\n",
       "OdAyW4bEHqGgxpQu6g+OUp8do+Z+VS7aBXJwdApzoH7TwPHHQQNlwJOKH+pqxP8iMsAaec9zlkMo\n",
       "Ne884Wj3PeemtXietBCeZmMCSATNtvCSkec00pQjBGTgmswYOfsrMZB9V5EAAAHmQZqISahBaJlM\n",
       "FPBD//6qVaSFa9XQBBXQbo2X0Yuzo+BrTRqlVEMFE5YpHjUGpGYcXZzq3EsgZb5yMs8MyUEWICwD\n",
       "u2b9JSw3mUWB9FKQeHcjY6W9HiSWI1hUlSb/1VJ+c1LpIjJznCUAh96w8FEmLqwjixZtcG3j6B68\n",
       "Z0eG9W6Cv6+YmuVaz0eW6YfgM0urRX+z2R5ml4LSPjLIDgr4rmLRu7TFREGn8SUiotbUFNu9QgqF\n",
       "mdjmJfZZAQd3NGWJfd+TjsXo2LIFLiU0Pw53ptkOPpGbeXm4QBD4u3q1VOs0udxbhTfJdUu0qW8I\n",
       "izOTRd3ip8dcz42bzkbj495f51R1iAzVx8Kq/KYUAKeRWq0lBDBrSIjhN0l6NFIGbKD5HZ3HBlnh\n",
       "Jfw4jwsa/onxxwME6rJoZUougJ//2P/lhn/+s2VrakDDvvJX6Ry0yOOKyRymM0XX32yAScQcMFOt\n",
       "jXAzRN+G68+qaiRUGqVTycGaoTGNQr7lsi2Ti/fa3Hexe0xdVHBbIw9E3Tcqu81KKQtbEyx+kiDs\n",
       "3Yx/Oi6cPebwOBOk3Wr880c3CsgZhtKN7b6QfH4q5enJ2BRwVL2FkAWeQgtNa25CwlBy57AL4DWL\n",
       "1qbooIFFwVGgNgNrif66G9s9+SchAAAA4AGep2pDPwViTfyuAEsraWHkJP6TmoIhP/rY7ACZfhKD\n",
       "pad4gxwPayO0w7pp6Ftfl14dW9Tvd0bPqqUF3CD+FwfKCp9JmazO3A37YWzmktCxQDlHmzUvqKEj\n",
       "+CPjNphHZoJkvR/Iub+CBVNZqJD1I0OcJwIJd89Qj3aYJaWQonnoXXNAppvl4LGbtCJ6caDjOlhx\n",
       "SR2b5mugU1eLpSPqgJcdMS4vtmighYu9pD0vIzxL9p30mJp/Y6K4KhaCAD65gvJ+TJvidEhf2rJZ\n",
       "bAkLjaavW8NrEnH3HB5ffBuy/ffbAAAB5UGarEnhClJlMCCH//6qXXzBcJNH32AEQf0R9mifTvHz\n",
       "nt6pA/2AmAGLspRa+YWMLuaweGXVWd1GXjEpunaI4NMw6S+hLsGFVSFLu8rVAowDWvjXSlzqOgqw\n",
       "6nFQBhvK+z9lpqqRQGkHFr6S1wT0iXrOwjbWqO3KoT11oRu9zzO+DiNa8h7OuDKFr+IfR9i7KnMx\n",
       "a4dViO4ymBEJ15fVhVDHNiMCXHIN4E04ZdV5d4IIoFLOHPPkyk4+b/tBOaBRbjruns8Md9emwkJh\n",
       "QLSMUApHzEJNW4iN7mI2YP9kADQnI1664awh0+1lPZIOoj/sw8SMe3Ha0Q8gZJazZStp7m4lnIKL\n",
       "xULFpNytDpUBrE2YPS5wIk6ngkdf/ZwyHp6Z5eKXMDoPvv2lw48OD8CV6QIAfajpkCEMJCIkgf/X\n",
       "A5scewf+p76g8mqxPqaL+/eCMpHtdIHi85RwMoxJwm7l/BJtHFr8N3Lfcms+lDS/jNAGLguhUeNS\n",
       "U1lVGcdvgZsk5CXd/+AVodXUQywrHjBB+apntUUB8qQB/j4t8RSnzfANZJJPXg36oihXQiJgAhSE\n",
       "NTRUZWG8Q9oUsYqopaIt6EHkYEK5yfm4KAszH5E5mcHNIwn3FpvLknRxka1SdnkppwEPmwWgAAAB\n",
       "XkGeykU0TDf/CSgX+CjUgAui6ClZEG333+RtIIgY/E2FmrjjyCOEfW10zn08mLG57rPtOLZiGzOh\n",
       "x8JKU7HyN+KPBKgNBUo7Jj+dcJ6s2r7deZrEb/GiAmdURZm5uKlS/Zlwnbg2f7aAI2VgYN+Z3djv\n",
       "gr0ZApRbYcQko8asad6Af/8qV0t+kbEGFWxTGMx2+UlZSIIg8Yhuf2Ku3f+r/SYPLf3926lvRq/E\n",
       "W7CeQ0HqNdO7iWQ3H4ZPstlgNjhch78bGcW0dOhTzdkUWC50pV2bUl8ePKgAdHToA2S0Cnda7cFC\n",
       "zdrK4/HbIUQEmgLN5eNTifhC+NLGiS6qdltvSiDIQ4jNurpHuEsuG2w81RZjjHYW9WyoUq0anZG6\n",
       "qxpAhw65lXyRclx+rBve7fSJ+eH1rwRKSfS2l6U4149Al9BVQulN7RZUg8inG7XkqSs0H7+g+jBZ\n",
       "GXAzOAwIUcvxAAAA7AGe6XRDPwRoLBPlmbsQA1bSBonVanbyGgPfWZ/p+dJAOSo9j314dGCwrIQ+\n",
       "xs4+tyRcKJYReeN0f+dPPJnJ+Mh56LCFD45hjLD6OvbldKZ/g8QZH01hXtWiEAb+QE4KNVJlmGX/\n",
       "fhGMMi4TkNewo3EmKaw9YFtbCVtwO/2fJJxcv6f9rIDTXmOBgbWdu4pZxGHOS0pb4RbAcKvbdxmY\n",
       "7nT4TUD/nTbRRR4rkKt0hZKY/KSBHr7Ncj/8L7+nRengBbSplwcQdmSffivICJ0t4Mjy4ErejP+v\n",
       "Ot0ZHVq4iTZwqiEaeTDTda8MsNJ5AAABAQGe62pDPwRwPIBq///gndwKHOVSt/VjydRoTR5HmxiW\n",
       "8wnphD3bj9YBjgGw5bfqPgUkH3Ag95vaDdg/uuivxsIxuWGF46HWN9j3mYMQMaXbgV9T2WUZZLaa\n",
       "xuR+0ngf0BQk/vnn70HgTiHQvsrt8ckGOPgVD0+FTwydG+fdYVyWE9EtxM9XRSx+Oyr7ui2lAZAQ\n",
       "560ToTRwNNMaLXBfaSP0nLEnh1xX+BiXVSA4KyjYrE9sceYO4wLLkMYNzHEVXBoDoWVo2/2s6iOD\n",
       "LGQAnpbjfMr483yK/fSRD15UJVu5jtF/a7ANTNPGHAklM5xZv4oSE/8IF1fIwHfWaFHsMcCAAAAB\n",
       "y0Ga7kmoQWiZTBTwQ//+ql18wXFyKr9gAunB+Ok9jTk8Tl755OVe2uX3lo9dHIGBkH5B5JKfNxrx\n",
       "FDKJ3O7//K+zfp9bS5GdzDhX67S0M+OrRfZWd6tedShO+2rQihkuObm3VY4YOxEKW2rT25V7aC3r\n",
       "9k6UmFgIuDO3NEFFHNf9WiJcq5wf5vaE3ppXdQF2aGDCjF5JIbvptwh3XoNjfLyi7nsDP9pkg14S\n",
       "f0hPt/2FshCDU56QtrVn53KifVGTIbOBC/CVXfJArg5V/Sgpws2vzUEm0Q2wdCjR6OK3BXrRHEYx\n",
       "1XPiDurlM8LKDq5Rm6OPnpPhIciUGdGquaHjcpGhmzhsLDAoKslrqX+CpoKhKQV5kNoNSR1Ekq+p\n",
       "tztb0gdqZQIDlGe3b1pUCSTLVJ0/triFKOW+TDn+guOndobF7vgCgQHK252dtEgB73tcJjvRBklm\n",
       "Ae5YBsNOvBJISTSss9b7zLf27MTJ6tOjwSVlUVcs4VzG03zNZsaL4ITTd+ccwDvAtw1L0yBEqT22\n",
       "rBYLpzdD3z2ctKuuFI/ryrN9TaN5QH54t0YFhRm7xFBUIQlXoFm//wErDRnol+A+ZlHhnSKtK9qx\n",
       "arOdfwAAAR0Bnw1qQz8KoRVAB8nnch3xXpv9bailnryKmwd/rtZt3NfiOVPPsNTy74fYJUEAnhOW\n",
       "bnKdliVe4vNnp0CFVDDeqQA62Ys9AoICJRJpS6uywOneixxb3qpULzvXCTxQLg0xtqH0XAHkN1B/\n",
       "KMNiYXRd2ckk56LKIsgHIugD0DBrS9pHIdVImd/SO3D5s48ehlocIXjnjLNKaXO5y0pMRwEg/KmV\n",
       "5s0mx8wpfXzyV3LmmkFCpukW+8KISpaIMYQO2uDeJb7Oqrx79a2UZfYRcE4jgt/v2l1bdDUFvyhq\n",
       "j8dZWtFf+d6fKqxhyg00a54eahtfYaEJApVz48rzfmy/SwwSpQ4dhiObKyyFpr09Fvi87fDw+Asm\n",
       "ElYfPEvfoKEAAAGJQZsSSeEKUmUwIIf//qpdaUiCat6+K5AB+3R0JXNSSM1+UQ6iqh4El9VtK4pj\n",
       "SClJ5j6BIVw7gkOcLvsCy0eL0eJ/X/PQS3Nolj+pkWPhicjS+u5Tp+g1hfWYD/BSn0mg3sS6/9tB\n",
       "C9CUjeninuUrhR8Pu+yAHzsuNN5SIJ84MgOYeFguTUXpzNyuSloEXs20ORhewYy5w9mW/imKHLXR\n",
       "pPbanwdyDVYC6+oRIsbxUm1PrKlJh9eKSFM5v9PHbcC/A8N6YYq8z9L/z9IAP4OzVphRweSOEcN7\n",
       "F4TTLStQXNfIp7SoUpQSDJYj4idO/wEu0imen+6KpDlYZxV6FXla083q6FN45riBXBTKClGqYjUe\n",
       "xFfkYMAkw//Xi9Q/8MJEWygLhKS4ISUmBU6E/iapOuSRLLwgbStJdH/hw82nrLWYPlAJ+3xspm5P\n",
       "/6VeqBqWW7Lv5lUXYyDY0qsSJHG9pOb73Cm7nF706ngaU81LYzN525WA5/oDDXHM6k7ZacIxdg6Z\n",
       "p+5WumjBAAABfkGfMEU0TDf/COz7I4Cz7i+ACHECee3sdyTxYP5pXXmDPqEq/etC7598l9SHDHZq\n",
       "uGgVQjkktSyuDa9zueGi3IxNuTZlyjAEBCYNkyUpdvrOp9qKef5Nad3m9P2a2k3F/P/r4rb9NWWt\n",
       "FMoUuH7ysPJzzwnmil6+ElNxMAmMIxsl2PytAxCryR912OmPwbguouUqUzyF3Fd2ixjBxpnD/5jq\n",
       "MbkcND5IdEx4vTL3lH/4rPgh2aZDddofcs37Gee2YamFIeT1cA57Fd5Oz5m3voozQcPhDGO3Rox9\n",
       "/Ks5qXatLw/YsaZreuF5c8obOUiXg5OjImE9qXZNpqKodnloMP1rb/jPlyMu6vpf3aiGvJi6ewzs\n",
       "QcYgtovueuWetETKJHNMRiQfAXw9A34bEJzemtYeCL8s6Fa99wo4OU0RczjswcrE8utDXZEF7cLn\n",
       "Muyuh+HS1F84mtX+Z53DTt08M+tWJXInuI+0N8Tsibca7VzUDWs/F7Up5B0YXKx1O0AAAADhAZ9P\n",
       "dEM/Ckicr8EXDgBCdk3vxt6mAtXSp48CObMsyJeg6n6gdGNChZgFrEmauhgWfB9Oo7tQrYFiFSzl\n",
       "7De3O+gI7o6ArKP32VXm0dDUm0Zgf2vdKT4WG+vUm3HcU9hdNaAK5ZdhxLPUi4+3UwM+6dtTRPbd\n",
       "oz9iLBToA908TTDWGZ5Tm3qWS3fxAO3ZT9OhTYb9u41APwjeEfElqliSbycfqTFTBvonXLUWf7ZP\n",
       "cpdjZjgjsNC/UDdGYY2T4QoxC8HRxe8BSbjpOrhZUZccuhwxTkya+qo301NS4xksFaggAAAAwAGf\n",
       "UWpDPwoxjRJACSE4pB/F09uYNY5UcAckWRT2dTY8U06uODDVon90HGL6japEMeFxxUaiT4CVjz8U\n",
       "dGsbeRtnygRP5v74XD9USwJ0+1X0/yXTFkWIKvM1IUpq15sPEGJF5+9ECU+cFPhYQ3w7lgtrJ963\n",
       "/RpijXlhQHsFVtRPK0ueduBavV83IjMDRgX5/dvo6t5EDkAMwLhLdYpa5YOnQ6tsK/xYmmG8jBQh\n",
       "+hlp+JwShHtPmZJ84RJd5ucTDQAAAaxBm1ZJqEFomUwIIf/+ql18z5IVms3vACaXTN6H2RxEJ3Tc\n",
       "YTtHn3oOq2Fit+ND+h1YeTocqPg+UL8n+Qgzpo5pQ39s/fqeeXD8WN9miXrYnnoTRSO0hOt323bN\n",
       "iTGbOS0QxfQVpWLR3gT3sq2ZElN/65u7JuM6VP99YNCbkodCtypTnOcchE/94Jr9nOHmTMdSX1Tv\n",
       "aAaJptzyAj6tCHgrpzuXiPNmpS71X5U61X9RHESo5rtPL9mYu353/syag7Qu3jOiyGUWP6UDsHRo\n",
       "aPW3efEyd3j1p9BdfH0GatXMDETPhJ5zz9TXgF1TFnQhGMfNcuJTXqSXBtJqiIY/xGdmOVm9TL7V\n",
       "m5gka+tCeBKh8U9/ggoKKSw822VthXXTSKmRSkYjMTwuJG1MmI+EO+aol+UJsqHtPotHETB63n+b\n",
       "WdCOHtIOskK6qXGvz8ot86oe9edRImQHLE9I6HyDDGJpqAwBeNlWovTkWwL6/FGPxreTEipOdJNL\n",
       "UUv26fda0tsRRK1PSthLJu82NFw4pUorptbTSJg4Q6yAnMcEmPdMrUREG2oTPKwQ8LeIIQAAAQ5B\n",
       "n3RFESw3/wmlXHl88ABOWeQ/kmXSd6E38TxytbQxCdWxaJgFprk/kjAaq39kXElM6VZudvieWskS\n",
       "+I70AHu8Pwbnm7NxmisJaee31zBcK8ACTkWvAMmMZ//Bbj49LDJaeN+ikNtdjp2VRf83UI38YFPv\n",
       "kKlvruiTNWox8Mtzyt+aBZEJcX8XQtzSGm41p4dp9znSGlZjcY1q1ZCJ7N6jaQMc1OeawqMBCZHv\n",
       "xKrGE8JoG471XGRt2997s5cKEVwHXflw0oEpy4uxWRz8A8WiDvNjXzUotDcdkRvefQ1W35WI7D94\n",
       "BpcJ93Kr8R7yos1EW3rbYPh4diA5hZN901YCPMTpOrbAptIdo+6ySNgAAACxAZ+TdEM/COnDsQAb\n",
       "xzTKg1vjgDL4PaPpJMN8ndAvaTtHVvsmAILHQbPcnvu6WSGAnmw9RCIK6KVAi2YGhQaBQSt9tPaE\n",
       "GADT+mz31F9vwx2gkR7Ynm4H1++tbIMNxO4Us7EyiEnNexuL7jf/05d4GQfLLIF9RON/EU2MOk0z\n",
       "6x6nKWK8DFLWPUMDN2xs6mDPGDY3R9flM3cUUNUZMNfdBDak0XwCC/dtCF5sQKCldNahAAAA0gGf\n",
       "lWpDPwqSviAEsdXxb5oRFtpjoMzOI1P3enrwJjHOMU4EGJZN127u2gU1abBkX+XX1Mxk9Kf+eKVe\n",
       "yItZUBXt6MuiwEOCRTAafgcgBHXs0XoGdI6m2c4RqWe/7t30LpmXqP2ErM/DMIplSfyT3X4CzQ/E\n",
       "cXsm1vkzX+zVOVynoeA89vaeB+kflsJJiCD68VCUgGYdE4MXDGb08shq5i/yR14UkGHD2Vr9lda+\n",
       "3hMBcTlbI4s4a5F7fBkbMllgJjfyRoD+AiXfeZZZIOslb0hswAAAAgtBm5lJqEFsmUwIIf/+ql2K\n",
       "7AADOVfardWiPt6tlwW32hNghQFyU/RrqoJqeZgy74mNnE722nF5Wfgg7fe2XFKzuzLjVSKZtPkK\n",
       "cWOSY3gFnc0PDNyf1KpyvG/7zPG0ZuOhuwrwFT2U5f+UmFfmhT0Ivy8kKqbleSa202D8NSZYJrH0\n",
       "v6M/zXwRvMvEhYkBhvsmeEEhiaEVkeS128k8mJwGGn9ls5gczckRxQdbQdtS5deA+MUJjcEEWe+H\n",
       "vH+RLyE8aeOOJwNE5OITJEwP9Z/45Pqe2KLT/ryC52Ua01iFMmi0FcMAfgMaCnooT5G8DpxtusYS\n",
       "wLnAjgO/EJUZXeV+OJhA/LUpMgl7NLyifOnrTXNasXWi5rWxQeKInKEKMYKio5AXaPdJQPgwdryt\n",
       "buX93JSOEtECsVpiyW8QN7MLajF4lIxaVrpHM/teRaOxzDCDzb60GHYaRD6ulBKUPoDiPE4JwyOR\n",
       "CwmIgWTRnwGYOpmY+uCrJLH09+eeh2C/pa3N0aNoZicpd2vMTKVppK+ghOi4Gh/JadJ1Vbw4H55b\n",
       "7voonhdJqP6MNNmtf1FlljrAxQGJ1+KrhGPPmt4B8GoQfeTwaws4kuQDGonHs7xYJ7azbwyBTDLe\n",
       "7Wzgca3KXknxZPLKK08RqCxGVGy4sluB4vBFi8Mh1Y5dLNNEQkI4naa+NinEMx9HyfnxAAABcUGf\n",
       "t0UVLDP/Ckn7x4ICAFahgiJZmKZBFv+45OHRble9LyT4UGUmwxmdH4ntUdEs4+9qx/ITgx8VGBxN\n",
       "sGTws0Hh5/KHCOtVwdPJnglbJkPJ22pmCB/+Ior1bHYyhUVBCyITnFcGd8HhKtC3FEu0k2ykkjZm\n",
       "kg++IfINqxq31exNTVnlqVtkvVXPfChPVobHEzF6gilhl6O6eWb47EamCdpdCEXyYangHNwpDbl1\n",
       "FSWJhLe4FoyjoXW8ozpGGqFPYIVwpLN0h9RRRJlul3M7hchDkCyw9pgsN4Mlmrf3A3DDtFJkqw0I\n",
       "axc+IePzscO8v2dJ063W0pb7g9Z8zytEIXGPHz25NKWkKjo/O/f63XZI/g0dTuQ3BVtBznrOo/8V\n",
       "SeNyZLSiFRgntg6fc7toWwH3m3HLpT5XiNcNSof6bsqs3aGQNto/NkH3mPrHc2Tj7f1ZEJPgun86\n",
       "asDD5agyxMTuXe/FkAYhBBUmRmtOXIujcQAAAM4Bn9hqQz8Jd0byAECDyb63GTCtBphZmvz5DrN1\n",
       "hzp93DySpgcEY1GKOqOalandvxSEkTyDYVgduLuiecjW6zwVf+0BoVywt7BRJMEqLCEiJkuof9fE\n",
       "FVUG08LCzw8on/Q6d4wl+YiQXf5ox7kVGyC62HMEfY8tzcwsdC1d2qscOZvfeWTlQJN7VuwswDH6\n",
       "1S0N/5n3UzHkr0XhugcUOGdruqXgybnBB02bjvdvhsV8RiZq7J5QAaX5plEkR7qVVynILWaiC9L1\n",
       "CH6NLfd3oAAAAVdBm91JqEFsmUwIf//+qaiZz/4riPOADliAnRX7CQOEdphbZIcM8+Um5u1Dewim\n",
       "rJ/bE3Ignc+GcxPyMo5F0H2lDsWpUoVYp81yHu3VTib2nCWY8GSpJ8YVmUs2myjxHNYgeZwnfX2R\n",
       "SvD9QZ4aLhlZCc5ow9CGuElVH6ySOmusl69s8R+zXuUMG8fpJ5ejQvoT4mdTcIbRYAX+ze2VLDOO\n",
       "i4nr+Mgb2zw1fJC2Xxl0HCputPbJDC/om330E4Wkw4Oy6e+8O4Kkb2kOZt4WTkOLySxgUSiW9sNX\n",
       "MWsHIr6vjxGfEsJoKfu59xUIhqnBH8fuV9wI+hHCS3/l4XZ3rQ6YiYCDz87wBIIp13UJZqrKzeNO\n",
       "DtY3t8pFVi2BcHDtwNuJUi6cNmPZXgrU5uGmz2eydJP4dNShTwCgRsbJpKE3glmGw/hugEmH2xsh\n",
       "8cm4YchR+95tUlwLAAABQEGf+0UVLDf/CR0NQD6w18ErOpNiD7f2b8qQJ55f66GZUg1RdsH+J03O\n",
       "bLQkZx44zk3Xwumkf/X/+SwC0KZTzHwPR58Xsc16FjBrf8867ueT5fqDxr/w/t3P+wIwpva6eTGd\n",
       "tX2jPA4wGMVi0V0gjhwubaZFFA92nOWwIF/JM+sGHYUEn6YRL50kW1L4q4K9jsX3Fiwq4QzLFGvC\n",
       "90yZHZNkn9TNjlBeAqWok4ZPlhyFvsXWM8Fm19qdTgp6v3+rStXvQvuAwmd5nljoXcp+0md0P1Y5\n",
       "1CNP4E2QaYjfVHU3460w4a7GuzYpcUW3YTxcvhcK2yKKl5wdsa9D+MydhJtPj3uKq5W9K4wwxvUV\n",
       "Cl9T8YhU8GZvRhyyavQoH/s/avj6uJhwNw0okoWcDgLXbagn2Xgf5WALhOPahmmSE+2AAAABHAGe\n",
       "GnRDPwpRZ1Pr6hxm6ADYcrmJ/ZD9yxVVtlK9LGgXwUDhNmM+dmdaKUX/31MaDkFywUAfsLCbOZ8g\n",
       "X+0py+tk8RIxFXjkyeBUBVAZbUM14FYulbUH+s4eyyBI4/8p9aHn1+KxvwFi0+4lVKmZ28uuiZjr\n",
       "nZTw+45sAE7SIY4q6ig9iMtmTXQN073XpOSb+4iSohAQwlre1xlsX9mort5TCgiSAe7xqcgLM/Jo\n",
       "+kuoHE3v3GEr48AiadApHfRXFB+4lgj0ga+7AsLdsBuZSjdJKobvdNoVbsPBBI6TOkqErGbQiRGc\n",
       "r74Q4/xc+PgOCPA8g0fVoqn52pn2DhsiI3gQtnKoRSPRaTNzhiftx7cA/RfcPg3w8bhaASuBAAAB\n",
       "bQGeHGpDPwopdkj3DgAQ3itTx3lkxKo/k5d8mHoQdRIX3aDMf41n/KjwLn3acXeatTb2u4ePttQd\n",
       "iBFVoiINjwtrJadqUYdyrpmg0Z2j8KPcF2sJhW5LW0e017e9wTYyfPsdqjFuvKLrnAAbAqKva8je\n",
       "ObbdFZ88cM4Egr06AH0xYZcJfPrhW2n3wNtyBWUNUgunq5Yo1jqTWN7+3Y0b0NEZPdhhpJ6hX5aj\n",
       "SwLr3qNMLarTyDgfldML0dA+6oJR4yRBxK2J6H1wnFzDGpErqvm7+/Xxfe2BK+vogxZdLhUgHv7C\n",
       "1DwDpN+mfZpFEZ/Pm7BvLBBp1pffoucM2zsThS3bmC9N+cw2Lrx5hnRAVqo9NuxX5iJTq0v72lNO\n",
       "8W09pg7biIQuxVeHCcv2ZpP4B71lD2GvDHzglNNy5dxOCfsq4ipeTs6UZ00Jq8A8cdY5Ybl09L4/\n",
       "0XYtkZma0tGBGpYl+yhUbcMo1NnPE1PhAAAB6kGaHkmoQWyZTAgh//6qXXzP/hAzoAOa2AeSjOvH\n",
       "2d6jl0Rb9U4n7IV3os5uMWwfcHqOvEXWGYmGmGzOyhHxouNYzABzLxeDPe8KcLBNVAzMV98VE9Mx\n",
       "op6BamFtu2WIyPlB3t3WGfdt60yfZ9QXjQGdYTb2yfYKYyKf0mQwXmCvvnDBYhliCRmokl8dYEfA\n",
       "OYSftpBpelcPPBVhB3G4CdBEs76dyicsMtXm1eYrth9YN19Twt9E5aAsZZ3eVjWRYosuOkgadoM6\n",
       "U8Se6ulOOvH8Y5fVvtAKUilei8WY/L2XhD8DxHyG8O1hwbpd27pamD/BC4ANL5/RAdA7dIaen+4y\n",
       "gTqRWmjXxrNCF0LSmJ9eif6LuZDmVWfKCh41VasyyCOzw52XyynDcEyWp9MKpcjuFogkMxh9Pb0L\n",
       "1w9YABnfICrdCZDwhNszaPN4GWEr8re0fZPoyuygpOc03NRLgx7BFVRYk3Qn4qpcCyAbcuub5Fpm\n",
       "mLyeKirNdD/skLkGPBwPXPMMbIQzTU7GxEOi/VrNIsVy6cfLGk5MpjDoXO4b8t+8CIMcJwwSgEbK\n",
       "3UfJ3pPEsafWH7MKcgmEGgK7JHaBFbluYojbueMyo/CjnI9WKahaOUKROnNSkvLsm7d2L+5r2tRO\n",
       "TSgmzJwAAAJOQZohSeEKUmUwIIf//qpdjP4SLg+4fABCsP/ZEGfTH/e7R8dOqEL9sXNrPMe/+nj0\n",
       "Nx3rgg1Qww58N8HurXLbDpn+fiIbl8WhotecdpPCP8mFWABdUE+iZk2ZjdntzdF4sRdl3m3cWTV/\n",
       "lTsMW40e7zQiZrz4xx55yojdQ688tjUoNCnTu3StCNc7gVuxq9WxBb+MBza5qXynGi/XpiOROGXM\n",
       "kuAM/pmHCZKl25s6oIin7cw91gjvrmQE+oqPeEKk4macpdlRNDJGlamjx3Fd05GYh3yut1GPfd/J\n",
       "a3tHnKHFRbfnt5M1XnwhqBupu1deSoB3qSUXKjiK5ECTBBoKD/hnggaa9S2VXFFk+ut65AK8zEqW\n",
       "svIX9ryAbPNYVyvXf5vfI/AyDQMcDa1djO0SYnkxEHC3hDYniQT3EAVBiK6K40s6Pu/MxhHt+0oz\n",
       "Tbr9bhEiCr5DU7GUkJwFkniuumfopyjDGTlS4d+OsjnFL6jnbYSndzteLE2rFHyCYWPGY0E7ZXL5\n",
       "og+sQNmnJez4FO+FZCXpeNxyTU7yEWkjocvtsRUsbLpgYgR+dIkoI1mPi7Z3YfrrtvvlWE97O9tH\n",
       "OTn232W8ygcQw48CsV39dQC27f59G0EvgIYLNHPu1lAsF7/PgxH7uSrFuHRlgiSPSg/pGTnq5i9O\n",
       "5+CxO8ceYaoaVhzmloaryTzGedKphqYDm1g07p9IsE2HyGsIngdC6ymyBjFK4BZE6v+rNMxGp+EL\n",
       "yBrwF8Z956UfPEXbEFgcCd2ooUEalRUuFFIkN4AAAAHAQZ5fRTRMM/8MDBfSCo8kzk0L6sKKPwAc\n",
       "WmQ7wV+1wPsl0US/N1ft4L89MX5oL1gP2XgZHTrIDRLMnnggEdSWFF8HB6Mksj8fuZWkfev3ysQL\n",
       "sXsgCfCK90OMAcFvMGQrhdwLdloqB71R1n/Ouk2DiEWQsuT5kB+IG8Iftq944rA9MthKEIAoLLG2\n",
       "O6r+MmVB/YOBrRYQUg/iTmDsuMF4WVfHkJDl12uMFRxHpickTJYoWFtH+8cIDXIb0fqOKf8GOjQ5\n",
       "S4U364oBoHOfTz793nsMm7U95rU3W91p92S4ZYsy+qELCChr9s2Mel09b0vCtDMrCIrklMft9B98\n",
       "eVlXjMToVrUt6/ALGChkJ3pIcYFTT507sqQqj2wJnwhrXtEyaUMpzEQ+JQ5K8IDp34EigTYExSw+\n",
       "aG49pmHUtdgQ6RuQpD/KkisMU89odQIPIM4MnQ0ZbZRgrcE+qMHF6tsejNtYjF3nBQbUG5iHaAuT\n",
       "f2UGCxjf+E+fQXlYRF6vJvaS7E5ES8bz2fiABDNF1OT6Gs58FNT9Y1dT9VzVbhF9rBzAMSo86y7Q\n",
       "5QVB2u1SSd6fj8H7EFbY9Y3VLmKP9cbGwQAAAW4BnmBqQz8EXssQlKAUCO6gpubuqjH6gLPIcLS9\n",
       "t6zp1159EP9QmtXbViWKO6r9lfpeg3Tqtt482LH2W9K2r2QW8GBNzCZf0nKxBTXbQoHkIbh3R2X/\n",
       "qyQdnw00bajolmmF4ulZAo+cqeGFoHNNVE6LV6p+b7M/SL7IY/VFnBdMpI8lJAPHYO6U6KfmLDXq\n",
       "bkJapoN+LMn0sPfJlEVJt39EdU1Rgs+PPDMBF0ShaQ+AcMsiTdJn/MRA4eyrREHh3Nml/Q5r6H12\n",
       "ZYAoKDAqN9vorgA4tWp2nnoQZKODwNKf+hEIESDZjWiFNYR8dIh/BBKU4gPnW0FVK49l3y9vQrN4\n",
       "sHQqQnq5aiRTQfio+QwA1JG5Uh/zK8Liatt/nmbQ+FvrNavuqj0QohPEvVaHs2s7W7XzAASE0wDQ\n",
       "OM2/XBZAHPqgDdDLRHwo2B4gs8AiuAaGyvkFQPj3/2+kwTTObglB5HeD8UKcCL4wpQZIPEAAAAHd\n",
       "QZplSahBaJlMCCH//qpVVWaAk7ly9nkHgob+0Jp8W/8U+ZKiOjSUXtx4L6YRUL/5u3MfVL7Qm0g+\n",
       "IVnbDOVhOCeMr3Y2nr4I8G4Aj9Hvn4FlK1+ItI2VKY5NFhtLnTMu4BDYbwBIgCFPNXCJxOar8YYk\n",
       "9c7jJ9waSC/dZJXgJ/Z+mlCu5lXFviP37B0652zTDSx5TYJQ4wVJW6cPtpbHQbeDI1jBdhBmspil\n",
       "emesEg5zEntXbjBrvVbpD7d7mwnNevPghSgY0JPTuZAFvv1cm4tCf27SdiJHQf7zf2d4fDtOequG\n",
       "mz3hfSajM2vQYsIS1EQYbD2P+mrKlcYhzdWkqYjjB+4tyPvgtEmVw6CklQjFqmRjtDZy7g70sx5X\n",
       "cUOucxfHA6O4KDXBhqZFOdyV+xowYt9Ymco762VuYEez37PGZGnsjxMR0FWBpBgimohOPm4ma88O\n",
       "IWbBZNUhNLOMAozCc1Qm5ZPHwXbqKgzp4HKFCZlE1sd5YlaZHaVi8Uoj0sqcKhLLnF9UejfDwfqn\n",
       "NCXSCghXW/7q8dWwZt/shPqNlOWHefqKrUpy6IGZygE/YSNszWo1J9CJ7FJHhDvsoMfhU2LAfOyq\n",
       "fPyQijydT10uoyyZcbZuzu2yUj3BAAABWkGeg0URLDf/A3wHeoPPVVDaGmHKbd5+BxmDF1GWalHB\n",
       "fojC7ayfpRnU7ok27cThHJL/x04erlxJ05iPfNDedOoiIrHSvE12gxJXUjYFSPq9h39xpfN8SvTM\n",
       "pFV3KrjmWlVzJsA3sCxI0emxYwWOGzw27gemauKoGFmrt+EkSEP73+hpz6u19YAVlfRHrtNfFhn3\n",
       "JGohkBKEVc9ByOu+M25xD1dzAZq2FMEGE8xLKGMLBmmWr3XvTVIIB0qN2PU0Gf9NI8dqd/sc/RJx\n",
       "olY/WRBrnHeFmkDdJYGItzRohnOvrSDfS1qhN42Dkal2eyZrUFxWlylJhNVITrFnH1kabWlYkYNa\n",
       "7kLLOY7T1mmSOfkLA035sABK8Fff8G/bQmIBWKCaQwiJ2CESDur9gyz53DdfgnccIeyuOghFW0mL\n",
       "5HzNgw7UDZlfUrjrwQ9Y/eE9QWWiIZRi0rPouDMAAAFHAZ6idEM/BGWjXAPIxuE6gpcVAivqhA+o\n",
       "wjHE9X3T5oD3X10weWmxsnBQ7a22KQyQpSqeO/GhoXK4SwoHwNUBoeMbmKCD+5HJgSyTAaa01YGX\n",
       "2mVHx+eQ8mrCAAH7Z4MoYMiNblPRx2kDfWwRLwe+SbJglVFfgktjgnLzpxb8jJIVot3nWLUyoXwF\n",
       "TUTFZttpF+RhuWsYjDjmG33q5uIHctWIqcMORri1aOtZ8XBw3Y99squ/gpxkNMNq9AOY3yx1tmZ9\n",
       "RbHTYm+NvR371DpdynBm5AE57FtGFW0UtEkb8fQu3uC1Xc0xG18K79PDORemIg/yEZwRuEpKMLsK\n",
       "tR3e4Woh/EbOajUMDIS9LnTQtjQEOdRqTevcwV0kF9F9YUFCrwM824NesQWweXcFHh0vnI2S0KNF\n",
       "BDHuKSYnBZ4AznR7hO5DKJKBAAABXgGepGpDPwRkBf2Gz97mbYASaHLwSUkf6eqPcREQ3FszJIOH\n",
       "w9SFpT5HBE3LF5xZZvM/QWU50HBHSadK8/0Wkcr0wAB9abfq4alpdczhi1zCoZtOveiWrSl3ApRA\n",
       "ACG1PQq+JJfYqh3WSkgVplKFdUvhINd939cUasJaDuBH/uKm9WZjF8duh8ib76pyyF9nmKSyMK4w\n",
       "DU+jNWepjLZXG6faoeFmfpf/HWuJ6A6l8srYu6VklokQ2xC+TJ07CUTUP3G4Ps5MZT6GlVi/1zzw\n",
       "obmYj1dmoCKSAlvVAMDdbZLXCLk+ukV7LTJaeNJTpi3Ye9fk51VmSnFV1VWcQKjvFfajdD5OW7Va\n",
       "Trkgz/xVIh/nYGl+fpRQ/joX3Qa4P5mSeeGKhsK9r9VCvqscpBsq9yJeRXz0jybzo86i6T78AbaB\n",
       "VTjQRcnhhGc/yQqc3DO/uG5AdiNdk8fB3M2/l2z1AAABuUGaqUmoQWyZTAh///6plh5wDWArUcFO\n",
       "j65oX6Bti2qEVp/xQtPw5aY2Eu6SA+eZ8Aeku6V9lMY5GKP2C1/goIJeO5XqxApXv448ZGMo5Zo2\n",
       "XoBd699FE967V+8FyFwd2vm2zOV/vobyUhRDs7TAtKhSgvztWK+L2QZf7NdwYrO+iONcEq/+2rGu\n",
       "IMUONrigRkZSjuDgOWA0RDkF2JtRItUvQiQZJfiGb1xHbgKMoe9ahllxOOJUEHbg/xFoJ87IOgvz\n",
       "1Z1sONKbzJdJifLezJsl0gDm1IwNvjA2XDJCF4xjynQPT/w97vjam0ANqbxFlk7Li9IaIp8H76/b\n",
       "vslpCDX6NgKywyC7lbW5stFDJ4Y4p59fBBX6D0qb3Jx2amh4YAtFuk7TmVkze+BK8V3pIC2vTTL+\n",
       "Qq7DXQZV5YBWS9yp2Tk93o8yOJ1hdja8RHRn5sMnPHmUf17WrGh9GoLamQDmVUfHpiKYfcS2THts\n",
       "Ln8cSI70Z9xt0/3w30Mqx8B2FbTQKjBg10DfXIrKOG2z/1Tgvg4aEooVX04X/mNjuB3/Ee4JV9AC\n",
       "BO23CR2s+hixzSHNzvpfi4a/gQAAAWpBnsdFFSw3/wHtqpJWa2IlQAPCjAUAMurOeAG687JzThtT\n",
       "t3T60E79KtDaHHjugYaJtnBrB51jNsAxMUHLTULVKhbLdQ7BCFflLSf7UiZ79LfRLoIJHG8O421I\n",
       "ZVilxv3Oi6q9NLzMYLeVisZ8DcvNvdNi+jH9AXKzvYbxJKctsGAcUYaY0YPKo7yLqb56yunrQcZN\n",
       "asEg4pWuJAIdVMgmkvEfVIMgoQ396gjojli+xSv4qte9bGUt89PVntRcfolJpy2FpLnEFyPeRZAz\n",
       "ECsVZ71iBEYTrZX8yvTspgxtp4fQV2dDUkdpJU82CMHXyNFwzAzS+LioVB0u6igpvpCCjAYrxYsJ\n",
       "bWoDpThmdNyNoU+iwCfqC6+vw7cKSbyrmufH1S5vR8b4ENq1u1hvUwhqRV9GJ1UiHy2T3Qg8FITd\n",
       "YWdcOtV0osJTj7ekZonKXr6l/sn0WYZSc8tYyZ9ZQj52EZsM1OMes53X8QAAAN8BnuZ0Qz8BgNbF\n",
       "z9lHLkkrxAB9bf1aG36NjQv/IZGQkwWHzB++xoX3Mj8K5jGa5yEqa7KFJyZ57Y8NlBAb+PgeEgxq\n",
       "GSjnWVsYdE1jc9s2BAw5/qFj7YpYC3QXM4nJ4pOof56OrrTEuqU1Tz+fZgGacNQBOvxdoAJ44ruw\n",
       "VPpBJk/OgFFtgA5rWpgQTUQK9l1z3Jd5//XCK+d6MLRWYt2sSBrB7+rCpi2bOIjFnMKxF2u3V5Ln\n",
       "AblMWsPQgFd3DCIbR4WEtC774rmZ7atdaOfyUZjr5y3sepO8k9FhaPBAAAABBgGe6GpDPwI9hsY4\n",
       "ZnV+SyJpEZMVJGADZ2CuWpGtG5vjgkIxFV+C7RhjqpVnZ+z7dFqgZFTgZfhjXpOU15Wsg9Xyc4qO\n",
       "x9aSfwqMNhns4ZMib8odxxNno0QRccRiqbLICId09Ptfg1NhoKQQawvmFDPdylGeRNN5HEpIJ6zc\n",
       "iUDGmHfxTJyK4ViHoxbnApAVBEh2NJ7nVLUJdt2JjiMybDt4AH0FYHN+57BE6s+EIvKm0jU5DOBJ\n",
       "wfPHy06lpMad59sce4X0UifM6paOQQ97aTd6LIVBhWs62qOxE7qblypnEd4F2nmqfbnFikVKtJpu\n",
       "sdjMFszepm1RT8mrvkm8SyNyXnAeeUAAAAGBQZrrSahBbJlMFEw///6pltbh2BX7HLX3kW04OWHe\n",
       "t6QQx+ez8cm8sB/JGZeeRtAFmQamI167La925FTxOBMLPN/7lz1W6e0n3leHy89WWA0QrzrRe7cl\n",
       "B6h/Qs+3BCGS1K9pttqu/I4ZmeOq97cCao6xqKLDiGf5ahmMgT65GsWhKBLFX4zAXFt6Iw/QCo3i\n",
       "07BVgpnJZYGs4qFaBLdCckBAHDuVEDz+YICSZ9llj9rjpCt/j4NvKyVYFKchMHho1zyHSTAp0UXA\n",
       "oLEtcKBNazI80vTo+ofEZAX6Of1Gw6nVO0iFZMgsKy9eJhD0KapwG2cxJzb6zXQivc1C9iJ37c0B\n",
       "NECepFzrl2lz79IoMxnzPhnYbsctVuuL3ELcoqIZ5mo8zeC9qYYH6BjiqUtqPDNGQhpXzh9szLjM\n",
       "+F5L7yz6mK0j99yRe1WM9A0R1+ErdeCChzi246DYPGqXeYvMXZMGjzMjWb7jK/UcQsr3CFN3aTUC\n",
       "aCa7pqKaZjXUB87u/QAAASkBnwpqQz8EcDyCuw9S1GiS2uyOvp0b3J6Rr/8nCmNwXRba/gbQo3aM\n",
       "YvxHphuSoZFRD5zfHqFTt3cUYexOLDLLiARshr3wv7wt0Lk1OceTWc8TaoHKsPQ8JbMG25NjSC92\n",
       "k6PRFmR2NipT4cwU+htW7zvV023kY5o/hn1FP+tdw6u8yL2xn0tkTioLdkQovQKUApdM6ADgQ372\n",
       "KNM5Xi7M7R2CjXmGPtScaiTVkG3l1CiWQ79okb6Y3h0CIWhWR7tNznw/+sUaMap3EC51+t/wD3JT\n",
       "r9Vl4ghZ6m5XA9CJUCubZ+yY+FUQm0gAN4Lq+JrxrEZj2TuK7lg2rzx81/d44yquP8rJazEWBHoD\n",
       "z7clFwPcki1XZkRwL/0p+8fq4PSKCp1oDxtknOAAAAHdQZsMSeEKUmUwIIf//qpVTffxgFJw/9tI\n",
       "v/RCc03Nx06n5vEvTdj/8f4k0upYBdrTWuLbqo/yVmKQPvLfuJaQHAnMkP2QKcyHMPPIvqKFKZF8\n",
       "2JlxNyLvSd4AeCY6C2QCHQqn2k392njDiGY5nEVxSb1e8GXoQ6JSSyIzWegqz2P7UTs9VKmtybpw\n",
       "T8jyYHIJW6Il/2EVr1jfsJOf13KAImgaxRIgg2tqVwZ31QrLUlveV7S4c88e0THHTAf74sPst0/z\n",
       "xDPttns4X3sbmwxHy4Kd+KsKmoeZA1t/IrJ3D3fFq7GS62xwI3AGL3wpRBQMr9aQvY1hOzW3K7gb\n",
       "gYwn2I6Kc8AbvgnoT4deNHyAiXVdnPyOIQ4KXOh2wO9Vt1dI3wEHsV1JCJ7fQtR8GqJnhvb7phmM\n",
       "iDYXUHE2Au1deeHcAqqXsNkp/7zkCiTCC843zia22X2bs8luDf8No5DKMu3/RYrmyyji6noJb0ci\n",
       "wGw3cL70EwdGIr3H4Q45FVjmmT71PiysCWwi7zZg0s5Xf2fuDv2/jxr7yS+aaiPWbEea94ILyIGt\n",
       "W7s8bgedetetDkskI3L6PGUm+ZXbbE6/Kh6JEmpGL80gLWy6IrOapMEfmQ14Q2Dgh66f8LlwAAAB\n",
       "2EGbMEnhDomUwIIf/qpdfM//FcSbQAZTgdjTgGdeJoPiBHH54CVquJTdqJVhjp8VlPHER3Xv9+zs\n",
       "0JBbB+I56dg0UOcRgVrKZ03QxMxq0BvZ01jUNxUbXZ4qbVVPVhKmAxTPGwNB6tOb9hmf15ttw9dt\n",
       "BHBw0qVM5rHNdjO/NQvJeIXEsrP8atEq54q1uEB4pS0T2saQQNXcYt331uIVjpPwHCwGJ+Xpdy8X\n",
       "2up7Y1+dwDq93c+QV71IYBpQ9mtXtLvQWIRnNLDNhKleySuqyXhcnl2WB+g4qaxV+GRtCl5WMTIW\n",
       "R/9oO0akiDGMZC5sFKx4rFSoaPp8oAEQonQhUZVNIeOboD4qwQSmuuVe+/2G2n34j2DN/AJTVYOI\n",
       "4YrU+fhTUcHh3nWBmuC5k/jDAd3BWK3T1kIMkqKjQwBtSQ10dI6wbcJCR8x/x9h0l0CUqDVD5to+\n",
       "DORl5NuzImoBvuO3RNazAOuw9lRY7WxXmBoBADFa9l6uXxYFfBA8jp41OT7VlUinkrc2YVBRatC2\n",
       "uAMcCc9Qs774WIuyXUVAg9dL+S+pUUatxczuPIpLABMBWNxnsCDEOchnSYVYIN5nWKKWDLZKylue\n",
       "5ZdAVGW4BUY8hR/KXbP+kqkAAAG3QZ9ORRE8N/8J49ARpZftxQthmx7dUAJYyR3qmoJ12Nj3YNbE\n",
       "wnEhB4ez2YAALsXiVMT6xsLLCVVdsi/WZNZpQTGdE24lXLXp1gG+BQ+1J8E+JmQmW5E+r2hdG4b8\n",
       "kry6ThLH/peDh20wCjpuKUfqKdPjYvlkraQ5h8NkyqT6sRombYtD8hh9r2N17jn9ZQs7QOdEMfc3\n",
       "Ukl0hd4BlkEN0Ywe1J95zyLnc4phGClmY3T/iG1BX0G+4DHin5rdXYjyJRDJEIZEuQqpwPrLwp2d\n",
       "Dudq2L7bfqp3xkKD0hOS2QsOkM5+moxLAsDBjtE+n5yCoQWP/jDt3WPhkfbuuv5fzAGXeAi2SWpw\n",
       "lHlv3+fDf3ao8aGLEzulKUKHTsfSvv+jFTW53yqCB7pTI6CGenn55XQhsFvfOgE08LjjiBbmCUI7\n",
       "zfucASFWXzy6UMF2FrNuuTqyG5+062BlxVBG5xIHV2Z0LOzAC/XuglT1MG9CH10f7oIo9qoNkG/C\n",
       "bVieoZGGlcmsJo4kuO0SPT+T8h0dF6U++Nj4vbe6sCEFNwGLHfhUR9Y/38dP8yrxR39Nvjyv0mml\n",
       "MC3fEwAAARYBn210Qz8EchwFC7tisn7LTNHZtc04C3nNZfxB+4XpgSG3Qr6dc9cqMSkR6kuJ6NQ5\n",
       "22DvMxsi39iaLQ3br5eGz6Kavf1C/vzz+tqPlnqmlipMHDXrcIuW4gkXpK1+i1n0LmTuFnfft305\n",
       "bsgkCZzbnJc5OY9k2A190f/QWou6WpIPnf4b8HOh1btzASq/AtwabwIdwcOuKmoLXtxUAJo/87Lj\n",
       "TJiXZgP0g5Ohn8NP7wOJiDKttAL7Q9YCYM4jm5arnY2k90PXv8+BeKGAjouOUFd+Xo4Q1d+ccO1T\n",
       "chyJ1VCMF+HLmUom0APOlXdKOZxuckGjDQ8tp65Pag9B3WJ/LCS6bxrWqA+gPGmLkruoDrE2CsAL\n",
       "IQAAASYBn29qQz8JnZ/4KQ6AD9oNL2r9vZAaYk4Jl/Nm/t8l4JtJiRVPjkVj4ZUPk21uVUjTnm6S\n",
       "LnzkiQUVd10BbFR5KNpTMoKD9hFJlvD9MLyhLsj5JIYdtEwXD1e9l6GPQqUiZODiW7UyeRF6529G\n",
       "WIMrI6DnZwPm3sLAz5G1LTaO77xGuDxKt90CAh60OrIS90/sq6hTi9c0jYo6RcQdRKQfSCyFZuKg\n",
       "9PgHUHFzKjfYWOd1h3ojGty9vDxVbiUxc6PzdA6DImRlsKY2PH2MAT/PtIQVnse8jv1DtYLri/rs\n",
       "HzPq+Y0CLMsbPL9+U+rpzxsGP4Mr4W5ORZ/fJBGHw+rH08c7d9jEoc2uuJwrNfFs9rY9EgQolWOx\n",
       "/Sc949AUi1nIZ7dKUuoAAAFrQZt0SahBaJlMCH///qmml/XxAM3RgEe43NymPgGwQLdLOPgel4l8\n",
       "oHyB9eCYC3lKcJiGk7sxZ/I+gTixGUKljXK8dvw+kS71B3PeSQvKUnMBbX5zMGA+yyEMsvv5NbHP\n",
       "LWlEk/eW91wu7ybIYFbA+IBVOFz3zSz/0ofYepb/hhbPFaMEyUAe26TCWpHKC8a12tcDAoPztCFY\n",
       "76I8LTbRY0+NxCUmn1qloRrUYrM5j1lgYCJoHrH6la6uchsIVGTcMfKzmo0z49GBHcdj7aRppx6O\n",
       "82bRJ6uzclIsRM/r6vkf7fwiVj936LpMFDFMeEYBWv8GT/z5nMFEimfIjMWfT3ozV2PHva8HnvaR\n",
       "ylN2OeZ3Jn3OIEpUTlEEMbhKtE1R0nuCxO9SNtlxIRCv4I/SGCpnaJGjiOREiyBpyMAp8BdNie5s\n",
       "14XJKbuUT2pDTN17PyMVJxMFvTHC76nbEuw2wBg1kI9E5a7sOE6TAAABBEGfkkURLDf/CdslIzCS\n",
       "hl5iF/eghQIEvtjH+AAhK2weU/bGokrobRf9wULTnT0xnkloOYgkO6Hl7AZMBuEOTsD1ZmTEokQp\n",
       "MO+UFOMYl73S1IXz7LLA4UyE6URfipVmPWkfeqlHlWG1p9lqf961j+8xiJd5OHES5RQFgE1wOY1w\n",
       "e+pbR+eH4ZnqYDjerOUH6vqBkwepHp+IK4zMU1OSHGCTqrv3iyI9rW83nQKpvjBidxK9vGxOMehE\n",
       "5I/D4ckdKRTnDKNRyGAsgISCNo2Zyw7NPra874QxRPvt/stDX5UYI90jECjpkZEJLemNeGbYzJwi\n",
       "s/A9BHc6kKUgJirZeLZ04MTBAAAAowGfsXRDPwo+m6x75wAIbxWp47yyYlUcmAnGE+u3Ym5icgzN\n",
       "GX0s/5UeBc+7TrXAZXgzKpFiBUD8wksdjtERBseFtZLTtSi4qc8yCGm2UBDKYPkcHnNfB1jCNbx5\n",
       "eDY2x/aMEXxIpg8zFSjvXp/V1GjQ2quWIbt87tBEmXBWHSsCyD4VGD6NrAGoUdMIAdohX2v32+nu\n",
       "djNDjb5/kEHF2iJAOzgAAADbAZ+zakM/CNsxh9CjUAIO9WKRd+Wb/sBO3Kd1OCSf6b28/N8fJGF/\n",
       "1QMPTW5rrVeqWed4ZcYcvpDORj+VywHsCU+e4YtlGnXTSJKpAPjuf7cioZM+6PnChtE789+N//wB\n",
       "SkHm8ScXUpHDn+U5Aak2NJs7d3yRBXSmOL+C3JmEgjoZH+/fMMWbWjybKEE6RKQmHVW+mJJQDzua\n",
       "vKAp2nTSn30DITpBeE54Vvj2JC4N563hjAfFxIalSeUSsONYKXzi3mqs52PImHY2M9e+7Btdrqpd\n",
       "THrn3lBM33dAAAACFEGbtUmoQWyZTAgh//6qXXGRQbBMAC6bsqvPruDvPhKFyTyoFv86iAI2+PrE\n",
       "bsa1WXzRty7+fIzzNVcAcxirMRXJxxxACvdRXb9hC/CduRC9fwu28clG9MZm+/8U26UKUOh37EX0\n",
       "YPSzPEDgc54RsFOvqB6f/vK+2Yv5M2Ynn2l0IMGuf49iUoBPbdvrZ7NJAA/iF4Oucdz4Y079miAc\n",
       "joFVHd36DKYrf97DcywgWm6ana6s+xKgrnGoyEHdEqKjnudxL4H/+uxmxin/NHk6X1dp0O6MH4MU\n",
       "BY7Qr84j1hXFjWaHwgokRn2MBqHk0RIKv46CAxnPo7pU5WlswdEqQmAqSR+zWxJQExFMvC0uYW2Y\n",
       "Q5YlZVCfqStTORtvC8lXR55B204R8p4DQAvLQdhEEaABvHi6IyPuey327SM1/VtqW9sMuDNzeRdE\n",
       "qMfWXme21M2Qii6KYq4rSvg1tzO1AvCige6rUhOPENnKcP17q6WaA0kA+1opCrs0L0J9/ab8dCJ6\n",
       "g+Px8JRZM0A7wu1/tM072pnhwXewD1BOAzp1zSH4ofkC+TrRCrJGBvEEMAMiSao+rHVZ054+ELAv\n",
       "eOfHq2PkA8cEjWuDYsyNssHu8QNA9dapuDAk8m2JWCX3jUEqAfknFAUTcBfK6D9h2+gvHl7EWU5O\n",
       "wWp4cwLTsUNG1zyrJL5dJbMn9B+iID8yd5S+QNx3lkEAAAG/QZvZSeEKUmUwIIf//qpceFS1AULi\n",
       "mjAASVHX8b6IuYy1g0BXz/YkWEu0e6jqaCov+bVHklu9GasHqfdyhqiQQUhhbp/3FS6kqv5gpmYw\n",
       "9qPiw0359NV+wTyjrm3bZE8r7Mz+HI1irBzRSlZhSZNzKv72AAbFtNC6NowCQqHOE6MZrt3N51KE\n",
       "FmQ5/QieKx9yTgoVZeFtrZEjUASLqAzZgbSd9JLhb+ZEWWkMWV88WfSQ3SIc6rbEjWb4GKz2Lv93\n",
       "+HZRQNhBQT/YIeJDokgMP1bz4QqPgKTMd8ZVZeXr66bGCop3jP7p8HRYW76JRYtFJw0qQ/yMzgf2\n",
       "vzgCgYQVd2KrSzreEHujufuCqjEOKbXom794PDKEtk4RxxPikjP2TxBJLHAEybslnVQgDAZ3sf1B\n",
       "9dfnsASD/8b3kuHkw11OjWdr0drwjMhtoDt0y1wEcX9jfYhkfWuumXPtGScfvTOMRjlNh51/aBkD\n",
       "W07H9j/aNxANbN+yOt5cV6BYvYikvarp3URFnghn276JkkYo5dgVIMs4asmzDS2AAwFmcAnnj8/U\n",
       "dL5b9Ymq+0W90NP2UrITDWvqbWMVTr6pw22AAAABvEGf90U0TDf/CSgX+Cm/AAJ1Ox+EF+kvbcbU\n",
       "Aro6hGTBjN1rFqcxVtAtWZH0N6BsSdy4ibWzXu+gsFFUPJOCkoi30OMYltUk8v7+M2El83+dSyFD\n",
       "0+KdZEKg20AOm0BkXCNItvzXlV19dmH3hbNkkDg4MeLfN3Yp2RSDA9SVUYmV8Yo3wxLPm2GhWzKJ\n",
       "AZRa4iTeuHtaaJYfzg7Bob0MmjRSJvOKC2xMLXlh6Rv3egjATctriQ38TZALl60jVc0uGAxYQkYe\n",
       "pypaAvAbLb0qTY3+D59TgXGY7O0bv0/loeWC6WNBmED1zhmqSg9/iM5jHO/xL+rJBUyRLdrDk4Vz\n",
       "pJeoMF+SVmsGovfiaTaGEDi2u76qI8P5ZL2H2qaozyK9Eg3seKlFpGgj68drueq3h8ci0uuCxjnB\n",
       "luLwHOGNrA/PvNKXXjweMAAf/N1pGSW5mkhsGqRblb0vXo8NW8XaHEwta1D4YIqjGz+WlOPbzi9p\n",
       "EMuK4KmXKebNcU/sDogBq5AlXhtOT1xh6Ok/r0or7JydrypC4JQTpFl7FoJ66R8Il6Cw+dtUSnq+\n",
       "mDl6eTjIWqoTNCfF7t9vwMgKYQAAAU8BnhZ0Qz8KPpu4YdNAAIb+KYTxmMMcBCWt6B1W/VaXh4zh\n",
       "v/sxObXuiZNhnxPRer6IHBjWng1EY6kLPX05WphVafP7cWEEwu3tr+mtMoiIbk4DV/9JTFFBLyul\n",
       "o2RayXbPC4L13PwuDqefikY/BgPU3ZnUbtpKD2L33UNcAO43/7i1cdkEwXIdW9xg8+XzFRSM9kao\n",
       "XYvU2m7l16r+BEiGGN/WUr2Ori7JB5/N4g5OTR49TrRD8sq6MeM5wluol/lVmjjRXSW9EH8LcxFq\n",
       "L6kCteJooL85ecL0DqAZv7+CCEZYq89+SER59gcwzPMSRwqSbqmkkTYSSyPlcV6eWvyi457eKQSG\n",
       "XAzEh2SKDb0FLjP2bTpn2r8RaNxVbu1v6XVegB4mZbC6VK7WwE97V3/HEXS/LiC9JW+jRA2m1HEs\n",
       "r45LFCsbEG38B8jURS9vWQAAAWoBnhhqQz8KVaf+D8EEuDcjQkHm3Q6FV6i1wzfjAUn6nT5LL1Hj\n",
       "Y+lUHi9Ipfcgq+Lbz73U0VC9P0vjDgdXLqvWITcuV1sZ+s/e5BoJSu3Ih+/ZuyXDi8+1BufQj9+j\n",
       "JEzXlUAlYFNAJYwo4dTVFJ0SFMwYmLKEBKXQh4lG4gLB+Zey47Z29iiRZfk//3S9/GdSDLp3cA8g\n",
       "UQtnvhVjjG9G1LS8HAgO5qE/K0W7ZqzjrifBDO8GHnNNwvB2ATuWZhDenKCcbV2Q8vjNI4B/i43s\n",
       "9WV1X604V1L2EiiNYZ67YpBefqy8xtvDOKESh/UHyExhXZHQ2ysGPCMC8GTd5d0S62Z9u7kzXQxa\n",
       "eyXFxsb9VZoVSgae1bRqXB56IXnB1DHXMu1f6Kl0HUuypBWhNiUNpCJa1W+qyPWG1fI9TTi1gmXz\n",
       "CenajG+MDUXAUl7ZBD16k642IH/8Koz0MFY5VGHDFuPnTxFPvxr1RgAAAfdBmhtJqEFomUwU8EP/\n",
       "/qpVTfzmAZPAJXV6W2k1JrPjjLK72zDlGWe4N5SYloIth///tQ+tuq+I8+WRZNQy45UIMymneH9U\n",
       "Q/T0ThnPa4tvMldGc/ZuVn2JMlP4/UKAlDnS5jVobZXNxsf9roQgiF0S48LcWrStj22DqBvKY5y/\n",
       "Xiu3Kb1hSbwgO5ECEyBbWwv0F/dyE6thnbOPXEESdMFH8PyUEyAYI64OsJVo8P7XpGbtQdp7O2Ol\n",
       "G+lPJeWZAiCOuz04EGIgTpHIwq+MD3m99lfGqmLK56CieQTGwsvhMRv/tAja7UjRiPcwBUp9QTyO\n",
       "AeIyTS00qg2wPq9dp1PuzC+4TQUSGNtkItgIOwl8StNd02MnQX8URPEcyf2lURDP8Yatf3YHeXbc\n",
       "GH89LeH7nFmp1biyQYaJjsU6UHYvThfcExv4jFU6o2x9jboA4XTk7DuUHlr0wFWumN3gRENmh6Xs\n",
       "7eB949naYCyri0JLqGxqSzJBliY7J9W4D73kfO80JQSKv2gwMqHsY7DjMpFdSvzGo0eAWX7DH49C\n",
       "WIIzfnHz64rQCha7d0ZYonBa5wRihBQYQcXPbVqXY8ANjS4gVc6zd1IHL0XpePSnMC5GQJdsGZS9\n",
       "8s62L9MOwq1W8qmyD5GurdmjMU9X+hPjLiMn2l7BOzchtwAAATUBnjpqQz8EaXcIA/0/2JX9YPzq\n",
       "iI52Kazzzn/9l8kMi75Nujh2/S3Bvt8wSm+96egYwmMsnxkxVeZutDYH6tc6+idSbgq8WT9+Vpir\n",
       "uDwDV8aN0f/9ax/o8lAijRfm4D5kZp7YXFFweTiwub+T76+Bs8G3WBqlUOzuOgnKyE63o+n7rjKV\n",
       "3kQxMS+vb/yujkOgVWKqAk7//maj/Fl6M3e3TZIK7ELoVq0VdNDx43iCtbIp/D4GSlw6BCFNRkTA\n",
       "mrms964O5z9ltWDUXIzPJVt8I28FtVeSG6KRMvEYDGf78bxpseL8Q81c4XEdGHJ51MO+vNYy9kgd\n",
       "KC3N3sw1S4laZblwfOoyuHkCvakkfhQbuvZylwgQFE4mjBxtmXEuyyYyhkWIZSxN92dBI3O/ZQHQ\n",
       "y9Il94AAAAHvQZo/SeEKUmUwIIf//qpVVWaAwqVXwbXqhZ90wHoCsDfEKevy2NPL04jV/I7KFkyW\n",
       "MjUKqe1N1NR6onkGlu/acAuGXxh3WMna2EWQ/Oh8G7W8MLzFmHbuXISi6NzljLxoIfuNcDPXUBpy\n",
       "LXxMv9dWtpZeXgt4LstemA8SgrJkZ+lisr8DzZNkTrTyUZpD4CTbKNFAnojVWCr4XpSCYZPTRzZY\n",
       "7CO7nhvWYczZIJItd1tBRxXdrwo9DBhvJdKlsqEQWUizGmBPOEOPWFBkgkJxXlKGYN3wxr7eO7fP\n",
       "y7ChiI+3yYne02q3rn7SeBpV2Z/e9Hd8emaFKqoABYNiyS38NItFo/xqSZwwbzDeRho81HYAZDvO\n",
       "DHz4Vi8UFqV7EAfKXugSyk1Hfk/Xx+kFLWHxGSmTKfwMTjYhyUt1Bceap5PMEOWJ/SpwKoe1QEOD\n",
       "N4y8OC/zlsXK0a4aTFrgeBNk7OWiQd9K+H4PV/91X5CBZtjbAZpJjILdgUZ8XdQP3TkT825qyrp+\n",
       "chFx8phfDFGWcdNgoUCf2bQLzfA4T8HYrnKoJmvkYa3x7UNDH8tkJEOE+Eg9FMDAr/egKVzuz0kv\n",
       "gKBgptLbbKtafS0es9GlcdEt3cDZuzJz0mQrJVX2gtiRKu2/hiSyFUO29GcNbSmBAAABSkGeXUU0\n",
       "TDf/A+fpEtJiOrt2/3bbTUv35rHGOB1+5JBPm9gSZOYK3icD0ikvCaJrH9TKZIaWQOSzXsNZAH/P\n",
       "63RA1Z1c1S5g0AIzl76LKA19fHCg4tbYSfthqfXGBebVP1CwL1pGsMjv2mE+VgKaIUfXq6FhAqfQ\n",
       "gRUYyoX8iAzfUOf6RW0idXnP8xpDuDleI+UJ4v7TM9Tbn1Vj2FTum401vQ9Wf8DemsKo0pGxJOeF\n",
       "dWV+U0LJOCTDOUYI74cnQ6X60PFwA30whFxEahz86BLWIee3EXA9hzsCn14p8zDt2eEIOLEKov2C\n",
       "6fLIfkPHeLqsnS5hVhOyUMZQHLfS8HlPmmL34kzEMg1R1cOXxuYhF5HFWtMW0kvXPX6xJKUCb9Sy\n",
       "mrnQV05nDd1GVcnK6AsNPuHhYTZDHSCsfyMW1yJDnRtWyYjUslLZowAAAVUBnnx0Qz8EZ1JCE5J8\n",
       "gIRnQ48VrtFM77PKRcQBXDbHeL7H+D/2OgZLT+7EAPH26zW4Sl0wHk0rElB4v+cRYNoNih2KvnQA\n",
       "9BR3v4J1FBfH6HeIYD6zTe23p4zozo2S+DwTfP7OtvAndkmpJMETJM5Ywkqyy8Uq8NBp+TANsQX8\n",
       "KdIcZYLq/BCdYUHuxoaoG0QVXG3TOTFjxtcetmd1zqtQ9KB331Pegg1fZOa/4zO/o9WxpVpzWqFD\n",
       "Aadx1S05HIjemGy13gJelq5LG5yMECHhaqr+POu5R22H5tJPOPIAXRXYmGLKBc48zMKhqIwmky53\n",
       "4op9Tf9J8lO7O2xNzC8DNx7zrOOFd7ZIM+kuUvRrM/1ydJZUmbO/IMyhBfui+YuCWsGfTIC9f3RG\n",
       "+GaoCiXQ6R7Orux028BN8v/U604QIb1tYrsXaQrBKkd1NRHdKV+Vy5LsqAAAAV0Bnn5qQz8CFdnX\n",
       "SITJWOWwvhrWpB6BxTO5F1NbofsDmP0n+QUqNuHIGmxw16KTeRaJVClHIaKuDGKXIS/wO1XgRplp\n",
       "UPRrU+LZOxtOT/oLe1AqXMHLDfBlRaZBKJkWLeiI0T+rIsBARNEUldfY6cZH6lapESvZoXZrqJin\n",
       "a3VR41uiIkPpt+DI5ujYbjVUTafw3BV0vfDv6RqhGdfx7k4a7lz9bZgzpn2CL7ecdfUa7amtR3y/\n",
       "EBK/gRIQPsKkqPBBhB5RJaePvk8Os7WIax/1pqGXAgybhujYc0/qj0DveMjFzLFBRMhiC37uagRB\n",
       "tC7DnVmELwSYY1XhElNzh58BUh5U+PDDHAZuNd3Eg3CN1ZL3a6kAiZ+CwPipc/HxSjoHxOu1K1E+\n",
       "mGY7v6Fh0OvoRKGEDiCtED3Jc5b4CnYrWnF+lHB+U0MDnkmNHJw3Oth0hvp6YA7x+cxsSn7WAAAC\n",
       "MUGaY0moQWiZTAgh//6qVTbieJbJgDlhdsu8La+m/9GclR+ifUTqNsaDwkAg9+h/UHI8Gcjp8WzR\n",
       "dzY7c9B6ziP1axbhLcFub7PjC57Z/F2wbyBSfzALr/qHtP5bo0C+fQMRU+sVlOS9gBPqai+ZTcBt\n",
       "O8CnKzHnxmuzMUO+jId4cLBxzQM4Gz8w83eHVWT9Ug658Mn4qwbCtMxSYRFEI9tB7n3Vz3cMr7lL\n",
       "vBfEIlgGvOMmsCUFCNAtKFsuDq+O+J1Pv4rdG0qsoIguB9jqYcTZHBDoNzaHX6/n8zCqdZTPSNtG\n",
       "ZZPV/yZfSfNrOOpW3qjD1am0I1voZ9Qai0ZodnIrTisvQKhkDlNHUx81qhL/YhZ2/fOO8sy8UORx\n",
       "qRgvB2guwaWrjCt5sBw+avExcpPZ7LRNc2qfnRRO7DGsbkvxeiUUU69mootYeqmrE+Kz2oHHZ0sh\n",
       "uBp3YhFBbBRYMupKEvERK8okVZS5tJnN35lw14vlM4klTP0jYqbiQMRCFdcRubsOYi9vr+FBzFtX\n",
       "c0Vf49G0G1IwDBVEOZxCbfVQvWbcXHpONR6Hub804egVAnhBlL+ZRD5JmgAWZp8yFmEqXNS+0eE0\n",
       "IRjFwZEmMbmIvNoEwQOkP4epQUSaA0zCbJRl5v5DkoI3Qn+6ynRSig7o3nJfBizX08yhRVzvsCWX\n",
       "TD6oScvme9alyThpOeo28D68/NilH89S69+rVYncpC+wgut6CfD7VqvftTPmwc7StQAAARFBnoFF\n",
       "ESw3/wN99AQZYMGU+6evoAG9UclIIQGy0A/yUGyr01XVLTWKh8a1I5ghxaiztsAigIbIRUsPNSAl\n",
       "Y6zCkZedPecvLT6mBv7iP/jVCi1Mz9RS8dxs87M8P40JxlghiFFsQn0T4htPmHrtshezqbBC0rho\n",
       "QLUR3nbmHQD8SaUgefHkKu4nz73jmQ9aJD2yDUikM9N8fh58gpULLJiYmeLXRFFppaIeVMr+7h7h\n",
       "IAZttZpUB+HKBx7RhP0xz002KbMk3uQ2UFUuiZv6GHjCfgvQV29SfH6yMOXZ/qm09gvqT081GIYw\n",
       "hjrIc3srHE9XMDF38/nVBcAqEqEfYMe9fKgZ87nI7WCZ7sf9KvaKE1gAAAEmAZ6gdEM/AeaLP6AA\n",
       "BDU1nc2acTrMzsCM5SzgOx5K9OIfMeWPj3+vAHcPzj87kOQeAlgutnWAQBT8Mm6LPAN79P/g9mKN\n",
       "36R26LBbJ88k1fXkV57yEKoKM6Gi9i+ZTtTRnN7TFN62Q92zbZ24Sz1LxLvNfTd9hs4VBH/v7dWy\n",
       "bYHRc5cquVtyWHQC3wo+sXO+q7vmxMbU0VrXVF79n0Jq4ebryXYqvgtfx9YqnvMfkLBLDxby98cy\n",
       "8MfmyGnNsHYZmQIPZSCD+ne/0uXDEM+XVYs61cXaf/US0NPpkQnymO84XpqorKzwHop/DUGeAfkB\n",
       "Tvdd3sqNbN1tc2Uh2kWM77uzs34qilHu7P9/+F7C+WNsrg/vssKsIaLIlPno9524DhUe+2iBAAAB\n",
       "EQGeompDPwP3iImtvyQAr9afrj90Ff0qY/MjdNXte+ZAknoxa3ZRXP1GWzyWUfm1CNxMy83UimRJ\n",
       "ouftPkP/6aE8HjhE9r52sZDs0qYElupQnd2JbtACaNaQ2AbSlHTXsrZAn62cis2nsF2xTuWhy6kz\n",
       "5RRg4NSu3wAHMlxwBQQKe8Nw5tGafvs56o10enGc9ydHwAX9j/AVlsIdYXpr8tvfqejou4iMxHhR\n",
       "/o8YUfmsw0FCXCSqaBzqlxGlBM207zByAJk/fkXqLTJAbjDpNGyglFqZn3pa+sY1ioo0au8N2t9W\n",
       "RbyiDBBB/4HbaWmu5l060vd8u8VnAG4jbZacNWEEvccWxd4sRDdhndbEaoTcwAAAAgJBmqVJqEFs\n",
       "mUwUTBD//qpVN3FjCAKQyo/o0vJNhgb+dEHizEMVxdtvHu4/vuxonP1Vl1XZyfgUb86Cdvi/Bpvi\n",
       "dkGqOqXsc8XWQYXRAs7TN6KWUEpc69ajur+i1KAJtBjCTApgswCeHCTFGMUaGFJKDVd6sugznsqw\n",
       "WYvE4VFPY/wkPLxnVHseXXQDaDQ+tSmS3XHreATkO6YvH8+32kgauAj6FiZjdELdPfhureOsD5/E\n",
       "prI6l4jsy2M7CrVy2xgDD4bgGhQ1wS3VLfoWWBmlhnkrU4p31e4G5AGZ6sVEURFrVDueZfxaTR7t\n",
       "3e/PZY9EmewltGVmt8B6b1EnoyGRosI2p5CZz/ju8BphuNnXk9L0WlEAED6fFy16g2ppHlaujVj1\n",
       "Q78iYwuP+NcY6mdDMG0oYcEWLV8BbqOsyB8uHTEY/mFcCkSuoJ0O/JXsk/EokxUrtFJDkiNgocTW\n",
       "wdsN9aqudncQ2cn6VLNI4mScspTkXIfQf6hgxLu3UuuyCGT5Qx14o94i89eEBPxLxiSXucDQolaW\n",
       "S3tyUXVIe4xEV0bqg4CW614WvcE+TjhsWP6qG/EcoLwsKW8v22h5WCPioVqgzWBPtHwQsvQv/IgP\n",
       "h5OjtcjdIgpRM+p2M1MuKVxhiKNCWlHqt8HIHVr7tQ02fqXTZqcCpdnU3zu0mrFKV1ODAAABagGe\n",
       "xGpDPwQBByALUNW9xm46LcML7kUhboNPO3+5Pmk6vNCI6x+ykavQBQz5+bfTpdyS03Ea8vJ99rmz\n",
       "FOEkUj4tab+VXZDz8po2FJFcFCtCEXx3F7IP6Qo+Q96Z52+ssKuIGvovcysmFvF312ImYxEumKrP\n",
       "1IV1Ru6BRk+DBPnBfNLD3C+n3CWVLPg4rXL+QbXylW6Gn9aQYGEaWZXflLs575W1nB2bKwCQJTGy\n",
       "xtjcHLHHhxiOzsbZiZqhp2Wt2dpaGiqtAPOxl7SsxXI5efQTacrG1XlOr6KdUgB7iYbzNABet8B/\n",
       "Bn8jTaPjWoLzfenwiP5trJki7UGOyf3OwnrU3I4rovdImXW4e4IWXIKy2LfNOR3DBW3s9ZVqgX8h\n",
       "VSaq2kkDbbxQnT+X1Qb+K42RTFnIbCOHL+kiBlmiuYp0/RwVQ5PEYsWh/KhGHKHzIaRT/fd0g29j\n",
       "UHt9CRg3vpmOO0/pVh/90EKzAAACEkGayUnhClJlMCCH//6qXXzP/g/8wAXRr+x4CNJKBy9efJK1\n",
       "+NTSSphdY3iHT+VjGU3jjVYL5nS5xEmKi1+IGFuEQV2isiPXHkI/kiE2r8/QbwAGtllI0DJtitPl\n",
       "dEdoCWETs4umQw/kGioBMHjr/iW1Nf5M6RuqderH4E+FuYeuxKiUgrKJhfC6GpTml+VKKMTKwQFx\n",
       "dxTCEyIogBt6iUGboYCf8fyDu1ZfaS2K+8sEPBGNFwhthUzJEc8TbUfAlH+DjY3FFTS1S6YqlBKa\n",
       "7liizj88aB/4kauItVZFkVJijxdOwyiVCZmOWQ2eewUbbmMPG6V8w3tTA7urvQLNKwvUAnk69uCD\n",
       "w2tr1wcVjRrzm0ktsB9uAX37yUekIkbBA8zkbllFkxJgT/ptxa2cKGgAve37+j4k6cpnw8DGp/ZO\n",
       "DrnuqpFm9Xm8ByzeGuOWZyzivCrLtKBfFjFA1PPSTVShWPaWP9/r7roJSLgJhtvsuKtQf2U2EeWp\n",
       "lI1Pqcz42N0DE/hf3udvXDZKh/9LMtgMLAyBYBYAJL69biIkctLFnXQ5LaHwkClUX+BelWekPV/b\n",
       "CY/Q6VVd1uG68rksd9K5EuD6ziU1zf64ypd093PvM3UusCFMMRnFXPf10ahs192d7TyZIfmRzYgi\n",
       "2ZgnDYkPclEghgS2TQqwIHOLt6E/YOL1JXICMGkHbh2mMBfHRCXxAAABb0Ge50U0TDf/COz+OfaR\n",
       "0Cc2W0K3RfJkknxsAN7506igR3nT+Ap/DXK0UBlikN6txjt1ipPPVulajbx+6Crw7eQzXbUnyTJU\n",
       "/0Pfn4PPBcG47Wc7ymcu0Rd3PqUTM+mZrZ3baV/0w/2ANqmO4DFNdQ6oh5v2kuSKD+YypW5hst+T\n",
       "MK+hNxpfUlH1WF/fBZPtTeOyD4mOaWE5egbtURoNV2GHywoEiEs0Nzav13mU9g7rOVDmxX2p79zh\n",
       "W8eNUgg3MUF/w/51Gdu7t0TexpnGXZOQaWlmPbh5mk37lFgdtG5RJ/m9eBz2xImaTxExK2R4x5xw\n",
       "JuVu2ATB7kMb0DnoxznjZCecCLTOv12Ceckvj7FzC6kwK8bJafKu1P4Jcu9+7JA4i37MBYw0Dotg\n",
       "hEqjX4NsQYX9c6joSO8rPBPKuB7flpX0ggY+LAf1gTYJpW2GVfv4vwUZSbwlIOLn2j369j6+PpV3\n",
       "IrFw9ZavjJomlukAAAE3AZ8GdEM/CkzNckWS29SInSYdgDgAtcaFNMv5WgWym+TTCxJoB3w46X5i\n",
       "HPVRUQxU8+BbY2D8Lb/NLHCdFmyI9ycvP/rxIxfduAjphoYiLheczLErwrpJ/lxTd2kmh46bgdCE\n",
       "NnhmRkvvvdLVv8WYz5qJ24A/vvhlX4hmVf8ydopwi0MoXfjCeS/+TULwE595k/lJJMGVCrbLt3tB\n",
       "0krEDqDfRRrH0ZfBCa9/NtYOWMvPTEUxhpR0yf0IlEHVDXQ6SPc/FO5AzK9ec7wWM3QDogXzo3it\n",
       "c7RZ9nBvwoinJgQgHRULzmudRJZLZ+g8L1rKbS5odWCzqkzCvBGI2YnQCLKOYTtbH4dmBPeHGtm1\n",
       "Q5w182c5+poFD9djqgpjH239Ej21h9yLylmhFS3XVjCfPLVc1E5gWeAAAAD5AZ8IakM/CleRVAB9\n",
       "F7k71tTnc6HFu0b6I7JwLtMjIuPAF/si+cPJtBgdHU22HGE2WA+vliCNB32ph2sf7rJT7XgMP6s8\n",
       "04XSjCuHKEF3/0jhiDnjWluf+Hq/wl2KS3IjYHNg5IyDqFUs8GKFvcUVgyUa59p8mvVvzVu8t/Gy\n",
       "7J/YAAPZXpgSCT/P+ZkMnrNRsoFljDS7T+iPuMu1kPgsembQAPmFuoZYZ7ljHXPqUols1O7Fzian\n",
       "BnDdudHKH2jQXMD1HpkUioNbPCjKMm/F94MqcBvwd2uQulX+kpJSyMve9nEZpKZJ2uW1kzNQLesV\n",
       "v4aQ1QqDZHsYAAACFkGbDUmoQWiZTAgh//6qXH3Ol5TVJqqAVX+OfeKeNHx8Qr+vo3p4u1E8gH7I\n",
       "yGONBNz/8ngRPGatVOT/e4INfNC7AHK506D+QlF33z75c07l8fm6DJ4kA+rWZm+/hfz3v14Ujmkf\n",
       "4w5Y9HVNMXnDWwjU8j7EIN7QuR/9t+1/V2DVUPaXx8abqh0cQyF8getzSH5gil0a1f9AZWdygPyb\n",
       "39DKqyDREUAzVhMroMoGXIHWhBp/xzHCaZB3EPpnchwEqrNPzl1ypx7XlXzXbkkYoMN6NcdDBLoR\n",
       "tJYFmjGFEjiiN1qezXxDvo2LUkiapQYafvIdpsuiRlQQY40xIcjWe9r/JxyuPviD6fUL2OBKEpcX\n",
       "pI9579o7M6YvblyCByXLGouYULEr2uqP4kZyE7Cjs/BGOdB3BtONf5eqN9Q/YQmy823PxIeoMfGh\n",
       "3YZrvJEHKyoD6YEqPZUTtzKivwNWGsgwaWF2WLK6YF8CIf2mNt9tnepJ0TzZGMXlLsEckppYCvC4\n",
       "/kcKWkowar85Qa28/etvQFchF++gYbIvxEgRDHDNYER7S/17vFNnDyJipInCphqU+f2k/y6sJGTA\n",
       "29dI+mvy5B+nhJHa8reVLZ8LG7VxlrFuJQ15gZ8BJsGughsv64AbToHBAVvv3q7BdDLjwikDkaaL\n",
       "jhfQndVYiUucl7ZdmQMc8tc6zuFJ5rBynzuI4NNjjAyN7QAAAc9BnytFESw3/wnbJTerwHrs27hU\n",
       "i9DGYEBz+moBW16iwxYRlsE9m9/M2WrqeNfYd6I5LjpNPtDHDHrQLxymLAj97307paaUllTqO1Eq\n",
       "XpfUiu6DqL+gZyjz9/h9MXgqvbtOnIz5JyWByfK8OYo/IwQPlA96E6JgUJr+YgOv3MOEcbaCdSla\n",
       "Uf7f92+QzFkTsrIdZcmrBdN8tUurm3DKLebBpFcU71Y/XbdZVbRnJZqyZNUAt0JweZLYkDTguupp\n",
       "15h1X6Sdxfjzmx0nWo9dIsrpr1TOzAMG5D//ODGXBfbOw9SwzH9fp6npLYmwjEDS78VyUchd7Xf2\n",
       "B4IRwm+cFvVDYJb4iMgr0tOeNx5KEmrBSZ68zA+P3LAK9j5APLMILEsTsfkOVlcD1gvs99xSRozD\n",
       "xxPAr33m3izL7yIg+PHzKMUSFFDDSgPLvGbzPKMM7rQnhfH8bXacg4wvnOVsZekg1ghJiVXETs3Z\n",
       "rQXa1c2x5v0fhJOZodoo4E+ATftq39zXUSw3gN1Q3qMNkwUAlMRtEyAj24+zfFaIY+KPHVwc+o7m\n",
       "akyeBntEqOAe5Jn5/cj5qOqZScBymX6j/6RS7a3L9ZwktgaGRmzti83mvQ+sAAAA4gGfSnRDPwP4\n",
       "kekTXK8QPsWSs0s76RNrNvih75+ng6w4+Z4UFPFezjpgb0smGbmyBLfk7R06TrUt9g7xb9pDzZpR\n",
       "47T0RODMu2W+UIojsL1gzo3HCafsfCXECynvX3DXUgTTbVq4GlaU+fa34LjcG+MkbrPeFjJcgvQf\n",
       "1aOU5Bnw7Hjb/dkC1OfyMWEKA39AHaTUF2UJ1pYoSJhO1kkNEa2VKESXZ/pgFcJWLRJ2/sXgdZ0i\n",
       "bL04JX+okHf/cerU5Wh/buHfwx/p6C53oHg65nFx8MsCXqKUmS6eD1aVID4GFoAAAADcAZ9MakM/\n",
       "BHA8hOP9hyEhkdxNSZYNwlhpEBLvwqlLdHf8EK7KiF6wzpBcvVLL/O28cZ3eKYA8aiVJw7Hzv5/k\n",
       "4VF8g6Suh6xi4bmScDN3OTiw2MlV2T46UgFzlfE+aPNdvyi594bFQXuoWtLx9WqrHfc6JcLGt3En\n",
       "dMt/fw15SQC8D9eWmWPS3M60ipnh6Usy0q7Geb8Vn1nJRzrfkBGKGYBexFkT3nP0K9SwHJ+OPeXw\n",
       "dB8uJcn5mQYBPvcWxCJ5VALUZHF7rDZ0KvfMyfk3fWdg0W+OB3deKxb6RwAAAmZBm09JqEFsmUwU\n",
       "TBD//qpVTZHwAZv/yzB2+k8YWFPxGm2Xnvijs/FwEYg45BA83mLr//BLvzioBqQsmI9dvEL0UgsP\n",
       "cFPeQ83Y3ZkqN/wyCB6LpqnG1NPv/s11Ehz3jCnRPLri6AuSpyfFf1D44fFH1uInZ96dD7o9FshO\n",
       "P7y5i+EAqJBaDzyD3B7/odj6llsM4eKAaLWMqvH40QESjS3Tep4fMD1x1/4VbhsSesZmMNxCUtUf\n",
       "RbmW/7nJfsGUfRpzTdMyGacTHj91/dHjAitbUwb58AU7hm4nXjqlKyU4HTrefcGXJmbLb6GSJBBN\n",
       "zVWfwCndpZufOwf69WQR1XdnpdFezaQESgnBp63vO6+m/Gv8gifmo6jcj0FVS8EXmvlddZIfcYde\n",
       "IpnoUTVTfX/Uwr/7+21NGTdFQcBp8+W3y+KfUldYaCR5HOYoZqOe8/W+WuicTJGlch9rylkVBvVM\n",
       "JTZq9qzEB+9kyD9/XymYvvhXhcA1C6IlC24KAS4HDWHoC0miE+hae3yuWWjW1pRcJQIG0mon+iQh\n",
       "W3wk3xBJabG7Ma7Rb97IwCBGIo0rd0ql6mRW6N8KLx4mQumLV7Zb3/Pj7+jSKZMMLNlq4uhsGUL/\n",
       "y+up3JQQ9TYGPNmbGSX3KOcBz+vJPoZG08gXQPouAc1nq9NpjrKk0HuiGekvE/YbqMtUDkrd8p7w\n",
       "Xp996uGECBi/VjuTQufpc/G/4T1C5Up7lX8RQ71gGcX+l6vnYHsHl3pFd7CH1MH7c6+kX3cSqwNd\n",
       "N2bhvfm800R3z11tY4tqp+xH73ajng0lx8vJAEovX15S0QAAAXYBn25qQz8EBqHAETBUkkZC/7WY\n",
       "zSuC/0/WEYyP/kUhEx574jAL7INsyb3wwOEeSTM/1t2YewJpst1UThNQbN1xumfWil0Kawes8m/U\n",
       "zm0EO7TymU0VDxvj53yvYc+fDmMrI3c2x/4TTyvIqw++c10sJpqhv8/X/owyeci5EKhPntvAaTAk\n",
       "5g1fhZd1Fgm+go30/y+SbIIqgMCPRZcNpnASW6p+vTpPNwRukmv8jv4oTSoUOs60AC4Ul/msnaNi\n",
       "fhEqQeKOSJPHMeK4ewpRBIYjQyBCiK4UvODV3rcUyTpVDu5fMdppm9TNCZSZolCPxPdk8+45fNGT\n",
       "X4O60Z0RZb+JK2kzhKTepZQplObEAg2zftIOWm/Whzqn4d6sAbDtbWmcAeq2X5O4BK+Kd7fqBPC1\n",
       "ugpbAbRWjwAwsr08m+Urr5HtMEiip5TFEKE1D4bPrubc5cNkoCNhHMq/0Q2BN9Ypo9s61uuwIUZn\n",
       "X+rI38/SjRVx27Lj8wAAAhtBm3NJ4QpSZTAgh//+qlyII9QA1GgLShDq+Ad9tptvSRUkb/ALro7c\n",
       "iT6RwpPvAc726bZxfTzcO4UBMxKEQbOdZvsAZnfjrhRShC18nMo/ddJIdP7Z7CcDTEYVYWGiR7rC\n",
       "nQsEMccsD4eL1x0W9FVPIY+pkSLq4sf7x61piSEeeCiTG133mBjBOHbA63SBp4nfg75bbrxHEH6W\n",
       "drJ8J2R7FgAFOrBr2RHmkHa+TYQN9wNe/pAZYh5jQclPDWYdFOz1n7OvYGm1qlCus1H6P0XOI7ge\n",
       "OF4HZS8lY3IlT/NIC425w9wO2zlVHprV4LI+BkjbnVBW49dr3DokdtG5XEsvQlGGh9FbVbg3KZeI\n",
       "9xUaRFg4rPPSUPAVeBK4uuDI9JWkSNEKY4S9AXrkywvTS+nDpA9Rh9NKbqfaMeNRFWIqSVyrxQS5\n",
       "1GU6fdSoMWuSmvXm/oj7ArU7tFNGX/Btom1UCtEipQ43oLdOq3SCxlTWriPyVP1iAiniNqTDR/ZG\n",
       "QvXf1X01u3LoT3KPUkYNFVkPBTEeNNUqYjm16LxyopZH8KwTM1SujfXyuLPj/+sjcGRb8Pv7PqaY\n",
       "5fqH3qXGkxidN+LZQwUMPwDvajPiZD2kmRYVC15pozliMoQgxtZY1+DXqn1/LSbIrVCZm4uAeTWc\n",
       "mV65Pmkt4TZAUv/E3Zgu7QF1CZcv2h0q1Kvh2tUFuHO//MAS0oa5IAFkgAAAAeVBn5FFNEw3/wko\n",
       "F/gpf4AP6QjOT5XQPUo5WZUgMjDHSQLCld3QcMWWxNGqzLOsY0BWNyGTCdL+eI3DYpeg7NNPk+s5\n",
       "8+q9qzVeTbPqGGML/37PfbwVpuLq8wPLDHC5RIVDKy3zXc6ocJl0W33K3U+jJ6v99duelW2ApaQm\n",
       "hAbZdkLgGhcK7dmieFU4S/6qJRgqeGxPTIZuAhLnjk0/1vmUxhvZU4aEfhXR8nyIz2z6TJek2B+7\n",
       "/woNtHaztkUlhb6QB/bVAuIUbtWUkEdH0QS0lNKWw7Dbd6NQJ77pE3lH86VagnxqCvrNXVlWzSRY\n",
       "DvRSU9IOvVm1onB7GVsvsa7huqCdLzp1qesP7Q8kKlkEV9AIR/CSCKf9nTNoOfUW6ks0BGOjVpfR\n",
       "Bt55LqzW3oVqe6+vnhKYf0Yb1AG15TMbMN5ylL2/ORw2AT/5BK1mOAK71pcvxwRaLOScVHQ8aDj/\n",
       "+Zb4ErLWQf2IbbURCaVVHjY8oUujIZBnwcpFAI+NTt3Y4CMQnZKvzcsZS8qHJTehdci9oK1JbpX/\n",
       "aP0mvVbcV3wS6IeQpB/xJR6FK1OGSTWcUqueqgDBVN3RPpnGryqh+akXwR53S8xuCVtl9IVFF5mr\n",
       "XBTL4l6yqxtjSgUJeWMPUrbtQAAAATMBn7B0Qz8KZJIPWODzwEEcrtZZuvQM3fbyrWMdYwvDJGV2\n",
       "1RmK9EeEvtyQjtzo4jjffre15weerZ+fCsu75gRRm7M/WncRKSEk6oJOhnurisrv+VtPUe3HTD57\n",
       "mvg5bhievABC1stSeMdlxSNGQ2hmJZ1weYVvpkltW4YGIodDvTqX0udTxa5+F1N5vm+j3vcwBcFX\n",
       "bBpDAwiC85tWiLnkGY/sm+TFhJRVy1kSVushKYQ/+q45I6MIz7sAEsr+P2BKJ0IKao5SCm9/8vI1\n",
       "g+6bPI5cwtb6ptBzL/zeCEs5HVCzX/h9BISDq8MW/VFGzGzIHh1SLptGuuzOWZUjimPbYCnE2hz5\n",
       "m6HodfU/CdDm9PJAjfAjAZH3kdyUquIBhm4ixhjXRxeuTWZ86CQKoigV4DAZAAABUwGfsmpDPwpG\n",
       "6A4C7qQAmrmZHi5l8idW8sl7aILi/COjNyld708Ls26CsBnHGaHyXgu5kMU/DM+ZYCe6Vr6MDatG\n",
       "W3cpWq7C4Nt9IDIfDUiJ/ystTs9E2OnsmuOb5LChU/3twdQ3y7TcBDJjTyawn+d0Vspuvi+Qy5Ju\n",
       "IP8Yf08RxSpelgvN708iR++lKHknH7wpPyMYiMinUUgtT49tJWsqBY9jlXh8rhIlKJS6r1f/L63H\n",
       "lD7Jrtn+T6qZYWEF2wJQgCPOUmqdqK4qD3ogTgOZbRzELh5XqVOk4OfZCUjLVNorwKebQpIu+rjj\n",
       "3HYRrvBpPTC6F18MSKlS76vC9YJ9Bp9o0IANhQxMx3Ndr//iBRQiXAMeCverX/BSzx/wPxcKlauo\n",
       "TAbZ4GBj88k/+WtIsRkmXWQiZNRSQEzdzkpB/2SItCm0flMH5bnWaYUJGktuwAAAAYhBm7dJqEFo\n",
       "mUwIf//+qZYY26Vmn36V5cCGvY2+xnXMd+pKWX1sn6q0r7k0T6z5fy2QcqVXUGdbR/WR1gFmPvqg\n",
       "VMxeAhlE33rltBhnFiGXahythEA56pJXP0rYc55EadV3vOAe2p2/UgQjsgVeAdiV32XMiiHQiuPh\n",
       "NBM9+TOLah60haGE+3NOK/hFjsD9U/6vHsb47/EEUl7FIJYypvqb95166QKpqoPKkQHwnT+GpgiO\n",
       "4ObEGkSZwU93QXoan7DJVPfUq/rmuH+x2CnT1PQ63aNNTx7Y+qxc20mdNnmd1UHQBF1w6ovcX9jv\n",
       "ljrshsM2nHSBDTR2+5SrnuivUpknHefhMewQ6sBkEUatkpZ+x2wNs8Ck0vqQRJbCk0p81/ffuvVp\n",
       "jhRILvCl73GZJlQa7E1VVLUsP3OHsmqVPsnPM1RnLhFkXK+3/TKD9WgbCriQcfBZR1mVoynEWYQj\n",
       "usBPXjjJb88KYoVxkwgvsOJYhWTviYZ4L7/Oud1Qi1oCEw5PqDVvNxFnQAAAAZBBn9VFESw3/wnm\n",
       "7PACgBwJuTqveu/gupGuB5IWDEQYJK+VElRCBbp6G8TcyNjY62oLZ7IKwQ0rkY5aPZMFZOuT+EBS\n",
       "i74q/JTxaMotX1lKTO7Gpkm+j4DNB0uInULaWjBxGLaSuqX6SBhcJuydzzfhkeHZbnIjGaahF3f8\n",
       "XkyhMjfNmo3rFjqMF2uo+DjHwaP7D3BKn6OA4n0T25B0DWx2GO8pGpujb9ShRYmE/77/iQAqwOyw\n",
       "C3RlcRC3q36kmArEx2mOBkLMPPetxq+7QOATu2KNHmRtTiLCPqO8ld3V2aD4H4zsSEEed+aDEZIB\n",
       "S3tgcjSiBU6FTYnBKsSsk/+t6wO/XXdIzuRVxCqY/4iL3ss6zu+sn62xn/myhPhbafejFtRuwKRJ\n",
       "BhI8a3s+TxLtUAtCeNexfMNWoeVDtnpY4YkZoM/Dw7rpf4EbG8VFt2u2LnRQEVABbfdbzdgEpodt\n",
       "BiIwFB/nNmlVLMJ+3VM2NHSEWyBUv+GyHArY7gu3/UV3UhwYjWX+DXCUkxbXbAIJAAABRAGf9HRD\n",
       "PwiyoTe5H/vkfwADtBgm14Jd9Llbq/6K4p6o/U3IUk35pTxYfFVmt8YX5P03pu0rnWdKwpNct6MY\n",
       "wBtcuIWUjP7do8F+zV5tYkOmwSJXF84JDD4zWBXu0PIptg8YhLPpp3a9988QsCd2KTdJUpYWcCbW\n",
       "OtI+RTYTPwb+AF3mXCmXQYH5xu8d0ZQaBXp9tyM27Y/KuP6tTkny8tNd3i3phYp6ar8sQvtLHuVa\n",
       "tArQr8A7s6raZF5kymF/UGuI9jOFZuwmRw3Vtb3gy+oHNf568/64wUFfLB5K9eFxqReLCMj1iq9n\n",
       "TFeZwKtAMtkGIAcJfJxz1ivHyy5dmLOA6TcwUMDkae3h93K2T1glNfJ4Lxex7BxNoMhj6mmUVx+H\n",
       "YTGXH45w3dwKMqHxM1gMZGEKSWPftIhC7Gt3bb5HUlJqcAAAARgBn/ZqQz8Iwp8KUlbTWk8AA7QY\n",
       "JteCXfS5W6v+iuS81N3a43GTKML0cPiqzW+ML8n6b03aVzrOlYUmxg30aIbXL9qBsR1taPBf/vW1\n",
       "I0cuLkK1RJdDJlM09DG6x4gcm1ba4J4QSoQCO5c60tMZR5MUW0+um/SHZi0q38d1NWZKWCdRgKBv\n",
       "xFcivlBg7voyieGwick2iXTibqRgIqgmsepDPcIJp36dNSqIG0BPS66+VHGWw3CBHe4cl/s+x+7d\n",
       "HWztSf1lUrMzg+W8GlxiVvoYJHBpskOTcO5uTHNqbxuJ8cFvtxAzrOhK8CaWpDkF3x0ZLo2rrkwb\n",
       "K4Rmwh69ai5lIfczKXwtBNtQ5gk6if34ZKvv/vOvk4mBAAABlUGb+UmoQWyZTBRMEP/+ql18z/4Q\n",
       "M6AE1fPgaocFSTT+mUEizx7X6RygBPUwkD+s9OppYt99tTQpiKRgQiblknMNciUXCGXBk3+FAAjW\n",
       "hkRpif4oXy0TeRgiYIDQKI8Vf519AjloehVh94DTD+GVpynfUle0mirRMRCez78dxEqKnc8E8X81\n",
       "i00FFDGxB/MtwCeW23LtmIs7BjUmiPbdePeHZLtqouesy2Jvu4pTbcg1AdQfPopeBn0U+BLPuDjj\n",
       "DwhI5nLOKdeGTets7UBslyS4DFbp1mRgwyRYI8x/o/VE6GllKA3DO5c/bN6KWEw1iuV9kH3mRAOy\n",
       "J4DtoD9BP2NL6jbAkS28lJoxI91QqYxZcSQOMLCpk/2S9LqUZMioMZypE8kPkncqiv18rxDaeAp4\n",
       "yQj85PNPSvfFo1hEjL4l3g8ky3unTGaz/BHJ1q85P8DTJz3qMctaxpJrJ+AjOFfIO6MUPnUk1rKv\n",
       "3DRo5mFfzXJWQeQYV4lAUqZHQ7uSpIO59uC9iDfwwYT3MtQvMOmwMa9a8QAAAPEBnhhqQz8KQNA4\n",
       "C7qQAmrk6YZZetZ9ZDBPRUYiBREm/qmKT6gNBBJN5t9xGT7MNc7pr21z5vG3RuCsPT7ffFQI0Z4a\n",
       "Lh9vREBNH7BI0O/DZI+X4DGcX7zHR65zR7/p2243DWyVCy9UC5E6R/UtQPOHV9l6zhwrqoeXH4Nr\n",
       "w5ZYyQLwfFA0ZxbjHi27WZFYuD/anIc4UbL/Nyw0QAHFRnLfjRzqpcfi+UEqRQVC7H6f60aPk2ED\n",
       "PbCVDQGrZV1IHnQanJow5E5e1fo0mv1sFxs+aS/7Ctx7dCzh1mzd24g0hwDbZ9oP0IXds7jpRHYJ\n",
       "Dg4/AAABuUGaG0nhClJlMFLBD/6qXNkvMd1ijC0BF//3+OETmwSCr2OCiMpDQo/t6ig6B2/UrKcr\n",
       "WLe0bxJu8zfXdDudZuHoe7C9VekUlxVXa8sJs+6ULcoNABJuwjOkE6uKdmcQpw/nUGc39NY4Jgsj\n",
       "kZYiF/w/NOeaPescBxTRNwiCbj77pPQspWt+6FYvaGQENnlh3C7yhJE3fVY2sewvWmK4KjvdoPTk\n",
       "J4TNDhbBw5dmyicnDUfz8n85GsJOXWUgFULK7EOvCGxSzQfVJMbVHG2tcAWdWe+ocTEG8OT+jQwy\n",
       "IrY2pZQ4rCrpD/3p3uFESh83bj2Yn/Eo4n5IBVhrtWQvko9Y69L1FOnuH9zbCnNhNin2Q2BgcqJi\n",
       "Cvcvf3rNXcaSXX3TPJtLoRFw+FoCyo/fcumn66sAxjaiwxnvS6xhmAAXV/kSIf2Oeo4lBnpJHnxT\n",
       "YrHxx9JpXg5qeMFgBmIRVa9UUlEA/cpL239QK1UnwdXWQvy1BNmkKOs87+wf0VuMKrh1NqHGDzzc\n",
       "4STl0UhJ6y0LxL0fdd/XnkZDfc4zObIKDZfJufCD+vuEr5ESrLLC31duPa5fjEiLBwAAAMoBnjpq\n",
       "Qz8KVaf9qVhIOKr3Zn28Ro8z7UAFtUoSgBu0Pn6Kf5uss7ZebuhO2SA7YOKGUdr4J/qT68ql4baV\n",
       "2Usu8UZWI8JiTTT/m5G+JO1xMl5xfjv6EJuP9J14FHCtw/cN9CneJV3YVNVQGsxxVFw5MeivMuZW\n",
       "shVPT2XxaDqCB3sHCYSYK619OtNRKZPKzrGjZYKgNMc64neC+dBJmKN8Lw6KHbTbc5JpB06nZons\n",
       "uN0kKreBWp2S7aOaor/9Bi7zHUq/tmsVU5HuAAACDUGaPknhDomUwIIf/qpdjP4bhtqiCoq3UQAO\n",
       "x9ZCAD5D9uUDjpHM+9it/b6wgsu/XSLIfEOi7iEFtHxdM/4hIb0mVwIPrnvekzfWOlQGthoKWfVi\n",
       "5afFBWKfV2CVMif7ZGcaZtCLoo8uct6o6BLBb37qsCpbulbn4UVThOKZt1IKJPbIK1H1PC5Q6Ajm\n",
       "MK++LYzoQjaZtOHOY1otUl+5bQyhnKPxhT277wFKNcQLR6jrBYxqG5Lq34bWfKIl0kUo+yF/Nm9o\n",
       "muFiBXKJztnxzRqcmHHv1vc019tkMuBQImUbfHwyXWnjfpopm/D20qUkL5i4sU0jYtNY3hHMIVho\n",
       "JX4LeTK5Q0UiShhZtk5X1ReWJisKpS+O57Mv9UHozMw45YCfucBUIVKzqQTbT6vHuRomdzbKBZky\n",
       "J+MX2aL9VqXyAbj2G6in2uSCu/omGKVTpC0QbLqroZsKjgSxGQxqR0Cn2YxHH+I0wHUYC1NQHenJ\n",
       "blA3fkcpeISniYbtlfLPF2mPpDeL2gO5XDz/xkKxOCP3+vM9zUGo/9bp9SYCDk6DfegxavuHiyZ6\n",
       "g5zIbDiZZBn0WaDHZ5Q05DM74/zNKU7o+zj0lwPigXyGKNeCW8uB/giH9BypvKUi17tL9fR485a8\n",
       "Nomgc9PGzsj6JyGYBAGSFGQKYyRFWu3CvFK3yKogxjIboL80BOoCy3gwSQAAATJBnlxFFTwz/wRp\n",
       "Y1JinkALAsK/ZP8vOPxLomNah+gIEk6ZTiI/4RffJ+C6g/j8EJvFMOKa5pevNt9TLqlWwYKnCPux\n",
       "8sjVsHEkJsRhyhx+BPEdUZzXehJQtnsiMjT3eAt7eLIdI30LMOd/oenA3oW/Y/8WPiNRpVCk7rel\n",
       "XSgl4gmR7u32SxTezPKLwYUC9Z83yLE/b4GEExRS/Qd4hUw9Lt6gg2KULuC31T32Avb+YOb55MVY\n",
       "A3yIEbT05DeCvWssQKRf5d9utsspSaoRngvCQvpFaXFHomYx9gYWwOm8Tl+sxRWnCH/3ninZDZF5\n",
       "gM3EM/xerhpvFTLghUVYaJX+6bTmGnk4nj3I0CWUMGvmucEC9CUqjkzUe6bSNYUTfbsR3AdO8Sk6\n",
       "MQt7HiKwW4eFxYEAAAELAZ59akM/A8Q8EC5UMNYh3vxP7jB+wnxYsMRR1vY4/JhJSm9+g6EQ4ioH\n",
       "wo75JQhvlGVRXXplGzm0lE0cK1z8Eytzoi4QLetRZ7qHqlY0yZcfSiX2rm31S0hM5qlqe451O2M2\n",
       "JQ0QkUY6Qlr66Z0kClhQJPyXa0lBBISpW4AJZ1Kqx1hjTbbMrisHW11qRUkkgGyohvXoZPW4bw9j\n",
       "ONXCmMYNFWlU2Z/5qRM+PQY/P1sPgm0w9f/0g6XmBpvpf03qIdivaMOebCW8AY+R/vS4tGQG5jdb\n",
       "4zplHDXNtGqAbvNkd4rNeLl02fpc14hQJP2RC4GQb1qUAgCIdBSkwCz7QldwNYrZxrq5Ae9AAAAC\n",
       "TkGaYkmoQWiZTAgh//6qVVVmgIdczldZ+vsXTjTACyzAJBsbBSMsqwu6qiMfVIyclOC14AqtvXVV\n",
       "RE0rdSJdRwYa3uPhkWj7nHs+vPaHq/Wb6gvApo0Q6KGvik9IM6H/+FKaeKAPwVO7yVortTyqk3Tg\n",
       "cwcqMgovdMl5PcqkA002nWnnqmfyyFNtkCSf3ZGuZYBWlzShuwN52nLGIqec3H0iyNQ7kdefgrio\n",
       "cmL0og76VRi+AJpeh+iw9bpA2RwpuCp3W9gG5SLeSRIKVQArEu08vuk/1XLkQuC1SiNxmscI/2SN\n",
       "YeBzW35IXUztiiQyf8iibz+O7hztMQGEl27GniKaPagYK6fKyj0EJqxVR5VusdidaW6SbOQMDXQU\n",
       "h8HUG1Pc6UHuVmgrdWg5VZsZkPuFaNOH/0duhgUG6bBqh0VZpbcyoECpLJq0YOPGTh2PelyvUccK\n",
       "Lt+kSMl+jvw7ctzGwe/K4AwL5cBxQ9U0yZsrvuRBf7p5lafrLHyfBpQl8yKZxfThEKmypSjiU+nP\n",
       "V9PiqFwJeXX7sF34e03mo3fEFhVbCZwY2HTC8rHtA537sM8JdBjGYiWSYGtqO2fdPB5NSCDABCb2\n",
       "z0RQVeWocPrZdfT4QTvtfSO9y5QM/7sqh1cyRIu/gfNxMbeho0baDzY84fXiTA/cy8Gbw8xw5FFc\n",
       "Ocw73/GxXcH/LoA/4OECnIH1/R8S8t4ou1fNydRnBHDhZkyUjtQ1yTMbK9hSxbIk1CI9P6tmBKZI\n",
       "w3vZ3RfdA+ydMLWmgeUmkoo/sKVRAAABsEGegEURLDf/A+fpEhj2VXtrx1NeaP6o9WgPnYWpavyH\n",
       "odrUV31IrMC7ulZDpeZ+Dt4r4GhGrhheC/ejNzL5Gk+tCd72zefoKW+05p7K/2p9JZsilyg6nyH6\n",
       "jfgQ5ZEd9QKS7k2/dtN4UTXST7pKg43yUoG2ReTP0kh97Fr0zNsGW5v/RkFNFCvHxmhk/MurN2z7\n",
       "TEuptkwvW5ATQ16eoY8LY/QSKhcG+Hly/PFjZINDDJNh1a6NDGF0bJq+b0DNVqGBAM5ORAwtgzzh\n",
       "CKbE7Hof/iX6pyG4AVY2j/i9ypS4GQF7a2kJ6G5JIuGZ0NDJnUqIsGrFK1BqE7rJXMsuIzmDXR5V\n",
       "4GMN4yHckxXH1xALk/cQK86bYcC/rhamBucts2UM/ylAmnHF0LtQuV67+OAV6gMxaUvDUu14KdQh\n",
       "9M79y9qlmd4zcXviCGq/c6eyyOwyJZRY+yxHpoGhevIHluRkD/5reUkSw33MTN2KbHLqsa18XU/z\n",
       "BgeIRV011K0E3qDNhqmZyb5dGbBW92Mf31s8k6Fsyr/rfJi3pm/B1FdoHTVWhjAHWysiDJNcAu8Q\n",
       "QQAAATUBnr90Qz8EYsAReYailZBLW4kQHAl3dB/kF0HJC6qDTpk2dUz6OB1mEYIs0T1I+5ewB+iu\n",
       "WXZ/9hiHG8hrSEwFsf/SV2fHhTbpDE1DhILkEZDqXk8FzFohr/T1ycgdanjYvc8rZnbekf00kq3C\n",
       "G6xXtslAeWuCQei1SI2JVCD7LPhG4ZjzS+gHv6/TefzP0oeVHFSZD1b7Rajw8D02w/MZ5CmjNd51\n",
       "i2yeAkMJFpxh6ZV756IGs6sqRs3QTdqJGp7uP3CuA9MbURQ3vRQq3fZSbd2f2McrwxhsMQ+hRqaJ\n",
       "Ym3GQsAJ8Me8wpKso5U9kozljW6EEsWCdbOHjVcAgNsYytREXPBG28YlVkouID9FOT3ibbBOGHxd\n",
       "Wou9HwAqJdz6hdk7U5eCP5U0WE3RcfkWBMCcbagAAAEYAZ6hakM/AhbYHysUHEIl2DACWOokoxVx\n",
       "LPlVQPxHistlkLNoh9acDLJlS2p7YWyJi4/e8ItxjudTzke/8MH5Gtv4s+pkcAOLWQdvwlZhfOri\n",
       "f0njfnT0XBBdw233WEwF/+H9Y4HihlG6NBxMeq2O1udTKra1n7WVeR3jL9uT22N0c/GSUeaan0DT\n",
       "Z51hKKs6owj492qs7qK+7kSFdTcHaHelfa08jFxPgkNcHGrpSxhCW2+JZaNzuUe802wmN4Sb9cuP\n",
       "OdwnYlZjFTS9ut/VAk3p+iW0cQTK7BpfkeRCtiEudexi+U25d+1uCYeiMm4by0uvnt6L1EQX0Jx0\n",
       "NsmvnYr/2L85hXibpX6fDWCmOhRrcbt/1yucnQAAAbhBmqZJqEFsmUwIIf/+qlU1vk4CHX7zR2IE\n",
       "Ue4gN/xK+v9Iv58nnEdnVWPn9GLT7xvXDkvequTnNCe0S3AJiCBOZkpVmKaCJw4ZH7FFjxEmYYcM\n",
       "UvLucXSUvZGcZnZqkmav06/+m2OLpRBHsrLpdzbyVcxhzJjBMFG6E/nfwQ6l1aHATFFeYUt08tej\n",
       "vEEcs2AELWSoN+f9kFr2hqdqs7/jSH+TQe+6YRDHbVfq4FEM6O8IwpL/auhcm3JfUV7r7P50aupo\n",
       "9Idg9w9DFfRIvB8dP9GandUbjSFSgZKvDzMi+GFSNECUYtTg5IoQGs0cX37Qqh72J37d5F0v5PvK\n",
       "TgyA+4J/V5NRW6VZIXms6yUEmeYm6ArXy7dlsgxMSf2GE+cCUBwdKZYoSR66vkOvqLVSBn3alxQD\n",
       "Gj9RJVq6uTkiz7i0wmt34FmCbSSpfTNEZISa4heYTLc9X+d+vgjLoZS6Jt8p4cFNa2afSYAlta4F\n",
       "MT5gfb0vWiNHJO+OhMCYhE5/3UPd2i1JXWdbNlOm+ThVcGiIP5JmCHb1J6My5lTBp20RGeCCUg71\n",
       "k7QThEFN7fEMw4YovH9wwAAAAbJBnsRFFSw3/wMmSM3RADcC44KuN7VGZ4paXWfZdbOmStiY5Shb\n",
       "fRowogSuHdGGzL27WzVgHyIDcBCfjMB9nRHJXi9+IiWZtVaWQVxOuhbEyUSCeM5ooyPFeObeu/FM\n",
       "6yxV+kW9zMgz5wAnwdf6FhvzgNY+CySxNzhniE9/Tre401QMJRbxxH4QewfZMY4yVVkBvM8WlrkS\n",
       "mDuxfn2W9/Fvm/9gNsLX+ovuo7ndmef3H8hoxfm0mPmcdpnbOJaVQftoBa9wFBUWthht1SkI1EgW\n",
       "BU5sehIHFo+CJtzaXW5rsxAN5sgxA+hguSJ8ykgzVZx4GY0qJZ8732/HWSt87pngJiGZ/8O8CFzG\n",
       "ZSvIidqP9oT7kQG88aQ/mPfEWL2WpTm/X/odFHTBdxgG0qpM2ERBEW16GDwroUD17Z3Xj3zonclq\n",
       "Wb3iazqmpmJe1WjforBuQxXzeZbwAgW87kApPpOKg+T719JA0K6nR0W5Rsf98nenckUOYJc4RFoF\n",
       "NfnCTlGhRRdjosOCsB2eGCh+3FyTIT7PWbrof9YMhj5YOhER+ZhMhnMP8oajESX1ym6O3sdPbQAA\n",
       "AM4BnuN0Qz8DmiUcFf7myYbRoE7swiBWpUSBgAwEVV+Ls5I0JJtpH9VdOVQYc3TvaPo2fY7frFu2\n",
       "/LTCaw2BJ+9ZbAe/m+DltmsTya8xTzJzZqA502g2x9CqGzABRRlpdEdN3oL02brn/vBFuXTHNqGe\n",
       "g2gbdogExnIlRhBWeokfratv1zhcKEA898Bjk6E4m4jOrNeFETBM41+O1IhqmwbsOSEhEj91AQ4u\n",
       "G4eVEMRFdpHce30ge/FTHswwA4oDR5h/0zGbUoGPuKcJg+fXQQAAANgBnuVqQz8D8x+naJwAteP+\n",
       "NPJR32xiMKAraLh086YBVSNMt9eViYIBcahoCjwULdn02Bn0qBda//Os002YSyq0/Fizgf5mNJTF\n",
       "Xy9C6KbXan8oc8gKTBw4chWmgJK9fd0gOwirH/EkhXQJ+OClL+/DK+s4/oDzzSEvp7s8uZppW5M6\n",
       "eap+0sDG8jE3uxeYYuEODlVD/tvBDbMEzuSSOSKJiKFLtmPOrS+wtcXiMD4uVqgbJMEKcGtmHodm\n",
       "EbcxxWvLlH8gAnY5xan4w4ADldfmSRB8NsWyWvkAAAITQZrqSahBbJlMCCH//qpVNh3mFQAEI5xh\n",
       "wxv8J/9n2F66YhuRzUo/9FJS/n22I5Ti4k+NB3KZiqiv8jqs/lFajqzKpefGmQdMZsmqK7gJtBmn\n",
       "TmJgBaaN8mEV+gRwrJxhuLK/NYWnirOYHZsntmKvSnHeUa5NTra7oCOzfvswHPdFKTzRmJfu3+EU\n",
       "kUYd8lr7ZmNEKrGoNcZc8vmCfrSOoAJjyy/4ZydXzzEoaFLBbXsCJkZfXtFfY4lPQQm6yQAXwZPE\n",
       "VT2YoP2zCs0rMrlh3FIQh7Z8YTXqTBqo+frci+7MlJVeMMabWMAu8MlVB+N6mkRBmvZRokcElUEE\n",
       "NJFpPcOj3xewvlYO8FGGJ8Wm5V6AO5Hioa9bLDsyeZbm6cm+p2Ma19a9ZqEUc+uGaENqtgLM5bmi\n",
       "BeXtzxYVvzKiRkf+byq2JDB8OXoULEaVUNDR0zjE0zRdpftM3reScc7/mNKD3YfLxfEwVxg9CScM\n",
       "dL8gas7HzJa6N9S48IR48gnDvvvPoBff4UN4q+QBc00k8ZFgzw/P/w965db3rCbKDVPn1TD7ofHp\n",
       "Xxwb4WRTnvxVi9kmAh0DAmoCnb/b0sMCYJdnUYDeY41L6qybekcIMa5YUJ12GBi7vQIw52Hl9Bm0\n",
       "N80lnhBJAnSX+dg7ry9YCjO8Ujf3ilT2NEvOzpsHCczEdc8mvVALRT7pFhgjIeulFjjlAAABSUGf\n",
       "CEUVLDf/A31FbLsgAQqUOTaUFp+s/Opccm2tKwKW59G08H9/YLwfPp4j7XsjD8Mqh2E4vtikRS/X\n",
       "Rto3EdTAUiXOFLQELA+QAVVaOedLgCBR+j0CCS+skHCQRknQZcKNE4eadxKPw8jNaWdmpeaHeSTh\n",
       "ma9ZcklDDCae8JT5F8YQT4n4L0nXjcOOvXWxNWwjwcm1k1aj+njHyrpJlT5iAZkfeyxwLRLk9sh8\n",
       "6M3jBFpvISbpdEZy6GGAY+EdN+Oa5u/lo08hgADSGd0u5ip3eT8TScDQ+DHSrtMZ+U6X3MfKWE8A\n",
       "fKwI6OTDGKjOT00WM4CqOzo+/JQSbaM2YIMnZS1+S+a9Yr2mXiW/45SbREefwNFWLR081I1c9LF2\n",
       "PCRyFc9iUthLONli0JZU0pD6sLSQ0HMEU50a1b41qYP/eYg0d4ksFAWAAAABJAGfJ3RDPwP2JNV/\n",
       "DNDOf80AKmYJnxNwelE4EC/aME9W5CNvjk4qGWM2PX1XnX/4kaN9GdkuCdk7xZ6uNBRvnhEm8Tem\n",
       "G9ROFzznbc1C0Y6Aq89AS4RgjAj/pqHoEV0/wKqVnWijJGtUyizYz5o+IKP/+5zFRRWL/NNzsqqn\n",
       "oo+oyMTHScbdZ/o3zLzx1pqkZTwlKETK5FKJ5VymMi+9U6uwt1xYyvrXAwTwH6F9ZWqWmyQ+TkWm\n",
       "vRnacmYT447a4bNxisJg+TRW972CrWM/C7dx4bXZxVS53S39OluuftQQ5/ygH2hI1qONS70KTflO\n",
       "bk18vyn48TvX0dazBIEBOVEguf7IN77NyBAbkCbaNohYNIZQYzNOMXV58nmVEwIz4NHkKdAAAAEA\n",
       "AZ8pakM/A/d8p66gIAg651ltIH1OCrTlyKBtBTNHSPHZXMHE0X1ugz2j+GM74XkE2MediUiCTdQt\n",
       "JBUmyvWE3BrSGon0Oj9xA/erggS6P0ncDlsexP1piIjBUdn7HZlWkq1bHtHrzPiTc7jHrfQF2CLv\n",
       "B1ztvDeR9xWAgGkDfIwRuTuUbFz6tF22TKaPr4Jf7InRw7lbDWLzjlFPVIwYhx+joyZL0wvicIZ3\n",
       "JzS5CLK1bo1K1PIswDMM2DKH/2KM8INPm3fozqPoAchW2MKv/1qcIhLzaTvIN6ToZLFRGLN/1JH3\n",
       "yztCRL9RMhNqdMM33g6tcOLLYPyq7G3cpaOYGwAAAhdBmy1JqEFsmUwIIf/+qlVN9/GACdv//8Iy\n",
       "YiupS4j5et577zuLS7IB86fwv/g7QfWx1a8atxVDfgu7Cjn4v4PcwWYU21EtGaPODJk8DG6deTaU\n",
       "6odWOyUgtkdXoAaxQ/qRTBAgG9y453BfjOIh4NN42AKlAEoOYiZGEq/YKpo6mhk/mYR4Iv3Rq8wn\n",
       "7fajEgrHjz5QfeBkzdvQ3vQ3/M/Sl9G+8ngyKbLSTp68lcxJH7kCpjrn6LXg7ge5CaUMPWxYH0BF\n",
       "SHYkFbEE/ntQc2TJ4GhOZsI+N3iLvV3FEVi2v3aEPE6fQk+RN4wJajNTTMHB45QV+1Aw+G774Fbi\n",
       "SlVu7ORBXSpptWvY/Mqk4I33cUtDWWwXexi+I67rDxYyFgs7K3uUCFXyOxXUQ7vbWvdHsnAs915m\n",
       "UrJOeuPZ5c1FlaVoNZw+XJVCNwdbYviah11ZPbm/UPBMAPbUozvpDxmjOiXEOOn/vPB9BEV2Y+9Q\n",
       "ztZe6PzkxIC6WYZ69gx1cMMbPvQoBcblzZ1AKN/DEz+a6Doc2mGOyl0yVhYaCeIbxsfUOIMA/RXj\n",
       "2hFGvngN63AKY89Va4056de6La9qQ57d+sdiux5Ou0JYb+WhCsgYMKcS85oLX2X3EhelC6cqh3re\n",
       "0MtPpHE2jYzD5Ctus0fzWxesvg9HpjgVbFEOSDU67jQAt5+I0RDmUNF+VSblRBabNGVD/jGgAAAB\n",
       "J0GfS0UVLDP/BC2cEIhBgAAmwg8gIYl+dDXe1SUpBYNhLuepxg9UDMzfnSypwPxZttPs1w8mHq/j\n",
       "XsVpU4i21pKby6ZiMJfKdFBiQV7Un8os/W1kze1XCezlXwcNygXhwxHmHT+JnLXgHPNOYzEAbTjO\n",
       "Ml27IP0XTPEE9OTBTO3N7rTsIf2tekIVXY3wL9DNzfXqbHa+NJ5Hv84bcRhMfK4mWIOjv3KHDaop\n",
       "ndnW3HLocNO8yZLKMggj1FVUQI9ZrcAy49dXxRIV88/f8oLULJq0nrJ9TePlFjZ85IiiiRFwDUyM\n",
       "y39bMj6zOOu4FDQz7Lb/wOmaiWeVcvS86vWJLU1Q0ylypI8+MuX1WvXfVbRnV1m1cB6tqf/78AMF\n",
       "6FPGv21Gu89kKkQAAAEaAZ9sakM/BGk/RWUTwPZJFZYqo19A/2Wjl3olaoQHbL3vSQn2yrJ/Y+2e\n",
       "mgnYTT1Fi5wg+elWLmlRQ4I0E648JxNn0AQDQXJkQoTwwlKGyMkNl3i1hvK0zFAkX43XLz9DnQcC\n",
       "LD7KKPTtPTPpXCXu9AqTkPibItizRBH01/nhhqy3+asSxBhM/xrXoHxyGn2DwR/roGVADNDDGD2p\n",
       "08WCKB0oEajwT3bzH4yE4iLp2Nm1F0QpOqLp7kYwVoR89DGLNBzPc/LqrtOQ9kvd9a/PTSJuZHnu\n",
       "E8k8ZgWlFUBkARpwYhkGnpwycWYaaf1Nn4FNmLn1flUhcMq5Cd4Bmx8TZQuoxhVPo9J50vXfiHVM\n",
       "s7CmQ5rSENOTdFSBAAAB5UGbcUmoQWyZTAgh//6qYpkj6gBq3oJLfrX0cNu3AnB557fYFvCJPSS5\n",
       "f4HeNlzYcxS6UD4iMqf3p6YI9WVqCxG47Q7gK+ObeC7oV5FORfjnVglhDvSCz+T/zyU5PyTPdyiQ\n",
       "SzmRpS/10NTqgsKeoZb59Krz99MivQoXDghccD02qvteAi8U4mNU1mLU0+7oBKPJ/I0ByWDGN3PC\n",
       "DRJZJhtCTRZkzoYIPDSPRhV5Cp1epTYVTOKtcf8hK+bI4VHvhIFLG/UEGND16t/J/cs7gTm5tf19\n",
       "8M4AQLOaelZFTY3C6wOGykUxwsbHn5BLl4jID3EdpLHRH65YtRhvKWE3OmEZax98FqK8PDEsWCLw\n",
       "WG83SZkHw2QSTLd/aNVFK++xHnp+z5znJI4vInTodI7WAisSb/Mz96M256RT3YT3e+VE4bdDDx5g\n",
       "owFkX4FM6IgZ39gA73RwN7xwGNRwKl6Bw6SgznMgIjZD2oryQmY7Fpru2x1cVJkdj+StgaeA65jb\n",
       "2rZV+TE0APHruUIsuY947ncOxvvRCaGkHkVZIHIeIdwukLCA25rB3Y45FxujqBE6VBo3Z5YGxRrm\n",
       "Yoz3vPoYEs80v3uAEFC7qN/Y50YKqqHXI9Ifp4Oe97eWz6Oz0lfE7a6NWnOxAAABREGfj0UVLDf/\n",
       "Cq2X+Cl/gA2qJbfa2+a9uFlAc8eBQ0VRel86Px5L4Q5eR90To9ripcWCZXC4eeWb2kX1HV5rPAxV\n",
       "Fxe1RBxcPYWwIb69F8Nnp8iLlbsJz/SN7p6f304BeKE0jY5uKAN2SzA3UknUMbOYRxSL/XBZn4aw\n",
       "07JJruvJGyYwqU78ptC8E4yEHMYmlJPsP0eJbXELrQWfylLbrhVCgqYXMbecy7aO35JdyL1ufhrO\n",
       "4XJTtuJ5dXUKvNVd3RvCiHqdgUiNCTX3LdgQdcmOvluPsrwdxRXsAIJwDjVVnX/SujAWMTrcjMbP\n",
       "N4VvHrFS9li/7PXh9+uO/stW7YXH6arvCUu9vML5YQYCplDit6gPzxvIpChYBlvno4olVa/621NE\n",
       "wWsP7Y4c+ieEugAWsz79CJtoS2Eu0BZumftftHUOPwAAAR0Bn650Qz8MEgymNPcAOYEEIUfe99UR\n",
       "Xm3Mga9B/Hm27JPHZsXgU+CwDgkwztTc5m0eO0TOApgmVjHDiIxvaNW0Y+DG82v4aYRjQP3HL5o1\n",
       "gg7HOnREXgnzZKdW+4YLtQcXHh4botbESBwboVBrGw9TU4fnFNE3Jb03xRLdn+X2JZzfrsirOlIu\n",
       "opEjOF2mvb4ETSTGr30y7Y3+ETvh1r2O4EBk2Dl2TXqc+EIFZFi1DqNnjDqXbuydeyYDSvFaPnzA\n",
       "rkAVbhFSdkAFj5LkWIFqW9ucOiCoEwNqOBNRHjvwjaRpmSKDTh+fNS5Gpo9+GaBG+HQoykOahZIh\n",
       "7VwcJJFshJ4Rwg+bbeM19cGw1Rv8/n8CRK9ljAYuJ09JobAAAADqAZ+wakM/Cu53vuQAkJC8WK7T\n",
       "7ookg/MsjqYMDZEXhl7S/UhvTyHNhwyLGA/rR9Wh54U5lalmcGC5mAyAYeGT+/r3Mj+gVl8E3V3M\n",
       "cKwZK05HhP97wlrC2NCEiGkF7TAdI4uLnqACqGy9hru5GlFmb0AmuTPmdzTKu0DcjWGmfEb4tdvD\n",
       "ibtjFkSEur308x2oDNZbNyQ2whIuH6574cXcGQLquYbaQ2ch8TZV06jVmNT9HboOy96bUmN/yAXk\n",
       "fHMCCwvKRooGdTOQtMM98stvTGXb+MrkrafFnsh+7mm7BCf9muzKG4ywhWqjAAABy0GbtUmoQWyZ\n",
       "TAgh//6qXW92kpwABSpFbelTRrQ6Bi+bqwpYBGRg3PqkKkjm9humuKBF+LZsxDILWHpnpYObZuv4\n",
       "d38Q277KZeMXocAeKWDnMH6zzadGojsYjLRe8N5RoeoH24Q7Mk0BVieZQdEYx/5FqMPSBhDmMF4F\n",
       "c6rUDsNMn+h0LnvI+y9G5qIQEMqJPkVIOmHNlBWAAJuEgu/yaKpbeaqfU72c/cVWtWggsQI4aAOe\n",
       "fghAsigNYw39KDr5h6Bk4G07o3Fx/L897Bb3YeeavIdPqZO3EoW09qfMKOoO/C4oginn3V1/dZ6o\n",
       "j9kbXAVcvrpGG2ZIEf6YGvRE9SI+/pOxFu3uUunx87UOQki7uNMrfW9JDiySqmAZ+TN3iYuq/rSy\n",
       "BlVe9eQyyyyq0uF+ELXNjCn/64b4minkIF4rDW0jX0aU+wc5vryNdorDNqbXCkzIIGiBi7Uw+BGe\n",
       "uY8l1wywEUUsXXn36PmvOnDQ2KrrjBlB/hVqWnyoDbynDk5LjI4R4nL9AJaXpty1yJ9CoTi9drAQ\n",
       "rJ72jjS64ed1DlydirNXglQVpZjzt0grOOd7ImGSp60yLi2H61Rw8Sg/InIvf7pAEXY9wQAAATBB\n",
       "n9NFFSw3/wuGGfewv6kkeykrPpigA90qBujvZjvcXV5inzyFKxzFEiOyeVJ9D5MQh4hxFGpIktwY\n",
       "h4RrwI8WZWcutq0fHH07s2Uz4fL2YXG4DuljqYfOBNfeC3e2+9Z/HMSbRljI1Eeba02X9ewuov0n\n",
       "K8YGtOJFyyQds+aaXPpwCzhInfYM65vWd4ofHOD+dPBVbHFvlWJr1y48q+wgIy7q46eIC9iUI91y\n",
       "0jmtQpSCd3PqP1hi0p3qiZL0p/F2CvdhENUATXfnoay70idcrTY2xPXu85btwL9phdfBTU3pdmgF\n",
       "31OaPPHTgrkkNNuoU/H2ZRHLNvFu5mNEB0XEjqZJUE6ngdD3xvYTGt3fi6oGgc55s3PhpkgOc21w\n",
       "0CmTzPjOw11sYrNq40qyEPpaAAABAQGf8nRDPwpAGj8pL6NoIAOCLnMsJDcYgiQDs+ZfkUSQLhw7\n",
       "mUWTRYANfn00NJtRp/oeedKff7kNTzn9wC9L+6AAjS8rhcGjNR2tU8M8QE5/JhfV1IOMe3CgvvFt\n",
       "+3QUdG1aLNaxfM7mDFrCDh7jsH+VZ9mvyhtYkf4MAI3eSWu005Jv7j6IsbYvSROCgZO3U7MHibm0\n",
       "4MX6/WnXGr4VoTEgVTVFErvcAhZ9xW/cBTbtBcKRpxSJ9UeNKyPN2zHM3B166hg8sHjGoT/CEHm2\n",
       "sW6EKNKr2l4L7xKa7Fd8oWhAD9BIloo9Rtv4MGY0xRHn7pMN8VAsD1qc+ZtWQsYj+rTYAAABDAGf\n",
       "9GpDPwldArk/i7ZHFsj1ssENPIwAF6qNN4R9fCex1bWakiBqk9LZN9fSTdq0eaYChMGA5AuqtoyP\n",
       "Qix8oNjvA0la33MG9R3QPkfgE+Om3OGeB4NhtIZFyZglL5LHiIaBWVWw62rY16C0UJOFYsC3uqxs\n",
       "ACaHVklcb9om1ZkfLuAX+sE+NEbXDTGj/5/9IsAW86IdmFEAFtOvahgq/fr2p39jyBmoV82C4x88\n",
       "4McRJCzZNs5cwMsPvmmWSj/ixaK3NKMnjnpwbOT6AQ1zw5026zT9K6G8D3RuWfwr/TJpTAimHFmq\n",
       "03vlpYs0lSBkTM6WSGi3VDntkiRU+SbXNlt5PhB3jVu5oH7GUHcAAAIJQZv5SahBbJlMCCH//qpi\n",
       "eKlqAoXDyexABHyf/8F0wWWZ2p6oVqgOaj631UwxMiZFTmnH+Tdpt/zotkDUSoPK4Oel1GraqD5o\n",
       "H3HtBvEkiZ28aJxy7C/UQo7lSFEXTcGlESCRmzGAyurKHFljMuAsjkMnv2datHGJMBEK9K+zKpME\n",
       "ZaPELuIVXEXTMbq1rQK55lkFQV1G1hOFWTv6BwVP+H4uOl0EngtIe7iUbiT0hO4Q1qSf7GtIaFqc\n",
       "VYoruPSH5I6PZfmatl8UJzX5pYTf5rynNjfeiFdJkl26sG+kTxd0ttE00SMJnqsD9xnfhcM6KA4b\n",
       "0EbnH0ATTckepwp6wOir/aaqWFPZfJM4G+kzynRwQyav6Pp7lBfdiZHKpjDAEx02anGzeRBAGWSQ\n",
       "UQbl24nLosK72llHy46nArZ98t/A19N019t52cWIZuQZW0OgAOqhnWPPeMPwVsEbEG29DYTWxgfD\n",
       "7Td2Ox29rCV7mAoxq8PFJkj/HvMlebyX/QxktM7OR8VbTTmDvNa05p9cnV1hxCFl/tPV10xlUmzF\n",
       "9eBd4DFelAQMSSFuYTcrhy2IzA7ZGlMDWMaK8wIT6OrHxyeCnUvB+9jYoLN3HVV9nzS/D1PeZQzk\n",
       "XnDIBcaHnlocjCYMoZUZLC7oJ+dYEFnlNQHuFcOjaKLoBNcQS251iGI+S96A3OI8+owAAAHBQZ4X\n",
       "RRUsN/8KmNAADPebTZQzrUUJwZl7MVz/DeXDFJEqACbj/5Of7VIF0UGQ5VJiW6fcxUBexxYEhWdD\n",
       "B5x8OLFNa+er+zNeq2vlZ27jdtliuSrUaTw1XAP3zc25DF9anwmIDwbstU19E1F5bupOJ+haxexh\n",
       "Lh1AjoJXHqH5Blh7O1nnJMm5hskBqyE9ik7pxNnwumLDfS1Xg9z0TPirDbyRI0yT10h19UGgx+gh\n",
       "+Zj4o1sA1Pn3yrhN/FgHEZsBQ8+P/Q6lb6ai4m7VVK5qdy1/Ro4xfGXR/pPrfeuym8Xd5WKt3xZr\n",
       "+fpzXABHOqSdHnoqmGK/k5fG7nt5v+ffvpn0T7e7ZlkEPyoqYkdekOW6q1YHUf83oAY9CwO4Ah/z\n",
       "yiwA3yU7l5BKNqh3Vw4eCpPcC57vyOb1t/jAPu8DCwgiDFiyRjTIscTgdQVmQ5tFGa9fGd/RW76O\n",
       "gPp92gT0o49jwxilon9YzQc7s1AjWKgti2+fuhtjUMyNWoCpNrK2J6jixmB+/oFzadCIkjDgVrWt\n",
       "xQf0UGi47Ijj5wr2TkorzLI8OYiUecGGTbquRlbmVvOd+OsAnIew7t0Y3fmJ9PkAAAFdAZ42dEM/\n",
       "DEF4AEyokrDvz0FhZQZ4hR8+JTc+Fixl4ZJW5igCY/rZJD+XtBW70n1MCgqYRqsK63iUGsh4hB+O\n",
       "FOxk8E+NYUqeu9ptxdVrx119LjoLPPkBbwej+OhdZX5MxNRU/Ok94HzQ1KoS0Tt2FD/df0AFMNWC\n",
       "5Zl1I/j2HtA/uDswMe+atgDreuuCoH2fR179yJyM0CO0dQ7xdQx5O5GOhP+MKY6yiFPqeYW45f43\n",
       "wFw5mus3gJpzM0eciJA/ImnhQhosEkJ8v5NE9UO8ll0QHgwZDFlfXh7++wtlFHqSPHhVKYi9uM23\n",
       "qSt5ukcleBIDK8SNtnssD0rzQPIhrbefgOk0xUB3skGCWjdVIuIbRULva1FlqxY9lB/9B+YfQMeB\n",
       "2Su11G1bEkws3rNw200EysRl8Ehrk1pOmwXm+mVLLZD8Gy1FRQCYaWKv27fjCqj71IThdWxEYPTB\n",
       "gQAAAU8BnjhqQz8MIaKbRh+ATExWfSlVrdjaHH3sL7rHoc/4UrL0wacCZCBVCo5MV5DxnNlo/OzG\n",
       "+BvM0bRc0/T2mJdoblOt4oinEmfrXBJjxhMGNjhxXK5F+wzoPsuZSyd4GxZ1jSM+52qG1ot57EPA\n",
       "YzOfgZEcXHOQ/Ufs89Zblez/DBfNMRlFdMcrHcuBCRhPrzoaxWdJXioQhYWgYplqqNZRHMd8TJ7C\n",
       "PIqnhlasOqOTo0K11CRDpyyKoMLWO0KK34Ze+QE5joGBEl1DALSYJbGodfQgvidFEPWGgkzwYBo1\n",
       "gKrt1J1QExEgW4cdP9wTlRq2nbJMIHwIGXHP06FXxCYZCUPCBwtoooHJgM9OkTLCEtwcDawWGbRf\n",
       "VPeUHr8EZ1sMmQOnOm7Np7pEDoMjwTIvNlyafgIRTf/wkqguM75Fo2/BFBTGems9KZh5vclEgAAA\n",
       "AgNBmjxJqEFsmUwIIf/+qlVOHuuqcecgCD7RCdSvIR63D5KSq9GlG9wXtki8J9j3IqD+MM7yfDqP\n",
       "R3LGP6/UGuJeZ0EFy/bjJYI4/Kr1ehnzkGRu63fKDSu69FaZA5dR8LKouXuq+bPxaE614p9jPAKR\n",
       "dhqAm25DjwvVwdIKEEY+bealt8jj51BlubSaA5khu1IuEdDWxAQTJCB+s5uPZD3arhqg6+EXJy74\n",
       "1vPiyFPvqraFRnlhwZ3HxBV7yOzWMmWEkcbv8EWTzEcCjO7HmI/xfa2Yi0RVUUJyd0ZPaimK+zwg\n",
       "cAummeXZjjv5mWCyfJQhoT+r9Vi8eaHR+0t3TFY0S7+etpAQiof5ZaVads8mD70Tqg4RvY8IMn2P\n",
       "wzPx0cP24XIL34o7lVXsZxH7qCMjR5XsuJAa27f8RxA439JAqqtCylR3wWOj8R0QPYoJq/78loub\n",
       "FJH22XtR3UgWsVbvfDil1a6shpZI1yz42X5zqgLfQB94imK5JP8AMbV/Xk40eiafs8INM6JD6YNO\n",
       "C8Knsvtpwa7iNMpiBkQM1s962w57hvjPCnNzk2gh3D1At32dCb9fb8Wp9S2J4B4Zp1Vbq7+QZGbr\n",
       "s5fqCCrUpD5N5Niv1yTo5QN3ydeydrxaH4Eoeoi7XgRgcrOGe+3OVWcbN/FL2wZgF2j8RZEr9Gju\n",
       "4/opqQAAAYBBnlpFFSwz/wRmnn305b9UAtKBL/M/mSlDZpH9Y4bhIPah20BuzPTnjdBw2Q/6Ngrs\n",
       "n9Im2FD+zMlm7VYu+J8GNyQvB//Dl1LnEX3wSYe3jaeUbTyluc39z+1GM0dmTtXd1B/ux9yOAx7+\n",
       "MPxpGL5joKvQLVFi1JcoO87JMqGAPR4RUgU6J2URkENawzeGsBtv3GOZTawd00SRWjSjg2k57nBW\n",
       "ZY9yXFg4zmZvC+XfAsDTbup6CvUuILR8IRAs7NUSXL3RbAXEXzjEuaBIVnpLgsEwKgujbvDLbofY\n",
       "fUXLjd9sNA2pK1Ksv8F93/e0en87jTWCQq41PbMSH46w3UWd30rXsB+T+tDOkWf/9YexfFL6madQ\n",
       "vv6TUNpGJgBW52L7H4LjjIgq6WIL1WFdjDwwp/svFuFWk+GorTntb4htsjdDb2owfHLFc/Z1bi+Y\n",
       "3FLXBsZJTwdQQycbpiMARMQaookAwMhsqy6ljRBFCMy0KXKneFIZMvJaNqLJecFyBGAAAAEZAZ57\n",
       "akM/BGfabPcjDMA4AE4HKi96f9LZp8PbP5JQDX8F03l0WTUls7E6Qv/aE6PcFYPti9ClfpnHsaXR\n",
       "Rx0n3Z8FF3CyiHU0igq7dgJDhDcrI3Dc/ix/b4FUKP8AmkbRwLASmmnIJgA02umUhoMmcSYErPgL\n",
       "hxYB7LNoVbZ1ZAI+YEDSbe+5BXnN4VyPxQJvjW9DVE8owuigJXGAVx09aGbd/P/hI8/CBiLX9NxY\n",
       "+4szy83CSr6wo0j902fYaj9KILNVyKEps7vI3Chayrq3PzpKnAtNbn2IUXVhXjCl0TBtgtq0oiZ6\n",
       "NfAmj0FalWsFdi2g2RC6QAzHrXuR2REKKxNn0HiK41oGKqFudkhH+oTHeaqvMgmERFEAAAH2QZp+\n",
       "SahBbJlMFEwQ//6qVTe7FxEdMIAaWOQW6/aDA7ABkzE0fBHyrqEdgULIFietMnavF9o+Lv7hQbu4\n",
       "2ZA1Bdeg/G4eOxL6MN3wKtix45RohFFXY8eDiPP/NQFPl8hPLF/Sy9s2Pzfct3VmXR1Of0hfS+T3\n",
       "kWIYhSC6SxJo9pGyxi9eBj+GK8IMz5vgpuOcqyTrytDLcIYOvchyweQj46K9BC2EKeS1MxUQTQ9+\n",
       "VYpmvC4kUMLZh3VCVZxorsJ1i713tGAr5mcTGpeFIkG/ElbBr4dbPVtrau5gqt7Zl/y1eYj/TbaR\n",
       "sGiotYWpk7ymWLFsnHbJQLWs9Nti1LwhqkXlLLVVqD2ckiDnEpUcYXGKQQr0HfSqBBU8+LTFeE63\n",
       "g62sam1CVK79RroOr32Y6zTfL7PcQdQi0UzYm9S6JBt5fQJ/zdUK4MJ8h3eifmRc32/AgWUiFWCj\n",
       "7g5hEP7tCCItMr9ZOJSH2QVsYrdjZaw4SskDDgKE3kTo0bomyrTIlO1RyXIR7MT0mQwoRjy3PSgH\n",
       "xq97IGWrOheVi2d/9o5HhmUi+XYMVGHYFIqoCGsqxViblUhQNvWzj9cETlYN4aFRzjQdhubIsX5U\n",
       "PMN4ett3VNzP0mnhJZKNV1SUfdM0+eOTk6PXps/7VKejXGJm7wKz9ZdSWQAAAPUBnp1qQz8CS/ET\n",
       "6CvTQvAAhqpazRq2n/8IOMpYxWvGQBLaq7bfr5rLG2wIzlviQig/NizDrjM+ue9YzpnfmbnCLrzy\n",
       "XiaogNtp6Hu5Gc5o0tilnZs6mnY7ealhJeE2QZaluF0T13Hkv/2lHY6CDsP3H2ZmNesP60b+14wk\n",
       "CZK/ETRM87vXHqnO02u2m7CHYzoFXchvmpxcb3BGKjPWDL8RuIquWVvb66rcrcz+jmnSdSWLn+Vc\n",
       "DhWwckcBd1JdNdHqOJHKe9RYckz90M161ETrjL++Nelo9aeXIBO+tP+FMKlZepWj8EhUhoSowlqF\n",
       "piCFv4Ng2AAAAhxBmoJJ4QpSZTAh//6pluvP/iKQrALXGDCZff/2IxI7iVCCLFKftnCG/PiTf3s9\n",
       "sxF1HbEcaIvtEiDSB8wjSPFgAea7YO7/AlFyQqvTzO5QqvGYePn6rQOBTuMF3500ROshneGn/YTK\n",
       "zYJNS0Z34hu1vVfT8yr01++k4z6ZtOFVvsGZETdHc6xPFoRGMomPwSW1ysg6BmvaTF3OIiQvoesI\n",
       "GP54RTBgL/Jggd1Jp4TLhqNNBc6o8zaSbWJewVRURsJ/cE8pANH+Kxz+IsSiZmDzby2DWjkWZbbL\n",
       "XAfz67DBYOauevNJ5o9Vg7+L+JiCCc/qeQIz1RdyyShMUjmgO/Of+KpEfXPTI32y1wpi5mf7KyrF\n",
       "EEGjEKaJkuqOGUFKRSR+TkWr51k0ftkbVnJeS86NOmP+X893c0rKxIJnYrj2gyg1ywTINolIqZ8d\n",
       "WERsnLft4NJdShFrMSWI0x7ojQOfDmLIyuo4dIOHC3VeUeH8O1I1STtZvTSpMc9wGljL6+dhn2iy\n",
       "mnmg6gMhG0B8RoiSbOT4wLtE68OznyCglAZzMjG5yaV/aTsubAhsRQhUJdBT0tzJPLedrYdzacJ2\n",
       "5gLieAf8UL7ZYootD7ZlB6BvymIKevRgb7eJN8s22Xe7GhIrU+DPoN485dHBpTV9C2ipXTYFWdTU\n",
       "KmeSGr7Zb1gDQYO1pZCrax+ebPWMA24FIR7SCMP5x84w/32EEOwAAAFEQZ6gRTRMN/8D7IF0oQAb\n",
       "kh6olxIyGKVPOM95SMsYEgloLaEyxqGe07yu1UpFOMiJq9vycOazKgCSZbNDtRLgpwb01oJA54nC\n",
       "1ByNVjsu9e/M3mHBXa2c8FaQkToqub0lVEsrDUmPE4KE166XFVFAmUxolJakLcEqu2MtIqEqZ78/\n",
       "UX4CMsWiBQuqgTwd3+4rhJPTEESvL2l4kDlSML5COfNvQY7RMfOUBJbRZcH+bt7XPvT7NOBi4Tdl\n",
       "9+d6I2KNUnOSyKkFQ1hK/mwT3enViLAUIOR6gkdtf9lCKpj1ohtlB28ThyVfkHAODUZwTwmjrtLg\n",
       "9skq21uLEs+T7BAHer1NGgLs6YONl+cQ6rCA/rvcIpcLfUzzyWjsmu3APWpH3F4XLKVApvJb0f3r\n",
       "tIi4/KdjyZiQaZcpGRY/XrH+mXpDz2bhAAABBAGe33RDPwJkIe0QAkkmNTylPzhG/Pa16PnCpi8y\n",
       "Ihl4+cePjr6MEc/wup93LXeWqWnwdC3NOH89QqrVulxnRWiDUAY+zcOW/7/PdQ2+er7AxNX1Kgu8\n",
       "0AL814//OUD2ILwU1+TF499cgbJkUS8a8vZbT+/ZzWWyLC53KCK+88H+WhbKe+BhRlfxWAHxlVpQ\n",
       "mb3ccKYPDx07z2Zcft4wNXQeunj3oSs7QaqWbNKu+EJ8T9UJMBAcVG0kxvI2v5M4huyig9LzhxgB\n",
       "XIN9tf/oiahMD+sooObqTKD4o1BzIunOiXkVTjyPTXv2wYQEIAPxI0JFVfmQ7zgp3jHqR3d0A0dc\n",
       "3fk4AAAA6wGewWpDPwRw44DCFD9kF/w21EClxtkO/S1UxJrgtzWY3slqDL7dCy6IJN/Uh1gXmfGt\n",
       "TfMJyihXY+vbsG5+It2Qe0l8AFEam3VnXT+RH0Lv/SwKSdSXI6vDBHoo33a8Tyooxhb6mjLZikCD\n",
       "Bxdf/L3h14CoM7RZmwt1wVVzCypoDKgQTRZmsN3z8mJmCi+QUUtfhfTJhGj4iyra7HHLjknAm5Ob\n",
       "+VtUU7j0yB5yOm1Ne/3TIvxna79KVD56lcN9FecOGX1bmAMpurdxl0ap7pFTo+Tn+qc2LP4/rHuP\n",
       "OFqTZXCMitLVL5Wo1+EAAAGdQZrGSahBaJlMCH///qnLSaoAONsi1NqCg6ai0P6Yrx5fzN0hlTkT\n",
       "FBUmCfZnKQEmTsKHZmEdJzizple/5XR58YX/u9TC1xq4tID1dsdTA2dMhQeL2Lj77hP/QY+3kPvd\n",
       "tMkQnd2B/TnGx15xWe3Su8PO8T9WAX0Hziqh+RMQAFmS/xJehkt6/qe1d4f7fll7fwokG8JSi0/0\n",
       "OhkBRGD9pqRdhNCIyAXgplBZD+l0QarN07ux8YVbr0t5hX0I/do+oh3lsLO5Qg4/T+rMFWeczChp\n",
       "Zc4ZogC+d1jEa0sVpu/eqJkHPKpA2AOv7sglyLDhVGTEPRl/SyTLIPYB9xR1GnkfCYFgadxtWz9X\n",
       "GZkJHkEk08LR55zsAXLqvR0rw+0/wQvoCzfD49GhU9PbbuVcz9AjuZa/D5sVC3598omGC6NtjHI9\n",
       "Vt+2MvIgdnW6CxEWpfFP34sB0loswnizI2NMZB2NGSpyjLPcfDKVvNUpOg7PYedkM9wR3s+nwwKI\n",
       "vqnchIDiFuD1/ZJptYp5XGbOy2IXFdoE/Tfnc+ENyfgAAAEYQZ7kRREsN/8DRQgnRQA2RSTSRfc9\n",
       "5tTkGFcfHGxCxk17H7gOB1wF0KEmn1TTwVr9Q2LfNzm/M/CkSpH2cAbVuXawEB5lMc5LtoFlx8Ze\n",
       "sOQAWnrTU693/bKY/7MSzhyznXdjE2Nrn5rxU6hWOZG2JPbv4XsYpFFQA/kcH6/arPvgn6DMTDMx\n",
       "HV3+YuA/lt+YDDHWXQwX9JBEaPbtk9ytOJ+EcxDNnsglI2wGF/sR5QlYaEa9dKnoPq8nXFl+/ZqN\n",
       "568PwGdbBLOh8TtlITs7wW4BpVJye8zqwRogKLIG4Dvvz/lG3xdcl4nQsuKfKfxlxJFEXabvr/ce\n",
       "CLSH0MdMIiQT45sZdlfWAeUZh/52pqEDvEEfEcJpcQAAAJwBnwN0Qz8MHMpzstna8QHPqy12xRsd\n",
       "vxNp5DJYkmTWisjnxqzrgqiwInxFSIkhAqBkmX6/oXKHVBLU0OD7Q29+2tHP6aTjhEv58tNmnA5O\n",
       "snoLCNzRQiipDQit8Wlsh2AUoBaE8czDX3JyT/sqz38NlNL6YH+RZxdGSwoJxeVJP27yFSNHHoDn\n",
       "YhuPD3F4aCCbYizsfCFU+n7dAQMAAAEMAZ8FakM/A5WFEbDF/L8r9CWb3lsBFXPnCQWRUeu//99q\n",
       "op/1S1HcQ8YwH31La/FVzjpijKjbPlnpom5zHG9+LDQJp8Y7sYbds4jbMpLMvfcmeOybDXex4tsB\n",
       "OZa2x6SOxkhQapT0ia9OnCJ+HI2Lh8If5ejCu4Z49ScGvdRU548nFmf+fTuTB6tL7pXDDTGadZOP\n",
       "uwSr6CaAwZ3wx2oiEloz32N8zj/xm2r3r9zE7nxceWCUGdQ9S8nSMhoImIXIXy+7eyjpplZxWwP5\n",
       "Ql12GNuknw770E849Au36N6Z+GzmLSmtxa1ReU9JWWulf4tO/yZRc3gVIXK7MQGx9hMmyTLs7fma\n",
       "D49wc6I9wQAAANxBmwdJqEFsmUwIf//+qdChKlYOaAFetldJ8Y1IxcN1Wg6tAMtWiSPU533CGX8G\n",
       "MbpkSrebt8H4wCLxVdBf7mcCTy1cWrB4K0rs0u+CswTJV2KQldiDU+O9lZhHtyz4xBJdmkAVhHX4\n",
       "zoie1LlWeecUQxVyR3nZ/CGy1AaTKSIpx8TbWRIpHtcjnzr/LVs1AiKKHghqUphyu6eIMghaLUqc\n",
       "NKwOyB8wwIDf5HNLWiqmq6Inry8P5payUCw71NJMcQT0W5otY344YApJJ75QNN5TF+H8GHwpynh2\n",
       "K1cTAAABoEGbKknhClJlMCHf/qnRU9NxwAmrVhN44VaBuwx7kGlhSDR1H3DvbOF4S2UaKZ1a23lg\n",
       "mzD4JVFNk9tcwNO/UQZ/6QoV8dg7hOHETj8KMWDikPJP3vfzIz9gX5KNYmSoXuA0a3BEaPT9xBhO\n",
       "J5P0W7EB+w7SqRQUjysxFVfwwaGJ7tmZjDXCPnUsGkwWL4tzCVvwL8O4WFtgRr6eIDPux9YnVzbJ\n",
       "z0YvJ7oO8zFC34cI2nPlbQ4+k/KAMmYO0O7EZCCfZdyrg0/S6BEudeTjcN6DHVdQEoeTo3gLYDSE\n",
       "Tr2JWtHBveZSygRRwPi+lHv4OlgBhBjgPiOTdIDldpFrMaGeikjsw2KfgcNUK0+A6Wgl706H4mWi\n",
       "umOoQMkSC6vge5NWx2FTfuVpXIaM8V4g0WZl7ZkwZCnUjrXIXTM474SzXzCpGQJWz17680GuixI/\n",
       "BQldW0z1q3NqDzNty4g03hgjs+cZwbb/qAHx0Au5GKpFmlNRB4llSmxhxqbRkDeAQNpuC7KAIHQK\n",
       "rrC1u8GIzmOuO7E6KHav8iVadZQtC1ogAAABCkGfSEU0TDP/DAw+Gh33W1J6RdEL5ADn3XQho5rO\n",
       "+pF0NEoKWt6pvf5UsIt6S6/mV3A8zH2tmwAKxob0dn0k2q0TSped9ggnFUexskaUOflDYitvPg9Y\n",
       "KDhxTGIS0tsbI1TtsKOI+YYa4yUy9IZGwQMxU4MYMUhw4/woglBCwswRVCOWHJbJq+V0yGgiXmkw\n",
       "YUbbPLLTX7/0QhOT6GMO4+3FZLJOxQ5OqQJGA5QR8FzRVbYzcrIZGmCuuVOk+Xk25WsAqO/pmarW\n",
       "qahQx8D8cOE/OJ/en7VQR4c7JM1Jx2l6vUunnd98QQ5C/SKnKYfBaAaIeQdwkdBJeXtVRR4f9Enz\n",
       "ADmEJuuCp+UIAAAAtgGfaWpDPwFWpsK44C9HP3z2FBnB0BtsfuD0AEOF9aFY0JM1wNOEwC8m/49P\n",
       "95d9P32Do04jX/9quWrV+Zw980g/BrZl0bs7yhiX3KD3M0DMehwSK0KJldvdeUr2XxW+KR2z1fK9\n",
       "yq9osj30K3E4deN+Xy1XmvtqVGmzuR/B8aZEKB3uDUcU/7PX++5GPfE9BUUANswA2JfbjmnMAzhw\n",
       "tyjNH5iqqup4coSNaTXVaySKJmxuHnwxAAABi0Gba0moQWiZTAh///6p0JwnlACIELxXc566b7Gl\n",
       "k/xsfv37cbQPrJF+ELu006wHpQpCft73sIz6iDndTuN4Z0/Xx4i5vJnKPdex6iUXXZo1ksuSc8sH\n",
       "mG6pTHbbZd5TrpR93sRtcDrKusH/UWCAS2mJ5aqBoC8a+nHgt85Cg5UPT+ynxKhMIDCD/YXdXvzA\n",
       "x5Ej87ytezdUNU2Vkzf/7A1vUx5h63i/0XFKCPn0t0VON6oaCcPX2UDbW2UPAhY8V9ZF04WRawN0\n",
       "egI7nSewgvH1pWCbIYGyw7mLpuphjpvaOvMbRoUZA6ykylvaL3rBn1yI4120MqD1IOZKV/JEWdMk\n",
       "iPunCdjWay6HaB6kKlih70WVSgmk9mhGavW30FH+MaVGVO4qN7brgi1aUYCJPFlo2SfhAUqjsPHx\n",
       "kkXgMAk0/Zddgs/PDlo81FYen/uMw9Sv1DsbQK3JWMBtOLSh9/ezSGT0kksSQVHGup6rbQACWzvy\n",
       "gJOR+xroPMMSFg+PolMCBK21nD2USe34AAABXUGbjEnhClJlMCH//qoH56NtX0MgA42mNYjKK7HR\n",
       "MHU5Rl9qMIBIwxKKZyPGGb9bSnRLb3CH8bV1Qt8UKnYZrEE8/XOPfsOMCQS38pe3qkilnflAIims\n",
       "QVOp8WKmbBu2W5Dd6Vgsdu1aeLelL3dQT0VtAf0XRiZYyvbKLOzsc5jBkTDqx0S46DJFjYBoAEpL\n",
       "s3n8NyuK8gMdS3J8kl19KQ+FzbcfY1FkOjaT9xWzs7zpf3D3TZCogzWZO2iLosWzmwswpHoa8M/O\n",
       "6DKjJiqCDT3zNnR6u8rVOtsg9fAu4VL0v8DxVamSqKBNoLsuesaBZt4YlQ/cE5A0utkEhSTUGJUA\n",
       "6ekAY6XFj/xNmGJ+ztjMFhVOfQVk/dOFXHC3VbviPXsjnkK8xvzBqnIdbuKLdHlqD+w6s131kygv\n",
       "CMvUmJBsVX74nqjec4ciohB2MHp0J7wH0zUdksfm/jijebwAAAGNQZutSeEOiZTAgh/+qoa2tm8M\n",
       "/UAAQ4+jtb0JQzGfdyr8jVIjKagINOkxl36ipSnhCTpDHuX0ln96/PyDDjutyPbmGvGTqPIB8/SO\n",
       "42gUfh0KWrL5lC3DvNw4MHCy6Z5jXeI4hYad/BOQUK8zwS8ZkHVACBJLDcw40Hf5rDZE8klz889x\n",
       "8l5gK1VG6AIBWXA9NAtLQB0Vf+MzD016lOAZIvnAJ07LS5HB8yKI7hGE9kaOeo0U3qEX07hveM3i\n",
       "62zpj4cZMJ3BgUTZ/Lg0VlcSdp8/HRX1lfHUZqjywD8yHc9oaXIWPQEW3Ie0YwyvWXqRQYPEw9hB\n",
       "4sTevVpjW2jSlZF5fEObhRwnW7iONiw0S1/3J6i7pbcwV+4/W2pSpqOc4P1559qq85uH17kg+b0J\n",
       "dAIIOFSweiEStILYAeePVrtSyjtWsNU28Q8EEfqUtQ2VSEAv9tJ/W/PBuYr2lA8aPvqYWriIGZjI\n",
       "zsu8+9CC87NFpGSicSkBYzidOevcItNNX/1j2RnkczGyBdtDPwAAActBm9BJ4Q8mUwIIf/6qjVbt\n",
       "pz4AJKxdewNtjBy183CTPXONAXF48FD/5BYIsvyF3t5qaTaQ77iNVr0M0mmTtDSWpsx544FLygyc\n",
       "uay3Di/T/9G5WdR38Lq4O39QpxVV/fR98lac/7PeqGDog5pInKzZmcwrSzkv5/IJv/8uxDM385xG\n",
       "BxdGWnA9nFrApuF4fGYCXDdMSyhfUp+/zDyThsviQQQnobIwi3XMxKarDGR2kzO5VHTLdmDygqiQ\n",
       "RU+SHDN4J3JWEv7FgJFINMZ7b3UX6y2DZy5AkQR7kna92i7iYhLqcu3EcpAt5CGG6ov48mEsKPSo\n",
       "L82aaA7KcdozFiet0ZiSV1PvHt0QlpD9eppoRXPceWMrpVi4n3Bid4Bj//8rJhKNgSj1PCVngjUr\n",
       "IhPbHP9bsO8hdnOCN8LdXWHjsgbE8liUC0wQR9IGfBzhPph49Gf3fVI/TXr4IJwDjTzEM6FXtVnR\n",
       "BQk1vug2i/CwqAZXs4nrprn+Kap4noqezWrRIrCbkU9utQMC0gybnP/jL+4Be0FAzS4QpzSQa8yS\n",
       "5WMYIIMJMDmdiIzM3KA/SE06i22cQasF3rOJ/mOy2FhMCSLliXEGvhcDgUEAAAEaQZ/uRRE8M/8K\n",
       "YSAhe0XAAq3mhlDM6W9Pmk5xLBNCmvi/S89j5F525Y/sDglQhVwuaiIfi+1hQEUD+0dbIkOS7vY3\n",
       "5E0zwFZGlK4ztr72IgZ9DopWRU07hgyXvFs8Q+CvoOIN5YhkLKK92iH6L0u3Yr4WrHAwKs7LBtaX\n",
       "zlk7/ivlAqz1c938TARraKmqyfjylxBHx83gOCphr7/9yc/f59hGonwsvoHnXZ0syuCwejEsXSq9\n",
       "YEaIvEicJ6B2FprB85rp06znLu+nTaHvsisk6LX9WZW/vx+nQmTLU0ZA5OSleJKE0dueB0DIrWeI\n",
       "IFy1+cjcdN7QJd/cM1fBDtkowjcsUFSucx38GowtvzITWC3EjswGspt/O06NAAAA8wGeD2pDPwwY\n",
       "s5ACaTkFBtk2//hKNLmqOv9Bzio/NRyQBazP7RBiVi9Z3rGI2wBOJDYBaHdMKd/vR+823/PeXT3M\n",
       "ZMEupAZ4jloJDuz+Q+7q1hRJ5s0NjasNkxpV3uv8rVuiAF4VvPEkByse6j1PJCRrCPOMx4Pk/LW5\n",
       "icezWWyH7rAlPfJa+cb4wgrlKVKE+W3G/dx0Y5sycKHD4YbgxAJI6SCn0u0BWgWfzFcFHIA/TfQ8\n",
       "8J8PfT9yfrCFXc//Jf0uYDEGb5rDrXbIbH9ySQNiW3eTtJ4NbMXyTn/CP1lwnYxJ0LN5mnzwQ4fM\n",
       "QoOCR99CbgAAAgRBmhRJqEFomUwIIf/+qo/Mifly62gBaCnAKI3Q4ulAVnl99RgJyTP3+8RAJ2rc\n",
       "2nOe0AsvgW/ePnBTRQXLsL0MhHWFdRyS4UttRh+1OfoaFFACkFVdHXbUPWXFcPkwpTlHzjGHzltr\n",
       "kkUXuEJaajfvAUE4m6r8eM32dlDLfDH8by/HsXm4EuNtfaijNccQ73qp7CCm8l9w6pIJeBpROOZU\n",
       "2XyAw8lWMe9CiepwDk7uHvvbb5gBLJhZ1G5LgCurZuLde5mm43F5RH8fp1DblmmWEnCvK/F7pUnq\n",
       "jAOmL8Q/jA1r52ReU3zb8nxcF/SThRD8vvL8jL5Brg66ZdW64yQLEVIvuCaEiWsk1ApnF6nPJQeq\n",
       "V5idSSnx6ApP+qid2TFECitL3fxyE0oQxAACmv69tS47CV2csLQhf8ngAAsQngOnXwte0N6HO2FK\n",
       "MZ11kxZegxrtkxV7gV11pb7kcZ7oyLG4sMaWp2cERt5motYBsivquWZXUouZRnqqHUf50u243WwL\n",
       "mURai4QiWSKEj61kfLeC5EC/b0cC9/5lyX5cPVwJJAzBSpkAZ1t2fAr/ea6keayHa9v1Q/W/RGga\n",
       "Z2DwpNFIeZBt3xv+aFBOJScw9NYGbSVysq13QiO+CI4+rfOAy9GU0Fnv3C/tuAe6bQCayI5YWwpv\n",
       "ZyralSaHQcMlkmCavcAAAAD2QZ4yRREsN/8NrLwAFjdnPUg7jE7m4bvjUeC0gOFdrRF5UQA1dgfj\n",
       "32Bfm1tYY3Vc6oxckOG/PGlsdgO2ift46T6CcqveMn52rraovPnKMy9VJC4bZ27F8Zy4e2g27rlz\n",
       "kyE+jNxM0UaxtBV7rybSaTO5ukHqDj2tNXAR4qL3VJYAzEFtiZ45OtSkgbP9VepA425zY2+gVKr4\n",
       "nRc/ga48b3PVz32LHppH31IqnmY11W/UJdAs5Akv37I4HQIUeIRC8Ex4BlAlGFpAegALoDImr1SC\n",
       "lZou1M/S4el6FQOuPHpQ0saiZcX0JCUotHb/xa+7bJPbjViBAAAA5gGeUXRDPwlipWieUdi5DGdo\n",
       "ALbJEVytygnzTVN/zWNVxd0ZDqJ4qffChAj3XKBxtaKjmdiRQUFW/HStPWdJs93H8/VB/eoBjmvu\n",
       "Glnj1fBIbvl9BdjtHaDJI+7OBUevQos4/WWq+p1iIs9CG5OOVKaNh+Oat0b5FuouXI1orkyxuoaM\n",
       "x22Rv1gT6cWIEcWvyjT9aVIC0FOS/WXneWNKPy3WKuNi+wuNQYQ2w5Ql4CFW5D/Kcj8pe30rm3ZD\n",
       "fK0oodvURA/KwuFssGmYP9SLHq3qhCkZ5GQ7QfqlB+xnP6ftAj+/luoQAAAA9QGeU2pDPwmdn7+J\n",
       "AUkAE44rU8eM+1o7oRKU+LRdaulLuSCL/tKAJsxl14iura9z3yJGhQdtg4UOT8NBE30MrUorqwrh\n",
       "cUFxhxbjgiDSXjjByQug3vrcTU/dHovEQJjIskFCVlDHqOV7cbPVMsaZfkVp9cFpZ6s5CB5D2FAA\n",
       "BwtbzpPbYFbNTgnhJ1GZJs5GVAaI5PtC3FsQgHRvAplYRFqdwHZCQPPImCAn5dhowe52lv++6va+\n",
       "W54ciXLMGr0eIyRKky24x+CGMG7HImFK2WBRpOXpxxI4C7BPPi87UqBzz18voPkl4bCt3V83zFIY\n",
       "KT90qwigAAABy0GaWEmoQWyZTAh///6qBKgxG2ggBIZgcrSZryao8opkBf6UsjoQUVKlxB1Fsn3A\n",
       "/CbnkPmR4C64MvvUsw4xo1TpGKL30JGXhgjUiUbhpL3CFWTfZmUDsnjKluVKdXefeMpZHjI2057s\n",
       "3AMVl0MZte0b+0dRsuNQWJTCXIc2HrSNr6SoHzh1UnW8y8I9pWcUFOroFiuKZVgZtaLEVX9/FPB1\n",
       "/e+IEpnbBQjaGRwn+pMS7IH7EgtHOuock5K79TD8OV6LqOwBpL2SE9tSTLDJ/5ZF6ZTn6bxQIFxX\n",
       "rGK2sFYGNXtC0NaEnpHjX8/cbwvOeJbvCjHnmMP8GEKNRaWo5HjK3Gn80oeI1gasADp++p2kx7B2\n",
       "70LSR4zO94h9P6biTABfQ6UPKPb6r6P9mzGRCuAY9KNmyfZdRBZOTaBjTGzmQT/p+JlD4tmMQKXD\n",
       "EkCYYJOmKky2WhmvlQWBvrVbIxBF2KtdZZbBgx6onGWcia9h2jhorgoCEkMj3bY1OtFAfmxnbwbs\n",
       "8c//xnFuPoydad3ISNx8DK4CjN2xIc9I4skvFDeTvVKBAPCuIM4wu+xbSJghIiYswqk7YiTZvW/8\n",
       "m6XwreLrw1bTZIrR4QAAASRBnnZFFSw3/xDPv+AAWl6vlGjXkgHOusm4yC7JyeW2XXoDTY3CRRtJ\n",
       "AiN7RVO9U8FDscochi2iuYl6so7n06FUOYbuVyRDaEjl9xMPbdxtO69/993id20TSz4cxRbBSBHG\n",
       "3bfacubRgvdgZFkv4NyHAXiPz+qUvuZChkMQnybx7X7/C3teCgWj+wnvuyyUD0Gi8w4auXYDGSs3\n",
       "sZmlZZ4Hpx2FJXvAbLz1tIRs0oDBxBLeboTkMiz79ePtgtPafO2a798oBp+lUGAU0Gt65hX6HXWO\n",
       "UsPoyksxbskajfquWJ1xlGoDetOqcGu3oDrPTnxCiw1mmrCEiRaQnrUweYPnlRXBncfFfVYHHrO3\n",
       "h5f5NxdKJYABVNlFw6xQRTkplGoZvcp7AAAA/AGelXRDPwlgyMbl3XiQlEZIANwh3Cpc6QWi3zUH\n",
       "CcdouMR4oKyf4j4/tpvUEo773AOv3Yw6lLG3Hv/6U+EYiCot4tWuktEQl6TwPx+XVMxM03IOxe1Z\n",
       "eLBvxV74SlWsJcE7mlizC3v2DmN/U3yoSuYdlteEjP7NSmdVLjwAwCcY1NCjbymVoxEvVblKyv2b\n",
       "1nqCndwG2guSL3H25wbExBtb9DGF2HIjIWDr+IOuKkDW32LROv3QV+FF/aRlsRbWM/fxdVlAJA2w\n",
       "b4qC4iBplM8VogVo4kyC/1hBqc+nqheQfyJ0EUSex5US18frj4riwOMzqZo1CU/sO7qy0QAAAQAB\n",
       "npdqQz8JnZ/4SplGAE0j8AdZYXNyPXQkHm3Q6DNRYwee1oFM1PGrCssW862+BTy8Zxlud9xWpn5Y\n",
       "UFjbUDG9jDxqFncWTCc5WOaa/yLRKZtbSBxNVYYCi/8reuqSZZb9BuH/FML6n2UfKquaJdwbWSHF\n",
       "5Rj3L2FIuIpLWYA7ODcsqyhHQ5D8I7qD5suim9BPpO4XdyMpn2TVdZ15qIniURYMn/TXxN9BzSlR\n",
       "/l2ULAabZJ6wVMPBsoSfmKkriYr0OJ/qsYqizdmZMBElV6JrvknksqaMhoVOTtgnfDdMfzG+Qpac\n",
       "SdRXK9CZ/XmwiEwDYP1CJQcbAd1bQ2QG8kOxAAACOUGanEmoQWyZTAh3//6qZ961tiAJwVg2ZUQ0\n",
       "AuYWITkKT8jHnoYoh4OGRdOMGUPRqJqXk/PRG+sVjSxTpMf6a3s44HUPuPQS2++yWKrgPo+iQGyf\n",
       "yBKqpJMj1xjFyw4bSpS0EhFe76VkA669V8UlOWx6YBY29o9aB3pQS5Ga7BffVpFNjoOBFcC4ZG0O\n",
       "0WPNk7XjNmghnJShdhz0Un8+qJ97qdNOMlL0m1bp4x/fVE+UOTVepltGNY3HlF4jAM2EznqI+uCT\n",
       "kepXJmivEvWBFpuWUIBsaqflh7I16Sacz9ZJDsnQMG+R6Mv3aSq7uP32bFK9iJXjWvWT8ZPQvi65\n",
       "DU+KZtnCc1jVmxrO3KaUuB07GDGSIlaI/I1Q7NllrJYOGS8lXv9Cjg6YMnXF1Cu58Z9oo+7rwwn3\n",
       "HA1T+LbdMwne5s+L281jkBp/nVQzG3jCR2B+xNB2DxYiiWMAs30pM+IaHNiwDrGQSqBak809ny/r\n",
       "9pKAw1R2nvkU2dq7yiJlFmV3eNPnJXWqrIGM3nawtah72mHbh1x2FhS7vZEZlYK/WXxwZUA78OCj\n",
       "Cj6bx2vJ9U70lheVTMKn5XxWQVHzxZatJaluW6QVfTqBRQj8eIFSM+SmCF/50ZHchMhx3QlvNQgw\n",
       "Mp1wbem9W7KU3UoPai5EsrNlU122ymoDmpmDSAmQtVLV0MAktorT9RctPf2YieFWUHzTL/wZyusJ\n",
       "AdqcCXF6T7mBYfqavbVus5sjqxOQlLlsOKI9p75sAAABekGeukUVLDf/Dk59zjAAW354EnQQ85sG\n",
       "pXAAtzs4iqiY3FvtX4RdXLmLmVy3i+m0KNn7wbRusVl+aRPxZfgTA6NAGsKVkD/90tXv8DFh7Hyo\n",
       "A01bT8ktsqQikx5B0KS3Yfdr/dt86b7mISbfjeyFCqNo0Ps2w/fKYuzzkudBys5cfnzp2ix66SNj\n",
       "7/D8pkMP7K8irw/i9TCYGZGtXl0CY/fZIYwhL5UWNahEt6HDXwbLOa2D5qN2F7ypXH7RW/R5yPOB\n",
       "V9MVXoXEPqVTldT+r9MCBSaT/TkGoT8Vzu3a6ipcjFZl+NPHTZcIR5ljuc3ICujIgAU1sxd03IR4\n",
       "pX4j+umRggVQxREmDhXM7KqwCimLwxDYmiZO3Nia59pEugrlkDGHzUfj2lXVbINCi832C8UY4KpD\n",
       "D4c7iRAAiQoMXZcEb/CUAoMxiU0WIgku21y+vdVhY9yLLGHlSGFm3JOtDObHl7m3MBuXGbWF2a7n\n",
       "FPHjVi1/5sRnQ5ynMQAAARYBntl0Qz8FQbQjCmgE1/++2fDDxgDg3y+Bv5UQmMpMFzGCYPd2foYd\n",
       "yeuvn5E9LKT/+G009x7xIW/aBeJW2p9TascwgMkfFsKxjMNg8WGVvylMmC5TG/+JW1gzNjsvpl9W\n",
       "KuwCX/Cxb+7bS7OUvAyyy9YR59DCjxhhvMJntTRMA7l8r545pPKnLtlRWlY9J9qFIGGbmZ5DRizZ\n",
       "DuoCspkDNx2Wgl+NYqIQeWjYuFL51G07zYHYmowDXwD7NyPv7BpyNlBrOEMxuhMdU3wfJ7SdUgyR\n",
       "Byeb0KsBFain4JV/FM4zMF8QEWzIVql0ghFDyOqrRyNmOeTEBMlNqSkQ7F5nKR6ViXpQdva2QKw/\n",
       "F47yuK8+l4tfpgAAAPcBnttqQz8OKQkfsQjOgRKd4ywKXL4DvTlLJvyN+OyLTEqSB3AQ/N7Kwgm/\n",
       "UVHNHFz0fICwlm9xtat2tOxeC6tC9MX0IyEduMSSYeBn6x3NAE8vaUQD6+6SedVMI6O2HaoupJRm\n",
       "21aj5918b8cSWCsNxJNRBd3TOwJSwr+9w7LCWn424JTkhTvUmfCtP+coq0+yAe4fYYi8vXNMcNrp\n",
       "wwK9lWwC8bes0ezukNs36qLTs7M+l1GfviwzFzyRNPXysxslrYblMmMmLEyjsfvqtgt+8iEIdfwI\n",
       "CB9SOfcdCohQr2W0BnSZM7PxaAEI1VJacz8TfhCQPSexAAABwEGa3kmoQWyZTBRMN//+qRo3iLgD\n",
       "i2Z73fvetkFcaY3ivcL6n/ugE2xFd36K7D6yW8kenfw7aHLUzTjYLrk5mYDjxeOZexHJEyj/angi\n",
       "N+z2Oce1TvfTBIWU9kLtiFD2Y2BzF7ePxCZiHsHx+Ar2yNa9vscffnK3yPaWzBepMPtkZQfwZgTE\n",
       "OYSywGzHwcP+iJrAinfGepLxYpMlL3mOjzbOJogWbGOBBEQR2jBP/sI5RxojXkQ0CaqZsl8LUtzD\n",
       "3RQKcYezJwtUOGteVcTwjwXt6dhlR6oEUezcsLOKNV8WvJW80ceRM3lN/OqX9j0rbPXycvss6edR\n",
       "Z4Yph+fLLiD1jPUAE8UMTh0wSZs+pP8iiZHIPywsGg7URJEXEIIcdrBZFu4yhB3yJxbMiHhNV8wO\n",
       "FmohFZeTNXl9y0EgmnyUWI2iXwEJp/U9ql/BiRgx8ZjqKS3tuvgJrTdxaT/3iXxssV7B4ezTIUos\n",
       "15Cs5U9tFMyjTpL09lnC/mRGyUvGcxmiz483NFeuORsBBwqwW51BcwVc0Sz3Sh7DpkV9z/7lI8F+\n",
       "OX0wKQ/PfavPlHrkzH0suTwClw84AEFTROJ0sosAAADmAZ79akM/AfYEx2yvNufoAC6VHykKe2a2\n",
       "Lt5dcPyRpX0ZwGDh1exEjDQsO9wjlkzv378Xi0XNJO+7/fv50RqKB5q1GO51D+MxRlvkmlTakWOf\n",
       "eSIljc6YoKpZAN9vOEpsZwYWLVGTdjI4+1ximGGxe61Ak0eDdlaBpfsAuyzwk+CFqNO1Px2B1CEg\n",
       "1g1HILOZsDF23+LfzFM3Eno6/qlxN5O2d+7qN1OdfxOkQbYy9R9rv5cUN0dAaWuihwGExo5kGRNc\n",
       "7q0+FeRk9xkQjhQXDmctkw2My36AJ/km+vYTNpKsk0VIbZYAAAGpQZrhSeEKUmUwIIf//qpLPOXw\n",
       "AEPxu5A0eon08f/EF5znnfXKAbMdfU3EbIJz0+4ERzRtXhURPCvOJmfRxCvJQHSiLdyz3ImeGg8z\n",
       "AkypRLyx9bCXfedP9Rj0wgHKR6L9zE7EjVMNEXmoL7ea6UOqQggVKCSa/XkgC3XYHKyWdL/+sRar\n",
       "pBpUoXz7gbyofVcR+nU/1tYzoZT3cy4ze0sPce3HD3Xb/Vigk3ZVTJUV0oes+/7Xaw6qbnM1C2T4\n",
       "D76Xfzz2k8fi3p+e4ECyin+9GtziW4+sd7U7EB9ZF1ja8j6/09/RGfLyadspuNVlYr5mxZu568T3\n",
       "q4aIzfZFwL4jvwJocWDbKbvNGwyFjlHw3GJIP3Tu756JXAJ0VfB3ZXqx0fKWghoB+k3fUDr9QbMN\n",
       "wst14StyyZDBqb67bh6OCSPiFEO1XMWGXbvSeTZKg7FixHfrBT8yrs+ZIi6it3jdBpVSsedKSeHV\n",
       "v6TNZSy3b65liytvAfxvqPK40Ym9iEWQGrqmHJ5/EJlt1EMksfSgRLxZ9BK2gE0+dPkZLFHDkWDo\n",
       "FVNHWJYe2UgAAAEvQZ8fRTRMM/8EkaetVWkBz7Q2SVujW/sDowz18CWtcaxECJ3dW4EIxmBb0Gqr\n",
       "eDmw5Fkg9VSv1ouXe/zCl5UW7+igZqeI7q30xHGLFr5NWYSP0Tn0RfJeQllE6905YxREkF2YvdM1\n",
       "JHD2196KQBGQuz/e2dMCuv0onjR/I6Im2qEFw8PsEa6GMKqXTKX3g7l50rnDwO7WahbN1cyecPGC\n",
       "TQGcMSYfkiNWBLXIDWvtyX+tHsZgeFdtBt128SQ8ZvbFKhwuWPAA0njAlgJev7nHHUgIfECv1KVJ\n",
       "WOImier+ac21FWlplTh+VwaVEeZnex2JtXoW0rPjT/EU94WjymE6AhW/bkwW7mH9NKclFul3G+8n\n",
       "b3rcmS4rwoBOM92VOfMaNgUROyY8ku8+4w3rJ3mnAAAA7AGfIGpDPwViOfBF30tE5S7lIpSplP+a\n",
       "QAkT/J0YfP1salwrrjrdps/6lrFK1YBoQHM2oZ78FQXpijT5UzyCfzJ02w3cOH/bOkGcLREN5P3w\n",
       "j2t/1oJAGtt+i1KE7WzhtDIemuLuNsx7eMS9msdEpGYZpLam0oKcJ8PrOjJnB/9+xZD9xOc9YhbA\n",
       "fWEIyGZOlBicziIQpOmlCytqmWUdcunHLwfLiUK2J14FS2CXuMfgUNd5xvVwhsZlL5vhP/G6eOie\n",
       "2uOMov+X5GRphR5EKPteVd7VXk8PfjIOaPbLP48+k6xDeYdUsowKwtncAAABvEGbJUmoQWiZTAh/\n",
       "//6qes4dVeAKsqjr7EDjsvu+y/PS/ZkTUPwUE5mDAesehANsPN3jY+HbRNSi+piwOcb/h/OM750y\n",
       "45YevQcpTohsvLOPatTTqekXXO1oc+mognFMq90Fc5q/XKJ51Bi217V2bm8VQE2kLyyW1dBr22pI\n",
       "zyGLFCYOeLDTafXTzRSISuUUXk/yU7yU8nfOwXK0aHWCkzAB/ndIQURNG2DX9IgGTXAThtM1wx1k\n",
       "Lp2qh3kGsbIEohoVYGF7liH/DT/AQKxCK+9Ri+v8NAnvzrU7AqvnrS/AZH7Y19mH+AADpNzzZqyN\n",
       "IZTBlp5EXV9jyEQzQzkAeVeQrBr1+2SoGCDeo5dzQU2HbLo6Ep7bzvc2Mvgl4HQxXPPlUK14i43J\n",
       "MTkTumt1XRZSJHRIu1SK1u8vF4z1akRlK6cZJyk+4OUlT8XDTG49lFhI6KyCv/3P6xjy2088RagO\n",
       "1juVCwVcCZ+gCNkOjpkKE/t73e5nEFQLeOOvgoW21JksHOe+5Lbo4fJn5BtxRTCxrTsHJjas5w07\n",
       "TWWuZ3/XxIn77VU1jZnKNZ23K4u7+gK/IuGdr83LKXtttQAAAXdBn0NFESw3/xFGWQnSAEvVBAyg\n",
       "tNuXAEytpfgn/bbIv8+5E4XYL6nWn0l9JPRQq+JQHUXXA+7xkgc7PPUV/sZdn79He3+IchOpls5h\n",
       "zV8KTqCQSp7gQ9DpnSeLeNOOPnyAk+pRN3dk4iBfTEvlnRgRlab7OaqNTgLkm3DDw1JPd/V5biwa\n",
       "glpWkZMt5Qhs2v7ypdeJyJJokQ1VT3F7RZ6DWAm0rqcuBKPFKdjmD0PWxkeW887e0joKWDWwtrKG\n",
       "z5rxEbAwbDE2KZ7UKzlkzB9klps2X/ABRH3mqTtXA4ixl+K7465MpSKcqeqQLZ4E0iDtA6bFqm+1\n",
       "PjQfuH1r4/S2IW1JvUDE+9s0Y9KQVw6z1k3vojvVL2t+cmPXR7sxfxz2sbv2lnrwQIznvt+xkHSK\n",
       "LNFu95F5jQWWkYEf/rosQlYrFaE7rW+vdMb/1hURVfmGegdng5Mq5k88qEr+NlUIpHZwo5TsYrG7\n",
       "QEkEUKCS6WBt42362NAAAAEPAZ9idEM/ATVDHiGvwqxr1CIW0upiceIFTf70kWNF+Ei/TP8FM5X3\n",
       "whiEXp0wCCL8kvBr+MDe1i8cENv/5+zqD43q6P6tHf6BHouQcC7r/ih5ggvzHBXNwLtBKMIYg3EU\n",
       "jY4zN+uj5U2IEs0yFulFrUWUBvSV6kAhXbya+jbOD87TmUyECES5jmtainvXfmq7dMuft1yZgVFY\n",
       "Aw5JyjDJ5/fuj7xfoN3/RPh0R7FJPn8GiskEfoA+PI0dWm1KsYh47w9wjAtTaBpmwYjCmIgt/I//\n",
       "NIzyw8lj8wcXpyEHSVwpsum/9gmlJzt+joYuSBTpQqYwQD374g0ftNDkaBZLKYejrYIGFJt4QPMd\n",
       "Q5KTOQAAAQYBn2RqQz8BC6mhTZcPEQeoigBxlvhB3uytybXGAgj8N+EYSJALrDRzAMNIL0dGCDY7\n",
       "3aCPeRymLo7Rbqfk/dFsfwnzEINsoibWT3EoE4YScZwPjwVXbxsNsAdGdarahJyhY777yLfMPjGp\n",
       "GG7KozItosjEBDvPBfcFhM3wHKLF0hAHyxmv7vwWszhuXvPbU0njlCwMDxmoQoy80mykvzH6UpuA\n",
       "4EERjVVq+QkNY8Amy6CS/AF/P/ipnUmaMs2jhWogFq3T1Hp1vnSeHm86VhNXpMWRgreHmhnSbAwo\n",
       "eLQiK0Vdl7LefZ3g5E+NezW9LDz/+dfyOk8lYuETv9aSiJFmquntB+bZAAAA6UGbZ0moQWyZTBRM\n",
       "P//+qmP8TEAVhMfeGQLqUZib34bhcfPkUnjGJ1LayYWtK61zmYLjhnfEQUSirE1hrbJ8bKjNVSkl\n",
       "S2IYh8cjNkJK1JXJAOAot+elIc0nxZSpOMUjtkMMrr6j4GxjZAw8Jx/ZHZ+TFy4pzYk5t+/o5nEu\n",
       "+DY4QAT7rbYzKyOWE7RWw8S8s1xpUcG13aeKOuR34/l8kBYU3iKZQwHFKKVTVd4+NhbLJ/GqVus7\n",
       "LcO94mzJDtpGIJeiDXor/FH4SN4ejiVOU/Z5k2z4UUS6fuus3jtH9sGQnCfQzDpTVu1hAAABAAGf\n",
       "hmpDPxRS4dgA2HDTOVAWFbrw0Sxwe8scRceppQoswEo7T/87z/rD3txZIT+uSlRovf8rNZVJViO0\n",
       "OIdHadO57C7bE5g5Un0kVM896yVKwzaGcfDpQfeyzDPLH2tqbl9SzbSs4ocQA5tpEfmiirgyCHWv\n",
       "Cq3k/DcrJ5q3sLe1stRHi7NqxJOypfqjG7AzZgm+TEvaIN3FTdneRlpWlIYzfYzK77oc2MYG6M1d\n",
       "AzvrIhu7x+mqqRp5OrcdahAVqljijG1NjgUCm7Hgjm97d/elesaB8Q1zdeeP66s7+A8v559E7hnj\n",
       "+WnK8gXTBPggN92CHkipJfl33HTO2d/6gXUAAAGmQZuKSeEKUmUwIf/+qmKA10AQzyx899ZIsHMJ\n",
       "bnGCTbGC0FWxf3ka8NQTX7WwNkfB0jO1uPizXnOlQh56t89t5xUVTyUDEoPYBK+Yi95moL3+4N2B\n",
       "grf0Dne/cMFAEWn974UUEUzQE6lhSISd6dOGDmrIb3MsYIPwAWzX1g/25czivk/wb0xgWYi3Zwy7\n",
       "UrmHwm9AnW+Dqk8kj3IIItXOU3CM3RM6MufTs6xq3NPnunuIvsaHDWY+m3G+2lCuT9H5RU1Mk4Om\n",
       "Zs+jRpwX/FYUFZx24ROd8Ujk6pFelSbDdjAlBEEZhGHL4SDDJkjnwb2rp3f3H3Zxz6i9CybGbZfB\n",
       "ukzivYZYP0GhW/MRNfZ19pOHvorVyiZPHpS7fUdbVgEzB6TjC/qA0ZSj54zSrP3qcwusLQQUND8H\n",
       "onuGIAW4te+yBoO/z8rcUDESyNjsNq/lSXssC+A4KeSEcq2+zRREe2VJ4dd3NDblqqc7uUl5IMQg\n",
       "ergkPzlc25+K7e9xAybNaGXsrUG3K2vtN2lS45jMHWN4SREIu4qYRZ9CclP+U+rORkHDp5QAAAEA\n",
       "QZ+oRTRMM/8A+re0l4poOoWqyPYjUq//2TwtRzRqZITlRfH1U0kZYzJzf67hgb9FnPlM1Fi+3BJ6\n",
       "10hG5tsR2i0EMmyLgPE/NligbkUQusMVV0ybeKm1jVxY8HPTvD7iBXHU0Y5JlwkCjtGiwfwMrYQc\n",
       "G8ZfAW2ZS0d3nb0dc3wThEjkfdkVe9OSHvWzkwd+40MgaCUx06CMW+JuyVH6sJkiGTk0gU4qprhc\n",
       "g4vGmKEbGDKzr9EZcfaCrzzsY0LtSpqhkW28ksHdNPhjLLvlCulHFLCv9ci6Xp3t3rgUcAG6cyJE\n",
       "fL2s0EXS+tINniZgK6zihE8TgyPHoJvlHrPSgAAAAOABn8lqQz8A7gNb+ZMRDbMuT0hr9So62LnX\n",
       "hxwG68gUlrF4GysI7oT94EWeLwTsI6z/TA+HivR8GPQdQqK8XT8IccOkIZfrvRh9KQI51RwlMNaD\n",
       "9BG5lzGgp27oz5fDPLBINbR/D/v/X6lsY5DFEqWutdnNZskSPeEF3mi2R18SDxUmpJiLmX+hHy6A\n",
       "DtiUc4+J+pkM+EqNaYy/H6FV/2ns4pVummzyB8fxXH2rY7Mo3dbFTsV86jTMmJotfMr7hlK1bcLB\n",
       "PqWdAyx6YIl33CtbPKly8rwTcp3Jqx63osCxgQAAAZlBm8tJqEFomUwIIf/+qkXNFxACrmPLH1/p\n",
       "dD+fqGuwGCAsT2S5SH8tHcjG8TuyuZAv+bRQi0qT93+Hxl7LIa8NY8Jc52YkQcTyw/P/hxf+EdSc\n",
       "ZeWcJkuNdiozM9fC/xYTdw/ZtOZkrsBc61r/+CKUFR8U+voaPGtx9aI1aGFBTXCrrOnoe7D4/D3z\n",
       "xGUXdYRv/HQbcRmWtMxC0XmSelaeI/0fMw8ftRgnYJrvBLgweaH75a5apvaRYwFnBfQc41bIz78g\n",
       "x90VvIRhzm4XVwCC6vNQX4h0gM2477BxuSJdKsBgTieVgw5zZSbbYy8sZVGJ+Stxz4XV4ZfW4nRa\n",
       "2HF2yF0KN8/NGqWyXlqIgD16d/+9+IHF09viIG//DNZWkEtzRmkm1Lw6F3lGkhhTAc4M/3B0VN+F\n",
       "FfwzNqC1wOOwJNoudMl8MBLp6/X6L9KDu6EzH5YJ4oYtwGBVFed2IQ5o7MndvOMXkzr2gEexndja\n",
       "kvGmkUPqUDvyD18Mdn1fuM0op9gmgbLUR5iIwpRmt07/N7EHpSKS13S9AAAB0kGb70nhClJlMCH/\n",
       "/qpj+SwA4TfBB5hztZcf1USJzRhs2YWAM2GpNnLRWwj0eXr8oALXTqrnAUXhZzaJTYR1eaNDuP8o\n",
       "CVTk9PCyNszEq/xMszZypRVS3/gnhmPQP9YsQe0v3stjddgmZPh0+Do53usE5YxlbvSAKSIIGT/D\n",
       "AVtABFzwJX06jOZ4wFX+f/aB/9sRKcCyXrT1TVz+1D4nxgbKIhSvdVaEvtxOuCIypfUMM6m8/hd+\n",
       "7sMEMR0EsWlDE9Ux8noWGgTJZFnekKMHeHfGAUig+QB6axqqL2HoYUJgEV7TH+SV3a9LkfMIiDkx\n",
       "zNp/FeraBGqEFSnYm7xuOae4qcqBPB9jRwV8RbNFczS94pV4CX0IHr77yFnylrev9e/wmiLSvbO4\n",
       "+fIH3DYhYtPB2kMPNHW3gmX7E85cMru8bAoEsTx/FRbdYA53ojSKUQihHt0H2bnHUPFwgq081Lsh\n",
       "soDcR/dOeX74BxKqFS9QWcLUQkA0wqiAHwUpQRG6H87j/nStGcAj7oHdlpPKvk0iGQVrHtNo0MVD\n",
       "qXQcXRp80KKmDBpTfiiROc4fvOooR/BkbFvNQlDn/QzLPyPvA7qsC8ey6MFxi5+el5CbQWYOFcAA\n",
       "AAErQZ4NRTRMN/8RWcslWAEyqN9NfkK76PaM23RghJsX+pT+689JbQ5rc65c2xfM8bq3zvMbB2ef\n",
       "erS2pUycfKPL13XFiLYlPSm11FH1yoNWz11fUuzN8rrChSSJgK4X0tp/ZGMokb/vtUv6pIQRus8K\n",
       "XHuhmB59bPQ9i2IOTIrcM1eX2IdX/147d3+BkQKLO5QtFqZvxzmrWYJV393tQOjMQweukdxBzlAR\n",
       "ohLSl3BQk7x42HSso5Lrvi7q/ex8dcp2Wc7+sCXJcP5fva8sO1L7qPkeaAMq4ClkO43m4KPvnRCQ\n",
       "i7vN42Lfz21GaF7JAlZmeRxErQFnIGWtFiVJ+bGUBegYVfZwWBHO37HO23xloedzkJO/iQRBsx7F\n",
       "L4/Psc/b/2mjtP8c4uxKaIEAAAC2AZ4sdEM/AVCMZYVobYEJOLoVRN+XX/1ufum7guuqmvKbLGt9\n",
       "YVd6uAS3D3JbnOULL9SjXLOux+34yJGq847S/5YqbrUndf1hdoy5/ovATn4kb88ih+MQ4YB61Dch\n",
       "ikjAzdhDGThr7UE7U8uFGylB+y2Zxyy7GsIkeE7MiP5iJzaWc4fnqRnJ7JftWKk1Zr3h98LlGBmh\n",
       "/f4di9zJC55Miv3wGRia6moFacg9a1qAaceWcPOuNtMAAAD0AZ4uakM/AVCqGG3MH2iAGj3ja/i3\n",
       "yu+KbteTAmxvdoX+oz36Rb3S8N0/tmpsQHuV3SZYOsunt8LlQdIOepzIWfWjhZEkWL1kP/rah1cZ\n",
       "iiIhl+wAKfCfVZKqEuXuRBQ1Y8QcM2fgT12Afc0z8qoXXarvBfxQL80H/6Z1HR/RoyuBZj+tT+vs\n",
       "xK18nPwaredb4OoyhO6w8kAYXf4AOj77bIyafA70w0mwPke28W3jaaZOb99fEnyBVEJpZZcBnflU\n",
       "70KxD+vFTxwT9lpbnPKlJCJ9lYtzZr4n7LUJnLi4fG2fWvaW+Kq+a9ppwjeIvIDRpRPueQAAAahB\n",
       "mjJJqEFomUwIf//+qmfevuJQA04yorA9z8EcVV/yj+SojFg5RIdBLqZ2KRHhflA1A2NEA7SpLuDA\n",
       "fZGQ+FFtO0KKP7Lnh/H8eitWjxF638E4KIbHnxaTVjhjqxgBhB0SCz1PuTHHE5wwYZkQxfwffPE/\n",
       "K8myHjQPLIDDiCNWwunmCw25Idz2ib8U3UCAp74EyLxdGob+8Kf4pggbZxz7ibCXq6u7nKU80RBu\n",
       "A0LrsdfbCBdbMKhVnpefxsIeVoM3bsXCrI8lXgq+1W5YSB6Caj0f77yRZgjzjJUMjSlKtSXajtSd\n",
       "Ct8zi8aSbP1D+VvhLVrTDb4V4wQ61Z1TdfvEr1/Zo8MI37JmbckFHbw/VZXKTb6txsAQ8wPK7dZd\n",
       "2o4SiEj8q1AG2p5RNqiZ2DsuiiPRPrEEWt/iyHDvGGB+EiM6lJ18xWHHLwnCxNGNCyzGetxAiQ7x\n",
       "ctqZtZdWgnHT8F0wtgwRufVW5c/ZQ+MEg3CdCwYvYMDugEZ7A0f59Pdy5WreOJFLkFko2Ll/CbYo\n",
       "n/HcWn59diQSEidRbyHgmpehUxHUxHLAAAABJ0GeUEURLDP/FFLoWABc0cZv/tN4NcQ98OBILddq\n",
       "ecljcjRlGQlHeVxoTjArIGq57BVEZaTGkcNAYvkefY2rz//6VbBnJM8Bc4y/0B+K7uJL2wTLh4ee\n",
       "ytO+KnI9McGMeWRBS5Gh7DiIg2FVyxSnDYPLl+Ul2L/NgO2LZ6oLnhwS4bdIxZwKV3ZMkpGyKD3E\n",
       "5PvNp6NIjuIcWyqY5I9Ri3UfXd4ImRL05IYe8ydYPRS/1Y+ePgbzaYEwK9iQ0gBYhonSSCDwqkUm\n",
       "WazaYn9SNYaE0USjNh88qeJn7CHVD6lPWDtsuRRjsIAJbMS+kMXAwU8VmhRgmQ+1gVv31NBC6ZqO\n",
       "Ng5J/fbmNNTxDjqwrH6Cu/Wo3bxOVDreb32qlysb6SWNA31iNhgAAAD6AZ5xakM/AVY/kJFqIXj6\n",
       "BxUk5ACaT7hvFQlB0pBFJDzGXnDI/KUPq6F05rQvYPMZz5hjb1qWg3o1F6wkz9Sf8Z/HgZU9GwkX\n",
       "4d5cm6F7TxN5L1DHn8qPS7/X9DgG2LurzztLZWzZmavgnzZ0g42r7RwNxCvTRIpRzfkWbkHX/4oO\n",
       "kCdjAjjSgNCPHOSWJwZthjawWt2utavL24U2Vq/GKOdyczlMRj1f8v2sIcMJ2xxbpMiEabX0/5XX\n",
       "ZKpXAcn5NoGg3CU3r/Xviu8TIChVI3yr5HmCGxpIe97HHNiutWdozcu9jQAw415KQZVvtfLNOvCh\n",
       "++f4i6cHvwAAAa1BmnRJqEFsmUwUTD///qpsxrfgBVuqC3QjshsFQ+lYoacmKKDAQ9DJqWoASy7x\n",
       "j2s72C2NvgyQU2ywdjFQ+lnx1qeCX//BtmZESX4DIr9N38vcVGXHw4KRH84UfsM0/fqJTFttp/Ja\n",
       "WssAxtX3s0kv86A+V7zala9wqeEr6C88+TpNCAAbBLKQHuqrPH1R1Y77BJQmOJjCuZgP8n58UzKP\n",
       "x7lhiDUnEyftwZA4u3J3RCSyLezrsqH57c5nG1MGg5wC2/2g3l7jMTgXhP4oW/iQzGfgcg3olzAM\n",
       "g+CH0WInjI7f3NHlM0Ceax41FFJC/qZjNCL0UEGg2khO0pWp0OcrpljoJQKpuXbsv6P7fG1/S+e/\n",
       "vbJxqeVVUi12mCkpzn4QzqHnDs+FbPQaXjaRjE01GD4dm1KJC09FHe5CNpAmHJBD5zVazozqE+xu\n",
       "gZwum/fHzgVxRXrgsK0/UxKhwbwwzrAEc5sd4gy12tpVufGt6hvz9lga+STZRABqiYrXZiIPqBHj\n",
       "Be17mgbzy95SkHe15wve8QCeutLKKOqTZYAaq371FLCKap2UjvTdwYgAAAFiAZ6TakM/FFGn4gBB\n",
       "OfFZ4Sa0iYJSMywFd2Rd1Ai0983et2NMoyWHQ3G1ZWb/b3e6glckd2Bq3wW7IQbjw9P6bcnoJIqC\n",
       "r1Y4mLzduaKxp7woShuRW3xqwzn1RQxXAtXmG1Is+Pgyb82ZkuDG5mGPK/XbBf5oxasfPDXWMKCY\n",
       "Vbpa8xcxOvaV5kJh5U+n+eEQl3IZ+Lnfi7X3rU/RJSsgI4wHy11chR5GqKNObA2d2bBP3k0fMLOT\n",
       "fGGUxvMxvErWSAeeAX3kSNuThfa+FNfPxvcrRztuyhZdImNlG3fznUpW+F1/pNxDb1yC7EdbIAYA\n",
       "aRDUYQgoIUb6Svo6tv+pOUBN6YMSoVq8QAOjgbT1JkuMTTGpWjEjseUuTTUj9SQ4gp3h1s/B1nCG\n",
       "j5lWVAihffnZlMtbLA160ZdKEtkLVrH7/adrRwW4P0ihmCO7hEXpig+Yln0181rcCUz/zyUt4wuM\n",
       "AAAAt0GalUnhClJlMCCH//6qRNaoi4ABrLpRtA9a2aGBa3XWZ7bieIKjswWs41qRwFZq3URSMdkP\n",
       "N0OcifB+lD7Q0FWbmgYFeA0TJ4eitckjqZ3vur3QyeAINQOAjnb8w9lkhjgEJTc7ZmizViM7L2Tq\n",
       "QwJm+qI//930wYT86emPcJpRaRieUkLyU6zantxmZWcf6oMH5mpnoD/G6WVhYBES2iQzJ+9fOqu/\n",
       "JnRzh/LD/kolcTPVz+0fZQAAAeNBmrhJ4Q6JlMCCH/6qP4H4ASoT9jaX+IQJwLqchnRvdkyjSi3t\n",
       "CgoR3u4OKCjgsGcmmeuxFVbihsq9RXTuB6mYhBRjY9BtG3FV78ryjDNIGLZglzdozaSUoXN+OjcG\n",
       "07Za2IP+wjHMlz9l+VzH0qH6B2nZbhR8DpzX2rYqZjHW0mYvTpoTFjQSItgKBRD10E8YFf9bAQsh\n",
       "n/g2PlLKqFQ4137JNo+5wwUtoOk22TqYjLiTcG5BTb386phLK7Skr3nrmM6EYNpITpeF59rEK8RK\n",
       "GtHKGKustczpdeBlT3W1r2OosfPKsgYoZE13d56/WNKywYBYJ1lTnwThJXmhZEhd5Uc4dwksc+AH\n",
       "tgGTWBPhcveLdpKQiWTwH79dA9HsllYYXTW0r+y3w8IkPkzbEr5QqEQVs7e4+S1d/QVo6pY3J8Lz\n",
       "5OYnD+9L566KWGz8nMMVkubmT6llBKTNwdksDBeuSs9k9U2RZxGSFGdV9jOu9uVoA/eueY0uYpLt\n",
       "LmCAzTjk4f/yyPC0XzhlnZDQQnvpEH65DcJS5vuUAfiqPBm4QYX+jksu93QAUeu8QxXX30TqZAB3\n",
       "/1wlQBY+TxapuzjpL217E6jMwZnLpB7aYY7LRETsrUYu/7pwyF4hoPhj/pixWs8AAAF1QZ7WRRE8\n",
       "M/8UWw4IAW9Ppsw9IWOqEwRzhv1hh5oF7j8+x41US5HiYOWBhLKxCeahTNzHLpWCc0C4D0hm0BbS\n",
       "0SDjkfbDdEg7TFKkm5SPPXIC5pFvyRgdRpXpaLhlHToslzmBYzbR1K8xrmn7LbYp9TJR8+Tzel2V\n",
       "Q3gv/6KKOO3D8r9JADVeF9YPojB+l1dalY7Blufi+/YuuE/ZnOKt3VOTrKeQwWf4pJF/h3cCtNP8\n",
       "7cPbXXnVKakjy/UUhfrwjP0BpzLYHx9fS8lmUW41vMbov2zanambKfUrg8azF2PY2aiO5mrYzhoT\n",
       "XhaciCtLoLx0IQaoHq8pLWHzMhui7c7n+Z5pxNyYfqGtuegqcRt3v7Ian9i43zW6cb8fPdlrhai/\n",
       "bXXUlCEkP0a1VFE+HwNm1fAXEVEIbLRJZJw1mWGrON1KFC3IwIvonMW6aG6RYmEGImILTDU0Ud/c\n",
       "pYQANIm3p3tLSML8eNoch8bB8VTS79dtMQAAAUwBnvdqQz8EZBFeWN2h2rIt+AAJjVySXu6opqKC\n",
       "5oV08UjyPyz5z6vTpm1em5yflZQDh96fnHOAQ0ULHutvOs72aPkV02EhpvvyPXCeEvKn78O0lBGH\n",
       "f97ZYEpedkn1d/g72ZH3CSyL0Ecp+Maq6xdx0hYrNEAr+2lEBs/kn7T2KsPG3qfq3XgUV+Ej5gxk\n",
       "/hjJ6x49BK67fetr65tiar6G1WI400jC+Zh0pzCzvh3FwtkMudqaWFkD9if/VH699ojS+N5T88MR\n",
       "8MSzrVXk3zLdqhArF63BkAAGUJUKmfVLS/9SRGj1lZDa+IDu6km3Ph0IDVkNuLSneBP4rkTLUvtL\n",
       "xzzmRE/BJ7W8ZaXt0nlXppv25BrVg9izCuj2AepaED2ElnhvaWl8tjgznkjon5rUH/HKXTBwi8b+\n",
       "gzGrftr3zu7LGPqwCZ7afoqlMQAAAhFBmvxJqEFomUwIf//+qnrOFAoIAZhS0kmlT63oegNcQx/e\n",
       "ujeuejeWsrk3AZ62Q5VVclFBytb8p+bG+k73w09GD4cz6bjwRIUo0tTVX1bd8oSmV3v+0afLQulj\n",
       "3WsAyg59WFbE5K9D+TKIMJsz618MX9QOPUZT0QLrggOUtUIfWNly73la0ryt64afLws9gr67tMIv\n",
       "NVnltBHX1yOWFnSCIUAlz7OxQ+19z7jBB4hDino1HlhlTX4K4rF8urNdQP4LtJv6mv7jHx7HKhbz\n",
       "beYI4aY5HvyOnKFo2FrIHtxj5dm1djUYJ4x5d0u7pwuk/8wCSIZnPEn+mKDKQxfnGHQ9kMgYJyMq\n",
       "5l54W1urNvlAbHC2cy5jUaYChZ9Z1p1GRV5ZnAXZjJNSJ4UXsYlDkCYiFPvLpAL9c/mlQn6rWevI\n",
       "QTtZMt/42BEeb9FBSiSGLIOm/NKtGqhBP33k6MHGMsCDjxNftCSJFmKGExWL7BlpgllaYlcFdWjp\n",
       "LWkDD5aNnd+wV+5Bq0z+MFEGCgAwLTApm5rY/N+qPhDfTVrJeCM7OJs813mUP0X0H3qv1C3aO0ab\n",
       "nSx3yY6LxMQqALg9RlsHA+sPhFHQY7KAo1Nf/yTlAUw8ZMlQmAJaOz50iEpI7+D1JsoQZ7ovCtD1\n",
       "kB/tO85X8uZC39GdsVZ1f2cz0KMvU4+EQiAZzyAPb14vJgiWoNSAAAAA7UGfGkURLDf/EUcXjWtA\n",
       "B56Vgg2KzhPBej274nm9qahSr2uuSqLV3aHu6s2HsEakBUv0+6fEGyUbqOrqmGygPqDfUCW4YdI6\n",
       "XjAPAIueT0M02g0aJIkhHJyrCC8Dy3Y6xd4rRA4Epo9Vfl/stKAr//sLIZa25XMHXXdwxH2h8phH\n",
       "hD+cSC+9klXES6asboe21/TvE9lKYs1lfw8tPxnp0E2oQ6XMKmX9RIzOQukRm6p4///iqHuY+KdU\n",
       "jQXLCSMEVnZwYRbwWk48jOC2x8Yr80EAcVDO8vg+sInMeGvUMDrLsBeO8MIa0OmnL8rUBQAAANwB\n",
       "nzl0Qz8Q1YP7eoAPn8ovbYYOdM2Ul9BIFOVnwfjIqmZBU36/XHyjK2AK793/7KJ2lMf0c/53oqm5\n",
       "AliQ4WVHrVS5WZ2XSPh64N9q/dji0n62pNimEMozqPM/2Ee7dsImwIZRUAK4aMXaNb48FkjxeniJ\n",
       "hAF7Gu3tUMcQtx05e7OuZ9MnN8bKmzN5VwRWqrBmtq5cbK/dAKp8N/M4eCL1+w31lpZyjqWphUP9\n",
       "5T3TJfd20vFge6icPIPB88XfevI89pDUMcnVfsOBVtBPh5oIQTsRd4HYtoYr7hDAAAAA9wGfO2pD\n",
       "Pw5IJjzUWACyy9J5gRrRv9wAP23/yr//Dzh/8PdcWS6eChZ38tRJZyL8cdXaaX5ktY5PoD6AIYvd\n",
       "z5lov/5tHiegX786KGit1Lu5X3sYaEl0sT0OAvo+I/dMa0OysBPbwAjmT/d4d00zIL38JbEYbnlV\n",
       "HM9OhRL/OpghBtLuKVqDVWe1U4U51drvBOeKiSj6hhcyomuJSDPZ+yBSOAWmeQAE1QHGRbZXW+wI\n",
       "38PKZz0GQ7fldXMsM/0iGguUBfmRvV2wMQgVcltord7YOwDS4Oo8Tvxao1JuXQkgBocQTUlNCzsw\n",
       "PoDQWlFb5MlD9ylFhl8AAAGPQZsgSahBbJlMCG///qkFB3l9wAtbu7escEMQdYbJ87F68GUn5Tu2\n",
       "cMACmB1jJ/zJsJRTjWRCup5F9gIeEBd/ZlhmQFBRJNumAwpNblXb/+6UYvtvtqLVUiKvJYHOOKnY\n",
       "WA7xyHt3wBuD+zVztkIXj5mves+WpDbnZivw3/dESdVnYyaE25gxmZa1Pi9Ms7xWGOlImNuKbi6v\n",
       "VQ4WzWlzv7PaTIGkTSzbh974KttWi3f8Yc6uG1o2zenTnBNHfeVQY5Vtmb915ARw66D3UZXjP644\n",
       "ZF7Pz+64TsQ71vOThderO/k/vRNa9WpOqBcq/gmxW4gDSDsMiQXIxSd2JByh5nmFMtK3fHaYIj5a\n",
       "C1Nclsj8WdAvVaIXW4s1qdpDCWFpDXKMWlqgADtEUzc0roTa3rYjjpVLtgGwXFSTmyU6b8PXJWnK\n",
       "x99YICYr2W/KdL96IOE5NZfcDjiWURqTTal97af1sc5sQuq5GY6SKxh2UgrbQNXxNq4gtlCMf+hi\n",
       "KCGVdrMFiceSEIhE0F/RoRa9AAABIEGfXkUVLDf/EKMaAAsab/99mPvoCw6cfcXyK1RvILOKvepT\n",
       "WiYYwloKtoKLoEVEvaoJ4rtTBcdw05Gw6U5shD5s+lWy/X6HjE9+4Fh9KBOJZ5Yhq0s8XYMk5PFj\n",
       "AiDdFDml14/GS4DHBjPeU/KiC7OIXLZWl5FUrs5av6SKtGKkdL8b5RriFHbeyVys651my9J86sI5\n",
       "JAPLolNWEvr1JrLRMLZO82O9DSjjhWLDpTsq1/To1DMDsrKhkA9v8SKd0Dd5vKNS+oXjgDNavKHH\n",
       "oYatW5yas7GeW+R9q8GXO/rQT1L8wMDtKUu6Kpw0hWrijMXSQ/x6pltNcIWYAqK8h9RQeYmizTeJ\n",
       "fUSO0w9kkNAu39p/8R1wvyZh2m3266NH/gAAAQoBn310Qz8BbtBnFDAIdAqExBYyaxnENeyQmVc/\n",
       "eV1rOQn/9tMxGkE5cktiYanIuW2n0ElLwu1jFrMvz1Q6pAzEFRV7PkxqzR6Rw4+osbGfDDJmEecj\n",
       "BVC/Hw6uG/pM9XpY2XnR5669qOxuoH1IAL9FiX+Q0RX091SN+iWDnz+ARIwGAYmhTUooYZwpnuGf\n",
       "rWfhNhgZSlO7ZNLK02G1o2+1Nb+hUBI+MbajB7zaz6I//p7YE1ZGcuXVohj/hOLzHLjAIqhIS1yZ\n",
       "R/XLmz+Us/OEJx/DxPe4UqtnvG7EX5NQ9jahUQOEeCGG1C1AqXE1vNYTYnEYXy5Efjlx+Yxy/vuX\n",
       "pe0RVee9fdYXoAAAATQBn39qQz8ELWk6veQmFUlRlVx0qUAXCmjSZuOOr1tHBo8nlNgTAnTV3NdP\n",
       "Q3dsdaTnGUB89SHQZg8latEUHb+LysWI7q7Fcux8Rk4A5YlQfwJfZDqA+csgr62ifu0LlniH3Crf\n",
       "npeIGZ4Qk5xIt+HPvrHmDUnzXykJrq6Ko/yTBaTcUysXU7lb2Sca3LR60H623l42OwYCdQsIrc+E\n",
       "ZPzwg3tY4xDQgI1XulcoJ6MT+CrS0iWoxW3C3v1jbchFS5oENDksEVTkVJ3XnKIgr6nR6MjZ1D0I\n",
       "n+yBUUSvyExNkRDO0WIYgCoqxZ0GIbN7UTr9zram3C10npLqkz4q3KJmJ76W9sk2KWzJ3OMFNI74\n",
       "6IpWD4nnMaENdXPXR1Mn9PtrA5QXY870HgtXfngB5gxLHWFsXwAAAddBm2RJqEFsmUwId//+qnTf\n",
       "9Pz8AJUA/ucqH8JPpbuzx0Sav2ZW4OELClsCqQjkykXTmvHmKrjVWiFNsc9GPZ2oXmoOj8LSKH05\n",
       "scjsf53/FVWiUXQUVhB3N5UG6+X0RP6I2uoUvyMfqFP3DTcvWpHHKGBWav5HhZw27tvNak0ioL+j\n",
       "sLHqYPHUH0pbfenYhwuZFSH4dWC5Okht55phxxi7wkzs5t+jB/O2PJhgopuOVCYxFxDUcP4XPQeA\n",
       "+RwIWlvsg6vDGuhDpD1FWckhQBPvff/9HDMtzbELHfKPKsa7ExHeHFxAiCcfH+ZmNf5BRu0iKqZC\n",
       "CH79/+vCf6TtPuLs6Y6LQ8PYJ24SCVMazxAiAtf9u5u2q92YSUk4XskazwUOlh6PiZMGNrTXFaMt\n",
       "as1bpl/pLq4LoFeuCJEjXdJpfU7h0ByPUQPlGX0wcFCTYsi8wnd9ZZbC/Tg7n3/G+yTpzhv2zEpR\n",
       "SdeN7KUOmVlxTASMH5SqTaRESHRbUnnpCMTMslawSIhKZtaLUzfQQAsgVmJYd8J7zyHMDHbWnKrs\n",
       "EgQyPj2S2jdUh4K7cE8WaIe2UpZfcWC7yo8duD+gEcUEmmy5XOP1UdopfgDKRD1BViKRTC65a7AA\n",
       "AAFaQZ+CRRUsN/8OTnZetQAlPo3SAQ7oemaTZhX7maIobhxJACjkVl32jLmkxEGbkcMGoKAW4Vr+\n",
       "B/KsUtLuzz7kLxrAgVle725eAmTbW7yk7MuhmKtV1NrWNZk0dqn/VIzCQ4GHlT+Y2OyQ58Vu0ZWP\n",
       "u9hQ9Ycen9pNPH1EnP61tZy60S70vIZ85T1+Z2RNK7m6G7BzZMDyOfGek1zKvyzfHqVHZMNF3ejc\n",
       "BNfXnoYQTZRn9t6f7TdzVbRvCW5evKAgZmsU9Kofl1DPHuUDRNpZBbk5C2R6i0kln5s10/RawEk6\n",
       "KtDoxkaAR9vMcIPPCwZi/8/PEmFpMYNyzOPxEq+4CM5whJVxhNMm3RVnryL3eBzQkAFxaU+XCLk5\n",
       "m9q8BhKKzikG58gqAW9F9aPxSQgmXhWbkePxkdyWfhCq2LGyixKryCmQTK1e6zxPUun8Ku1l5ASh\n",
       "uvqsmAbn6wAAAW4Bn6F0Qz8Ec5WBQI7QV1u/mYNRjJ0SS16DlHQdSqZnf7Ur8tkJm5Q/QcAS0xWh\n",
       "5LFMDFlfevvOVKNUdPvYN2+Nl92Dr/hTsxo+kzV6nTNECNexJFDwAp26a3/xcLKraRVsvxxdf/fg\n",
       "9EOn1fwHJitq1hleSrhB+H9aCC8r2XBerG/CvRb5B8l7Trc3xCF+FGJySMrTVhguSMdqRZe7WyXL\n",
       "lICtgxWXgxNUEaxwgPzEQm3EyuhkQLxjwbAy9IbxcKQEESD80CGuqYf0o44qzjwqWy4Gn7MiUTk6\n",
       "+xN4AGVpgIG0FrYmbTF5GKlfovwIeqx3lbIhOC9zNn3nd1O6E7ec2mXumQv5YNmZJnO9CGpD90wk\n",
       "nF1kA5qb3l5uo3PDSvYN5pV0R0OkNtTQwD30Z0LSam7mJanSeTUzeqOHVqyInWGoXip+nZ9dEFNa\n",
       "q8Fweq6D47CS+nv3YkI2yCBB5jv5JUWBRh6r7UEldWgwTfAAAAFmAZ+jakM/BGl9aAPjDcPzvzFa\n",
       "Wsz30wt0j5CnSzcbdN22tlIQqmmVYUTZ09+GHM0F22vTPgsRTmKsaSHby/MmQiHFGW6924CTc5uT\n",
       "p099GPkNndnt5wKnUAksLm2zbBu2l6l3HedqP7a4Gj+2xhVpu5pQHUHv6Zk9ego5QbyYkmK/tSfq\n",
       "+xM6IKOrHIuEZyMyD1/kCWfKaKJQx73T4k9SziZzOXqAzLqHl/GlUABg/dt5yy7jCDtLmbfn5X1f\n",
       "CapkAdebPucxvl0nGeLtrMbypEojuZuqhPfpajFeCEzf7t9alLmtivYkNqt/gy7WluRfU3Q1TmDx\n",
       "oRA8OVzKVwa3C0KOt09GsqXPlkQn0/9710+K0pHNnD2Yw9TxqCzsvH+Y4PYKnvv2bHRVPBtkf5zn\n",
       "SPqrEBv4IVp/+U5udh2YAq9wuhv1EFBuI49uCNjTYgqP55qYfMEAFYfFn1dvbon2Tz4C+HF14QAA\n",
       "AYRBm6dJqEFsmUwIZ//+oREgeqADRsz34XCWtLhcLpbj1Db9xjB60J1QQsqqRX3bhlUJO7loGaVB\n",
       "r2FhMQhlu5JzEf9oWQKq/AdXeinYX3c9/hLDB6uXatZNmLH7YU6OMBGLokb56h9S1VJI2h2EO0Xo\n",
       "sBIL542QxFEPRViae7EXp84rYIiWla/tTNHjLgYQbMQW/nAKs7a7Pp9Qh1P9SgwCKUBlcZHK5V0E\n",
       "0nZ3iSFA3U/auiVDfoLsi0gNFnGgEMBWWCrkVmyMD7qEsCs4Q5SQ9dq6/+1WBraQQEYqyDySNq4H\n",
       "sDanC+emY3Z3Baz6Q4xHRPZ5wHCmGTSbqMBbZJ/cGjC/OXAhZ4BM5ZEO7RJWDhXjBIVpDKJxVnGV\n",
       "1P/fJruIcPi9E50HZV1ybm8PzTiZ5ZFW5FuPunzY4+bHz+slmMEOECl9xGl+ccXaYNeQ5mXd9sWY\n",
       "ntPYmXkVFR6ZWZPygXXuMGZjwy1AuJqeyJ2n+Z8k7Gek3V/8LjYakhaNv4Vn4Rh9AAABFEGfxUUV\n",
       "LDP/CyKM8U7dbjc1xEPIABO2rus6n9736V5t0rTpBxjbhTmuyO148WjWOAdnzi1Te3hRZESn8mcb\n",
       "KGyTb0Du2B5K/HUBInDQRCQ5hh8kkxhGfnJD1AE4pC1dyf+RSwSyUPJ6MYnpvZ7d1sweor+bmLCr\n",
       "VQ1h92Fh9ofr0XURnkkCJ4saDv7KRR1KKDy6wAmJB/lAgs28t4pR4x4bZ70cJNXRLtvpVfbE5QaQ\n",
       "FjruiAnBPT5+Q6sFhuGaY2pXisQqleCp+u47SIIgUzuURWabakZPXANCqYNYKiwVOsy7GG02XDW7\n",
       "EzLi/wG67Kz00RhaDY+j5e7htpn/vcV36Z+5SUllqoZohR26KVmALhU3DwAAATcBn+ZqQz8LLef4\n",
       "KQ6AD912rKf5Wmha7URg2cIrG74UpuFnnWlJJYj3E58IYvQr6NvkYs65/0DwHFoDyeyrmKNPb9/h\n",
       "vKk8GrhyYuW2gm8c2iQ5sMOtYZprvpRKnmplS2zXf/sSMQkCLP7IJ9PxeDXENswuJOWbrfwqecS/\n",
       "6S0P7hqCQIiBIszA4iAf6q2alI+qO76iLrdltZg6m4jkhfxXYy6YolqlF+Ey/uXpKrWvjfl3S/HH\n",
       "ho/A5yBdJIKRnyFMEtfo1Jtfl49WshVh7y7WHXa7Po+b9dheR7zoNlpNA3OeGKl5SGaZxYjlI0jr\n",
       "zyCEObbo3nt6kdhtu2xpdrYA3DZ5jDu0DSqDOaWA/KyWLvNT8dG8MfLuXNTpcpFffC84MlowS6q2\n",
       "TysNqAIuplGL1qswe5F40QAADB1tb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAA6mAABAAAB\n",
       "AAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAA\n",
       "AAAAAAAAAAAAAAAAAAAAAAACAAALR3RyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAA6\n",
       "mAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAkAAA\n",
       "AJAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAOpgAAAYAAAEAAAAACr9tZGlhAAAAIG1kaGQA\n",
       "AAAAAAAAAAAAAAAAACgAAAJYAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZp\n",
       "ZGVvSGFuZGxlcgAAAApqbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAA\n",
       "AAAAAAABAAAADHVybCAAAAABAAAKKnN0YmwAAACyc3RzZAAAAAAAAAABAAAAomF2YzEAAAAAAAAA\n",
       "AQAAAAAAAAAAAAAAAAAAAAAAkACQAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
       "AAAAAAAAAAAAAAAY//8AAAAwYXZjQwFkAAr/4QAXZ2QACqzZQkToQAAAAwDAAAAUA8SJZYABAAZo\n",
       "6+PLIsAAAAAcdXVpZGtoQPJfJE/FujmlG88DI/MAAAAAAAAAGHN0dHMAAAAAAAAAAQAAAMgAAAMA\n",
       "AAAAFHN0c3MAAAAAAAAAAQAAAAEAAAXgY3R0cwAAAAAAAAC6AAAAAQAABgAAAAABAAAJAAAAAAEA\n",
       "AAMAAAAAAQAADwAAAAABAAAGAAAAAAEAAAAAAAAAAQAAAwAAAAABAAAJAAAAAAEAAAMAAAAAAQAA\n",
       "DwAAAAABAAAGAAAAAAEAAAAAAAAAAQAAAwAAAAABAAAJAAAAAAEAAAMAAAAAAQAADwAAAAABAAAG\n",
       "AAAAAAEAAAAAAAAAAQAAAwAAAAABAAAPAAAAAAEAAAYAAAAAAQAAAAAAAAABAAADAAAAAAEAAAwA\n",
       "AAAAAgAAAwAAAAABAAAPAAAAAAEAAAYAAAAAAQAAAAAAAAABAAADAAAAAAEAAAYAAAAAAQAADAAA\n",
       "AAACAAADAAAAAAEAAA8AAAAAAQAABgAAAAABAAAAAAAAAAEAAAMAAAAAAQAADwAAAAABAAAGAAAA\n",
       "AAEAAAAAAAAAAQAAAwAAAAABAAAJAAAAAAEAAAMAAAAAAQAABgAAAAABAAAPAAAAAAEAAAYAAAAA\n",
       "AQAAAAAAAAABAAADAAAAAAEAAA8AAAAAAQAABgAAAAABAAAAAAAAAAEAAAMAAAAAAQAABgAAAAAB\n",
       "AAAPAAAAAAEAAAYAAAAAAQAAAAAAAAABAAADAAAAAAEAAAkAAAAAAQAAAwAAAAABAAAPAAAAAAEA\n",
       "AAYAAAAAAQAAAAAAAAABAAADAAAAAAEAAA8AAAAAAQAABgAAAAABAAAAAAAAAAEAAAMAAAAAAQAA\n",
       "CQAAAAABAAADAAAAAAEAAA8AAAAAAQAABgAAAAABAAAAAAAAAAEAAAMAAAAAAQAADwAAAAABAAAG\n",
       "AAAAAAEAAAAAAAAAAQAAAwAAAAABAAAJAAAAAAEAAAMAAAAAAQAADwAAAAABAAAGAAAAAAEAAAAA\n",
       "AAAAAQAAAwAAAAABAAAPAAAAAAEAAAYAAAAAAQAAAAAAAAABAAADAAAAAAEAAAkAAAAAAQAAAwAA\n",
       "AAABAAAJAAAAAAEAAAMAAAAAAQAADAAAAAACAAADAAAAAAEAAA8AAAAAAQAABgAAAAABAAAAAAAA\n",
       "AAEAAAMAAAAAAQAADwAAAAABAAAGAAAAAAEAAAAAAAAAAQAAAwAAAAABAAAPAAAAAAEAAAYAAAAA\n",
       "AQAAAAAAAAABAAADAAAAAAEAAAwAAAAAAgAAAwAAAAABAAAPAAAAAAEAAAYAAAAAAQAAAAAAAAAB\n",
       "AAADAAAAAAEAAA8AAAAAAQAABgAAAAABAAAAAAAAAAEAAAMAAAAAAQAADwAAAAABAAAGAAAAAAEA\n",
       "AAAAAAAAAQAAAwAAAAABAAAMAAAAAAIAAAMAAAAAAQAACQAAAAABAAADAAAAAAEAAA8AAAAAAQAA\n",
       "BgAAAAABAAAAAAAAAAEAAAMAAAAAAQAADwAAAAABAAAGAAAAAAEAAAAAAAAAAQAAAwAAAAABAAAG\n",
       "AAAAAAEAAAwAAAAAAgAAAwAAAAADAAAGAAAAAAEAAAwAAAAAAgAAAwAAAAABAAAPAAAAAAEAAAYA\n",
       "AAAAAQAAAAAAAAABAAADAAAAAAEAAA8AAAAAAQAABgAAAAABAAAAAAAAAAEAAAMAAAAAAQAADwAA\n",
       "AAABAAAGAAAAAAEAAAAAAAAAAQAAAwAAAAABAAAJAAAAAAEAAAMAAAAAAQAADAAAAAACAAADAAAA\n",
       "AAEAAA8AAAAAAQAABgAAAAABAAAAAAAAAAEAAAMAAAAAAQAACQAAAAABAAADAAAAAAEAAAwAAAAA\n",
       "AgAAAwAAAAABAAAGAAAAAAEAAA8AAAAAAQAABgAAAAABAAAAAAAAAAEAAAMAAAAAAQAADAAAAAAC\n",
       "AAADAAAAAAEAAAkAAAAAAQAAAwAAAAABAAAGAAAAAAEAAAwAAAAAAgAAAwAAAAABAAAPAAAAAAEA\n",
       "AAYAAAAAAQAAAAAAAAABAAADAAAAAAEAAA8AAAAAAQAABgAAAAABAAAAAAAAAAEAAAMAAAAAAQAA\n",
       "DwAAAAABAAAGAAAAAAEAAAAAAAAAAQAAAwAAAAABAAAMAAAAAAIAAAMAAAAAHHN0c2MAAAAAAAAA\n",
       "AQAAAAEAAADIAAAAAQAAAzRzdHN6AAAAAAAAAAAAAADIAAAH2wAAAl4AAAD8AAACHAAAAU8AAAEK\n",
       "AAABCQAAAeoAAADkAAAB6QAAAWIAAADwAAABBQAAAc8AAAEhAAABjQAAAYIAAADlAAAAxAAAAbAA\n",
       "AAESAAAAtQAAANYAAAIPAAABdQAAANIAAAFbAAABRAAAASAAAAFxAAAB7gAAAlIAAAHEAAABcgAA\n",
       "AeEAAAFeAAABSwAAAWIAAAG9AAABbgAAAOMAAAEKAAABhQAAAS0AAAHhAAAB3AAAAbsAAAEaAAAB\n",
       "KgAAAW8AAAEIAAAApwAAAN8AAAIYAAABwwAAAcAAAAFTAAABbgAAAfsAAAE5AAAB8wAAAU4AAAFZ\n",
       "AAABYQAAAjUAAAEVAAABKgAAARUAAAIGAAABbgAAAhYAAAFzAAABOwAAAP0AAAIaAAAB0wAAAOYA\n",
       "AADgAAACagAAAXoAAAIfAAAB6QAAATcAAAFXAAABjAAAAZQAAAFIAAABHAAAAZkAAAD1AAABvQAA\n",
       "AM4AAAIRAAABNgAAAQ8AAAJSAAABtAAAATkAAAEcAAABvAAAAbYAAADSAAAA3AAAAhcAAAFNAAAB\n",
       "KAAAAQQAAAIbAAABKwAAAR4AAAHpAAABSAAAASEAAADuAAABzwAAATQAAAEFAAABEAAAAg0AAAHF\n",
       "AAABYQAAAVMAAAIHAAABhAAAAR0AAAH6AAAA+QAAAiAAAAFIAAABCAAAAO8AAAGhAAABHAAAAKAA\n",
       "AAEQAAAA4AAAAaQAAAEOAAAAugAAAY8AAAFhAAABkQAAAc8AAAEeAAAA9wAAAggAAAD6AAAA6gAA\n",
       "APkAAAHPAAABKAAAAQAAAAEEAAACPQAAAX4AAAEaAAAA+wAAAcQAAADqAAABrQAAATMAAADwAAAB\n",
       "wAAAAXsAAAETAAABCgAAAO0AAAEEAAABqgAAAQQAAADkAAABnQAAAdYAAAEvAAAAugAAAPgAAAGs\n",
       "AAABKwAAAP4AAAGxAAABZgAAALsAAAHnAAABeQAAAVAAAAIVAAAA8QAAAOAAAAD7AAABkwAAASQA\n",
       "AAEOAAABOAAAAdsAAAFeAAABcgAAAWoAAAGIAAABGAAAATsAAAAUc3RjbwAAAAAAAAABAAAALAAA\n",
       "AGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWls\n",
       "c3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTcuODMuMTAw\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = anim(env, 200)\n",
    "plt.close()\n",
    "HTML(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_factorized_dataset(num_transitions=20000, reset_prob=0.05, print_every=1000):\n",
    "  data = []\n",
    "  sprites = []\n",
    "  s1 = env.reset()\n",
    "  sprites1 = copy.deepcopy(env._env.state()['sprites'])\n",
    "  i = 1\n",
    "  while len(data) < num_transitions:\n",
    "    i += 1\n",
    "    if i % print_every == 0:\n",
    "      print('.',end='',flush=True)\n",
    "    a = env.action_space.sample()\n",
    "    s2, r, _, _ = env.step(a)\n",
    "    \n",
    "    data.append((s1['disentangled'], a, r, s2['disentangled']))\n",
    "    sprites.append(sprites1)\n",
    "    \n",
    "    s1 = s2\n",
    "    sprites1 = copy.deepcopy(env._env.state()['sprites'])\n",
    "    \n",
    "    if np.random.random() < reset_prob:\n",
    "      s1 = env.reset()\n",
    "      sprites1 = copy.deepcopy(env._env.state()['sprites'])\n",
    "  return data, sprites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......."
     ]
    }
   ],
   "source": [
    "data, sprites = create_factorized_dataset(2000)\n",
    "test_data, test_sprites = create_factorized_dataset(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import connected_components\n",
    "from itertools import combinations, chain\n",
    "from functools import reduce\n",
    "\n",
    "def powerset(n):\n",
    "  xs = list(range(n))\n",
    "  return list(chain.from_iterable(combinations(xs,n) for n in range(n+1)))\n",
    "\n",
    "def get_true_abstract_mask(sprites, action=(0.5, 0.5)):\n",
    "  \"\"\"Returns a mask with iteractions for next transition given true sprites. \n",
    "  E.g., returns [[1,0,0],[0,1,0],[0,0,1]] for 3 sprites\"\"\"\n",
    "  sprites1 = copy.deepcopy(sprites)\n",
    "  config['action_space'].step(action, sprites1)\n",
    "  return config['renderers']['mask_abstract'].render(sprites1)\n",
    "\n",
    "def get_true_flat_mask(sprites, action=(0.5, 0.5)):\n",
    "  \"\"\"Returns a mask with iteractions for next transition given true sprites. \n",
    "  E.g., returns [[1,0,0],[0,1,0],[0,0,1]] for 3 sprites\"\"\"\n",
    "  sprites1 = copy.deepcopy(sprites)\n",
    "  config['action_space'].step(action, sprites1)\n",
    "  return config['renderers']['mask'].render(sprites1)\n",
    "\n",
    "def get_random_flat_mask(sprites, action=(0.5, 0.5)):\n",
    "  sprites1 = copy.deepcopy(sprites)\n",
    "  config['action_space'].step(action, sprites1)\n",
    "  mask = config['renderers']['mask'].render(sprites1)\n",
    "  return np.eye(len(mask))\n",
    "\n",
    "def get_fully_connected_mask(sprites, action=(0.5, 0.5)):\n",
    "  sprites1 = copy.deepcopy(sprites)\n",
    "  config['action_space'].step(action, sprites1)\n",
    "  mask = config['renderers']['mask'].render(sprites1)\n",
    "  return np.ones(mask.shape)\n",
    "\n",
    "def cc_list(cc):\n",
    "  \"\"\"Converts return of scipy's connected_components into a list of\n",
    "  connected component indices tuples. \n",
    "  E.g., if there are 4 nodes in the graph,\n",
    "  this might return [array([0]), array([1]), array([2, 3])]\n",
    "  \"\"\"\n",
    "  res = []\n",
    "  num_ccs, cc_idxs = cc\n",
    "  for i in range(num_ccs):\n",
    "    res.append(np.where(cc_idxs == i)[0])\n",
    "  return res\n",
    "\n",
    "def get_cc_from_sprites_and_action(sprites, action=(0.5, 0.5), get_mask=get_true_abstract_mask):\n",
    "  \"\"\"Returns list of connected component indices for next transition interactions \\\n",
    "  given true sprites. \n",
    "  \n",
    "  E.g., if mask is [[1,0,0,0],[0,1,0,0],[0,0,1,1],[0,0,1,1]], \n",
    "  this will return [array([0]), array([1]), array([2, 3])]\n",
    "  \"\"\"\n",
    "  return cc_list(connected_components(get_mask(sprites, action)))\n",
    "\n",
    "def reduce_cc_list_by_union(cc_list, max_ccs):\n",
    "  \"\"\"Takes a cc list that is too long and merges some components to bring it to max_ccs\"\"\"\n",
    "  while len(cc_list) > max_ccs:\n",
    "    i, j = np.random.choice(len(cc_list), 2, replace=False)\n",
    "    if (j == 0) or (j == len(cc_list) - 1):\n",
    "      continue # don't want to delete the base\n",
    "    cc_list[i] = np.union1d(cc_list[i], cc_list[j])\n",
    "    del cc_list[j]\n",
    "  return cc_list\n",
    "\n",
    "def disentangled_components(cc_lst, max_components = 5):\n",
    "  \"\"\"Converts a connected component list into a list of disentangled subsets of the indices.\n",
    "  E.g. if \"\"\"\n",
    "  subsets = powerset(len(cc_lst))\n",
    "  res = []\n",
    "  for subset in subsets:\n",
    "    res.append(reduce(np.union1d, [cc_lst[i] for i in subset], np.array([])).astype(np.int64))\n",
    "  return list(map(tuple, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_independent_transitions(t1, sprites1, t2, sprites2, total_samples=10, flattened=True, \n",
    "                                    custom_get_mask=None, sample_multiplier=3, max_ccs=6):\n",
    "  \"\"\"\n",
    "  Takes two transitions with their sprite representation, and combines them \n",
    "  using connected-component relabeling\n",
    "  \"\"\"\n",
    "  if flattened:\n",
    "    get_mask = get_true_flat_mask\n",
    "  else:\n",
    "    get_mask = get_true_abstract_mask\n",
    "    \n",
    "  if custom_get_mask is not None:\n",
    "    get_mask = custom_get_mask\n",
    "    \n",
    "  s1_1, a_1, _, s2_1 = t1\n",
    "  s1_2, a_2, _, s2_2 = t2\n",
    "  action_start = len(s1_1)\n",
    "  \n",
    "  if flattened:\n",
    "    s1_1 = s1_1.flatten()\n",
    "    s2_1 = s2_1.flatten()\n",
    "    s1_2 = s1_2.flatten()\n",
    "    s2_2 = s2_2.flatten()\n",
    "    action_start = len(s1_1)\n",
    "    action_idxs = list(range(action_start, action_start+len(a_1)))\n",
    "  else:\n",
    "    action_idxs = [action_start]\n",
    "  \n",
    "  cc1 = get_cc_from_sprites_and_action(sprites1, a_1, get_mask)\n",
    "  cc1 = reduce_cc_list_by_union(cc1, max_ccs)\n",
    "    \n",
    "  cc2 = get_cc_from_sprites_and_action(sprites2, a_2, get_mask)\n",
    "  cc2 = reduce_cc_list_by_union(cc2, max_ccs)\n",
    "  \n",
    "  dc1 = disentangled_components(cc1)\n",
    "  dc2 = disentangled_components(cc2)\n",
    "  res = []\n",
    "  \n",
    "  # subsample dc1 according to total_samples * sample multipler\n",
    "  # sample multiplier is meant to oversample, then we will trim down to total_samples\n",
    "  if total_samples is not None and len(dc1) > 2:\n",
    "    dc1 = [()] + list(np.random.choice(dc1[1:], total_samples * sample_multiplier - 1))\n",
    "  elif total_samples is not None:\n",
    "    dc1 = dc1 * (total_samples // 2)\n",
    "  for dc in dc1:\n",
    "    # First check if this disconnected component is also in the second transitions\n",
    "    # Else do nothing\n",
    "    if dc in dc2:\n",
    "      # Given a match, we try relabeling\n",
    "      proposed_sprites = copy.deepcopy(sprites1)\n",
    "      proposed_action  = a_1\n",
    "      proposed_s1      = s1_1.copy()\n",
    "      proposed_s2      = s2_1.copy()\n",
    "      \n",
    "      for idx in dc:\n",
    "        if idx in action_idxs:\n",
    "          if flattened:\n",
    "            proposed_action[idx-action_start] = a_2[idx-action_start]\n",
    "          else:\n",
    "            proposed_action = a_2\n",
    "        else:\n",
    "          proposed_s1[idx] = s1_2[idx]\n",
    "          proposed_s2[idx] = s2_2[idx]\n",
    "          if flattened:\n",
    "            if idx % NUM_SPRITES == 0:\n",
    "              proposed_sprites[idx // NUM_SPRITES] = copy.deepcopy(sprites2)[idx // NUM_SPRITES]\n",
    "          else:\n",
    "            proposed_sprites[idx] = copy.deepcopy(sprites2)[idx]\n",
    "            \n",
    "      # Now we also need to check if the proposal is valid #NOTE: This also uses custom_get_mask\n",
    "      if not (get_mask is get_random_flat_mask):\n",
    "        proposed_cc = get_cc_from_sprites_and_action(proposed_sprites, proposed_action, get_mask)\n",
    "        proposed_dc = disentangled_components(proposed_cc)\n",
    "        if dc in proposed_dc:\n",
    "          res.append((proposed_s1, proposed_action, 0, proposed_s2))\n",
    "      else:\n",
    "        res.append((proposed_s1, proposed_action, 0, proposed_s2))\n",
    "        \n",
    "  \n",
    "  while len(res) < total_samples:\n",
    "    res.append(res[np.random.choice(len(res))])\n",
    "  return res[:total_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel(args):\n",
    "  return relabel_independent_transitions(*args)\n",
    "\n",
    "def enlarge_dataset(data, sprites, num_pairs, relabel_samples_per_pair, flattened=True, custom_get_mask=None):\n",
    "  data_len = len(data)\n",
    "  all_idx_pairs = np.array(np.meshgrid(np.arange(data_len), np.arange(data_len))).T.reshape(-1, 2)\n",
    "  chosen_idx_pairs_idxs = np.random.choice(len(all_idx_pairs), num_pairs)\n",
    "  chosen_idx_pairs = all_idx_pairs[chosen_idx_pairs_idxs]\n",
    "  \n",
    "  args = []\n",
    "  for (i, j) in chosen_idx_pairs:\n",
    "    args.append((data[i], sprites[i], data[j], sprites[j],\n",
    "                                               relabel_samples_per_pair, flattened, custom_get_mask))\n",
    "  \n",
    "  with mp.Pool(min(mp.cpu_count() - 1, 16)) as pool:\n",
    "    reses = pool.map(relabel, args)\n",
    "  #reses = map(relabel, args)\n",
    "    \n",
    "  return sum(reses, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 1.        ,  0.80207074, -0.06962834, -0.05127004,  0.89930147,\n",
       "          0.5116598 , -0.03356617,  0.00197612,  0.4440582 ,  0.24      ,\n",
       "         -0.07578526,  0.08      ,  0.12389657,  0.39034313, -0.00103624,\n",
       "         -0.00364855], dtype=float32),\n",
       "  array([0.0767338 , 0.94556886], dtype=float32),\n",
       "  0,\n",
       "  array([ 0.93037164,  0.7508007 , -0.06962834, -0.05127004,  0.8657353 ,\n",
       "          0.51363593, -0.03356617,  0.00197612,  0.36827296,  0.32      ,\n",
       "         -0.07578526,  0.08      ,  0.12286033,  0.38669458, -0.00103624,\n",
       "         -0.00364855], dtype=float32))]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = enlarge_dataset(data, sprites, 500, 10, flattened=True, custom_get_mask=get_true_flat_mask)\n",
    "res[:1] # each is s1, a, r, s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 0.33765253,  0.02305339,  0.05627542, -0.07246371,  0.6722964 ,\n",
       "          0.611201  ,  0.01150104, -0.07775979,  0.15734386,  0.51530755,\n",
       "         -0.05266601,  0.00808094,  0.5684343 ,  0.15666988, -0.01812853,\n",
       "         -0.056222  ], dtype=float32),\n",
       "  array([0.17174803, 0.68916506], dtype=float32),\n",
       "  0,\n",
       "  array([ 0.39392796,  0.        , -0.05627542,  0.07246371,  0.6837974 ,\n",
       "          0.5334412 ,  0.01150104, -0.07775979,  0.10467786,  0.5233885 ,\n",
       "         -0.05266601,  0.00808094,  0.5503058 ,  0.10044789, -0.01812853,\n",
       "         -0.056222  ], dtype=float32))]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = enlarge_dataset(data, sprites, 500, 10, flattened=True, custom_get_mask=get_random_flat_mask)\n",
    "res[:1] # each is s1, a, r, s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 0.7520984 ,  0.12720115, -0.01610171,  0.06360058,  0.85065496,\n",
       "          0.16065764, -0.0746725 ,  0.06561516,  0.50476   ,  0.30807406,\n",
       "          0.07210857,  0.01013317,  0.64151967,  0.16519457, -0.01136111,\n",
       "         -0.01848513], dtype=float32),\n",
       "  array([0.97235644, 0.84992933], dtype=float32),\n",
       "  0,\n",
       "  array([ 0.7520984 ,  0.12720115,  0.01610171, -0.06360058,  0.77598244,\n",
       "          0.2262728 , -0.0746725 ,  0.06561516,  0.5768686 ,  0.31820723,\n",
       "          0.07210857,  0.01013317,  0.63015854,  0.14670944, -0.01136111,\n",
       "         -0.01848513], dtype=float32))]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = enlarge_dataset(data, sprites, 500, 10, flattened=True, custom_get_mask=get_fully_connected_mask)\n",
    "res[:1] # each is s1, a, r, s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning a forward model\n",
    "\n",
    "Now we've made a basic dataset, and also have a relabeling function that makes new data.\n",
    "To test this, let's try learning a forward model, measuring performance using squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from structured_transitions import MaskedNetwork\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class RelabelStrategy(Enum):\n",
    "  NONE = 0\n",
    "  GROUND_TRUTH = 1\n",
    "  RANDOM = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateActionStateRelabeledDataset(torch.utils.data.Dataset):\n",
    "  \"\"\"Relabels the data up front using relabel_strategy\"\"\"\n",
    "  \n",
    "  def __init__(self, data, sprites, relabel_strategy=RelabelStrategy.GROUND_TRUTH, \n",
    "               relabel_pairs=5000, samples_per_pair=5, custom_get_mask=None):\n",
    "    if custom_get_mask is not None:\n",
    "      get_mask = custom_get_mask\n",
    "    elif relabel_strategy is RelabelStrategy.NONE:\n",
    "      get_mask = get_fully_connected_mask\n",
    "    elif relabel_strategy is RelabelStrategy.GROUND_TRUTH:\n",
    "      get_mask = get_true_flat_mask\n",
    "    elif relabel_strategy is RelabelStrategy.RANDOM:\n",
    "      get_mask = get_random_flat_mask\n",
    "    else:\n",
    "      raise NotImplementedError\n",
    "    \n",
    "    self.data = enlarge_dataset(data, sprites, relabel_pairs, samples_per_pair, \n",
    "                                flattened=True, custom_get_mask=get_mask)\n",
    "    \n",
    "    self.s1, self.a, _, self.s2 = list(zip(*self.data))\n",
    "    \n",
    "    self.s1 = torch.tensor(self.s1).detach()\n",
    "    self.a = torch.tensor(self.a).detach()\n",
    "    self.s2 = torch.tensor(self.s2).detach()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.s1)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    if torch.is_tensor(idx):\n",
    "      idx = idx.tolist()\n",
    "    s1 = self.s1[idx]\n",
    "    a  = self.a[idx]\n",
    "    s2 = self.s2[idx]\n",
    "    return torch.cat((s1, a), 0), s2\n",
    "  \n",
    "class StateActionTestDataset(torch.utils.data.Dataset):  \n",
    "  def __init__(self, data, sprites):\n",
    "    self.s1, self.a, _, self.s2 = list(zip(*data))\n",
    "    self.s1 = torch.tensor(self.s1).detach()\n",
    "    self.a = torch.tensor(self.a).detach()\n",
    "    self.s2 = torch.tensor(self.s2).detach()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.s1)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    if torch.is_tensor(idx):\n",
    "      idx = idx.tolist()\n",
    "    s1 = self.s1[idx]\n",
    "    a  = self.a[idx]\n",
    "    s2 = self.s2[idx]\n",
    "    return torch.cat((s1, a), 0), s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_none = StateActionStateRelabeledDataset(data, sprites, RelabelStrategy.NONE)\n",
    "tr_true = StateActionStateRelabeledDataset(data, sprites, RelabelStrategy.GROUND_TRUTH)\n",
    "tr_rand = StateActionStateRelabeledDataset(data, sprites, RelabelStrategy.RANDOM)\n",
    "te = StateActionTestDataset(test_data, test_sprites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('forward_model1.pickle', 'wb') as f:\n",
    "  pickle.dump((tr_none, tr_true, tr_rand, te), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('forward_model1.pickle', 'rb') as f:\n",
    "  tr_none, tr_true, tr_rand, te = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [tr_true[i][0].numpy() for i in range(len(tr_rand))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set([tuple(a) for a in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20133"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.5505,  0.6928, -0.0164, -0.0614,  0.1490,  0.5200, -0.0373, -0.0800,\n",
       "          0.7046,  0.9902, -0.0134,  0.0723,  0.3296,  0.1435, -0.0207,  0.0359,\n",
       "          0.2560,  0.4394]),\n",
       " tensor([ 0.5342,  0.6313, -0.0164, -0.0614,  0.1118,  0.4400, -0.0373, -0.0800,\n",
       "          0.6912,  1.0000,  0.0134, -0.0723,  0.3089,  0.1793, -0.0207,  0.0359]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_none[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.5505,  0.6928, -0.0164, -0.0614,  0.1490,  0.5200, -0.0373, -0.0800,\n",
       "          0.7046,  0.9902, -0.0134,  0.0723,  0.3296,  0.1435, -0.0207,  0.0359,\n",
       "          0.2560,  0.4394]),\n",
       " tensor([ 0.5342,  0.6313, -0.0164, -0.0614,  0.1118,  0.4400, -0.0373, -0.0800,\n",
       "          0.6912,  1.0000,  0.0134, -0.0723,  0.3089,  0.1793, -0.0207,  0.0359]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_none[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN AE + Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "from _invertible import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(x):\n",
    "  x = (1. - x) * 255 + 0.5\n",
    "  return torch.clamp(x, 0, 255).cpu().numpy().astype(np.uint8).transpose([1,2,0])\n",
    "\n",
    "tf = transforms.Compose([lambda x: PIL.Image.fromarray(255 - x), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz(postprocess(tf(dataset[100][0].copy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionsData(torch.utils.data.Dataset):\n",
    "  \n",
    "  def __init__(self, data, tf=tf):\n",
    "    self.data = []\n",
    "    assert(len(data[0]) == 4) # s, a, r, s'\n",
    "    self.data = [(tf(t[0].copy()), t[1], t[2], tf(t[3].copy())) for t in data]\n",
    "      \n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    if torch.is_tensor(idx):\n",
    "      idx = idx.tolist()\n",
    "    sample = self.data[idx]\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "args = argparse.Namespace\n",
    "args.batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = TransitionsData(dataset[:int(len(dataset)*5/6)])\n",
    "te = TransitionsData(dataset[int(len(dataset)*5/6):])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(tr, batch_size=args.batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "testloader  = torch.utils.data.DataLoader(te, batch_size=args.batch_size, shuffle=False, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nn.Sequential(\n",
    "  nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
    "  nn.BatchNorm2d(64),\n",
    "  nn.ReLU(),\n",
    "  nn.Conv2d(64, 256, kernel_size=3, stride=2, padding=1),\n",
    "  nn.BatchNorm2d(256),\n",
    "  nn.ReLU(),\n",
    "  nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "  nn.BatchNorm2d(512),\n",
    "  nn.ReLU(),\n",
    "  nn.Conv2d(512, 128, kernel_size=3, stride=2, padding=1),\n",
    ")\n",
    "\n",
    "decoder = nn.Sequential(\n",
    "  nn.ConvTranspose2d(128, 512, kernel_size=4, stride=2, padding=1),\n",
    "  nn.BatchNorm2d(512),\n",
    "  nn.ReLU(),\n",
    "  nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "  nn.BatchNorm2d(256),\n",
    "  nn.ReLU(),\n",
    "  nn.ConvTranspose2d(256, 64, kernel_size=4, stride=2, padding=1),\n",
    "  nn.BatchNorm2d(64),\n",
    "  nn.ReLU(),\n",
    "  nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
    "  nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 128, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, _, _, _ = next(iter(trainloader))\n",
    "y = encoder(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3, 16, 16])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvAutoencoder(encoder, decoder).cuda()\n",
    "opt = optim.Adam(model.parameters(), lr=2e-3)\n",
    "epochs = 10\n",
    "scheduler = optim.lr_scheduler.StepLR(opt, epochs // 3, gamma=0.1, last_epoch=-1)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "0.0058,0.0044,0.0038,0.0034,0.0032,0.0030,0.0029,0.0027,0.0027,0.0025,0.0024,0.0024,0.0023,0.0022,0.0022,0.0021,0.0021,0.0020,0.0020,\n",
      "training epoch took 7.2264\n",
      "avg test loss: 0.0020587551407516003\n",
      "epoch 1\n",
      "0.0019,0.0019,0.0018,0.0018,0.0018,0.0018,0.0017,0.0017,0.0017,0.0017,0.0017,0.0017,0.0016,0.0016,0.0016,0.0016,0.0016,0.0015,0.0015,\n",
      "training epoch took 7.1841\n",
      "avg test loss: 0.001557191601023078\n",
      "epoch 2\n",
      "0.0014,0.0013,0.0013,0.0013,0.0012,0.0013,0.0012,0.0012,0.0012,0.0012,0.0011,0.0011,0.0011,0.0011,0.0011,0.0011,0.0010,0.0010,0.0010,\n",
      "training epoch took 7.2508\n",
      "avg test loss: 0.0013315783580765128\n",
      "epoch 3\n",
      "0.0009,0.0008,0.0008,0.0008,0.0008,0.0008,0.0008,0.0008,0.0008,0.0008,0.0008,0.0008,0.0008,0.0008,0.0008,0.0008,0.0008,0.0008,0.0008,\n",
      "training epoch took 7.2491\n",
      "avg test loss: 0.0008168857893906534\n",
      "epoch 4\n",
      "0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,\n",
      "training epoch took 7.2705\n",
      "avg test loss: 0.0007789813680574298\n",
      "epoch 5\n",
      "0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,0.0007,\n",
      "training epoch took 7.2858\n",
      "avg test loss: 0.0007423586212098598\n",
      "epoch 6\n",
      "0.0007,0.0007,0.0007,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,\n",
      "training epoch took 7.3175\n",
      "avg test loss: 0.0007239197730086744\n",
      "epoch 7\n",
      "0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0007,0.0006,0.0006,\n",
      "training epoch took 7.3241\n",
      "avg test loss: 0.000719705771189183\n",
      "epoch 8\n",
      "0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0007,0.0006,\n",
      "training epoch took 7.3359\n",
      "avg test loss: 0.0007156100473366678\n",
      "epoch 9\n",
      "0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,0.0006,\n",
      "training epoch took 7.3408\n",
      "avg test loss: 0.0007152815815061331\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "  print('epoch %s' % epoch)\n",
    "  t = time.time()\n",
    "  model.train()\n",
    "  train_loss = 0\n",
    "  for i, (img, _, _, _) in enumerate(trainloader):\n",
    "    img = img.cuda()\n",
    "    z = model.forward(img)\n",
    "    x_hat = model.reverse(z)\n",
    "    loss = criterion(img, x_hat)\n",
    "    train_loss += loss\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    if (i+1) % 10 == 0:\n",
    "      print('{:.4f},'.format(train_loss/10.),end='',flush=True)\n",
    "      train_loss = 0\n",
    "  print('')\n",
    "  print('training epoch took {:.4f}'.format(time.time() - t))\n",
    "\n",
    "  # test loop\n",
    "  # --------------------------------------------------------------------------\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    for i, (img, _, _, _) in enumerate(testloader): \n",
    "      img = img.cuda() \n",
    "      z = model.forward(img)\n",
    "      x_hat = model.reverse(z)\n",
    "      total_loss += criterion(img, x_hat)\n",
    "      \n",
    "    print('avg test loss: {}'.format(total_loss / i))\n",
    "  scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(testloader))\n",
    "z = model.forward(x[0].cuda())\n",
    "x_hat = model.reverse(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torchvision.utils as tutils\n",
    "def show(img, w=12, h=4):\n",
    "  if isinstance(img, torch.Tensor):\n",
    "    img = img.cpu().detach()\n",
    "  npimg = img.numpy().transpose(1,2,0)\n",
    "  fig, ax = plt.subplots(figsize=(w, h))\n",
    "  print(npimg.shape)\n",
    "  ax.imshow(npimg)\n",
    "  plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 146, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(tutils.make_grid((im[:16])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 146, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAD4CAYAAADxa0fbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xuc3HV97/H3Z2Z2N9lsruSGSSABAwgBEhpRAQG5aBAOwSNFqEVUarRKBUsvQC8WT7V6TivWHoqNBcXWqhRRcmy5aTlS2yMaEAgXEeSaEBIw99tuduZz/pixLnw/k5nZ/c3uzO7r+XjksTvv+e78vpnv/H4zn535fdbcXQAAAACAocuN9AQAAAAAYLSgwAIAAACAjFBgAQAAAEBGKLAAAAAAICMUWAAAAACQEQosAAAAAMgIBRYAAAAAZIQCCwAAAAAyQoEFAAAAABkZUoFlZsvM7HEze9LMrshqUgAAAADQjszdB/eDZnlJP5N0uqS1kn4s6QJ3f3QfPzO4jQEAAADACHN3qzVmKO9gHSvpSXd/yt37JH1d0vIh3B4AAAAAtLWhFFhzJD0/4PLaSvYKZrbCzFab2eohbAsAAAAAWl6h2Rtw95WSVkp8RBAAAADA6DaUd7DWSZo34PLcSgYAAAAAY9JQCqwfS1poZgvMrFPS+ZJWZTMtAAAAAGg/g/6IoLv3m9klku6QlJd0g7s/ktnMAAAAAKDNDLpN+6A2xjlYAAAAANpUs9u0AwAAAAAGoMACAAAAgIw0vU37YJVKpbrH9u7eHubf+PonwryQ70myd77rqnBsZ2d8F5ml7w5W+7Tljh0bk+zRx/4xHLvo4DPDfMJ+h0SziDfYgFyu/hq72ppUy+/58XeT7Nbvx31Qfv+C9P6fNXtmOLZv77Ywv+uh9D6dkBsfjj3u6AuTbFxnVzg2WutmamRNPvE/rwnzRYsODvOzTz8j3V4+X/f2GlX09LHxw/v/JRx7YC6+n+cuDvaJFl4TSdq+6aUku+GW+BizcP7SJDvtxPeFY/O5eK2syn0X2d3fl2Tr1z4ejp2z3wFh3jVxct3ba5ZG1+TvbkqPPectXxaOndzRnKfG/r7dYb7q+1eG+QFzFibZ4kM/FI4tRPdHi+8nvbvT+8Oq3PcFq3Kciv6L1U5GGN67o2U0si57du5JMrP45zuqvD7iV/e1NbImxSqvsRp5OPcX09u48du3hWMPXHREmJ926PwGtth+Gj1+1by9TG8NAAAAAMYwCiwAAAAAyAgFFgAAAABkhAILAAAAADJCgQUAAAAAGWnZPzTcSBfBarbtTbvhSFLH3v4kG9+ddhbMyq4dzyXZF//xvHDs8cecHOZLX/8XaZhBh6gsugg2Mr6vVAzHdhU6kqzR/11faUeSFao0yszlxjV468OnkTXZuTv9P0tSV0f8/8u6S04tpaCL4N+tirugHbI53U8k6ZT3fDvJbJjXr9H7LXrs7+nfFY7NW2eSdeSb1+B1+/YXk+xLqz4Wjv3vr39XmM895JxM5zQYja7J7t3p80FXV3rfj4T+UvqcJMXHwHyuZZv/Nrwmt9+fdprtLkwJxx532JJ4m4Wgo2+Vpyq39IpclQ55o0kj63Lf408n2YbbfxaOPfX8E8O8Y0bckRe/0lAXwaADoNTYS8C+3vS11/mXfzQce+5/i7vY/sbb0o63o0kja8IfGgYAAACAYUSBBQAAAAAZocACAAAAgIxQYAEAAABARiiwAAAAACAjrduOKAOTqnRSU9qwrqm6e+Yl2W9fvKrK6CqTG3rDwGEXdWQZ18Qudp25CU277VY1vqt7pKewT1GHrvcv+3Q4ttS/Pr4RGx2HqXGF1lirrs70GHPaiXE3sKlTFjR7OsOmVToGRgot3Bmwmb5yz1eT7ICps8Kxbzjs6DA35ZPs3h+/HI79h2c+l2RXnvlb4di5PfPDfLS7/8nHkuzBO74Rjj3htDeEOV0Es9W/J+6+XAwac3fkq7xYDMZe/JunhEPfvPDg+ieHqngHCwAAAAAyQoEFAAAAABmhwAIAAACAjFBgAQAAAEBGhnRmrZk9I2m7pKKkfndfmsWkRp/0pMPOjpkjMI/RobfUF+ZW2plkHYWJ8djR3d+lpXV1Ta1yxbS6b8PT83UlSdaGzWCGmwWNR8bl4vu+c1zccADIwjsXH5lk27riY7PlquzcwbHg4Y0/CYfecc+/JtmZp54Rjh2rTS7ePP/AJDvk7ReEYz1+eg2PzxybB2/Li1vD/LPf/MskK0yIG2JceMw5SfbUnf8Rjl0886gwn7RfleduhLJ4lfkWd49b9gAAAADAGMJHBAEAAAAgI0MtsFzSnWZ2n5mtiAaY2QozW21mq4e4LQAAAABoaUP9iOAJ7r7OzGZKusvMfuru9wwc4O4rJa2UJLPgL50BAAAAwCgxpHew3H1d5etGSd+SdGwWkwIAAACAdjTod7DMbIKknLtvr3z/VkmfyGxmTdTbuyfN+n4Rjp008TVVboWWOM1WLMXdcG5e86dhvnXPz5Ps4qXXh2O78pMGPzEkSlXa+u3s35xk46wnHNtR6Kx7e3SkGrzdfS8l2Z9d+6lw7OnvXBPmv7nk6iSzXH5oE8OYs+mF9Phw3wvpcVyS3rnofWHeM2FCkv3G204Ix5562s1JNmfcvH1Nccx59qFHkuza//PFcOypxePD/MMf/KMky3dyfBisqTPi58y3H31Sku3o2xSO3bwtfd07f96ScOyUydMbmB2qGcpHBGdJ+paVX+kUJP2Tu9+eyawAAAAAoA0NusBy96ckHZ3hXAAAAACgrdGmHQAAAAAyQoEFAAAAABkZapv2llb0UpjfevfvJNl9/35/OPaPr/pOmE+csP/gJ4a6WJXGCfO3pCfpS9LT214IbiM9sbOMJhdZ2rzjZ2F+zZfOTbIzT35jOPZNR62scut0tMhSd/dBSXbh+R8Nx7527iHxjeRYkyx5lWNdyXuTLJ+r1gym/X5feuZJFyXZ8ZvXh2O7x3fUfbvdnePDfIHSxz5eaeHCw5Ks64iDw7Fb94+bIewNMlpcDF6hJ97nTzj1rUlmDRybvRgfdxq5DVTXfkdkAAAAAGhRFFgAAAAAkBEKLAAAAADICAUWAAAAAGSEAgsAAAAAMmLVuhc1ZWNmdW+sVIo7ADbCq3QRfGHjPyfZ4z//z3Dsm5b8aZiPH7/f4CfWQnK5+mvsLNYkC+59VfJiklmVjlvWwj2N2nFN9vSuDfNv3fHBJDv0dW8Ixy5Z+Mdhbi3we6BG1kRqnXUZqmoH7FboMTWa1mTt5kfC/Avf/ZMk++hbrwrHzpz8a0E6vCvV6JoUi+kxWxbPuRUec+2qkXXZ25c+v/aW+sOxnYWuMC/Qha6mdnyeH+0aWRN3r/kgH/lXLgAAAAAwSlBgAQAAAEBGKLAAAAAAICMUWAAAAACQEQosAAAAAMhIYaQn0Exmcf04Z9a7guy8areS4YyQBbMqnQFZqhEzrmtumJ9/1q1BGvema4VugXgldqnhUdrbG+Y7n3w5yba9eXs4dsakNGv1Y6K1+gTHoHwhfVnYPbpfKgJNwSsaAAAAAMgIBRYAAAAAZIQCCwAAAAAyQoEFAAAAABkx9/iE8/8aYHaDpLMkbXT3RZVsmqRvSJov6RlJ57n75pobM9v3xgYolUr1DsUQ5HL119isyfBgTVpPI2sisS7DYTStiXs8t769u5Isn+8KxxbyHZnOaTBG05qMJsP9nFIqFpNs95o14djxhx+ZZLnO/JDn0Op4nm89jayJu9fs0FPPrX1Z0rJXZVdI+p67L5T0vcplAAAAABjTahZY7n6PpE2vipdLurHy/Y2Szsl4XgAAAADQdgZ7DtYsd19f+f5FSbMymg8AAAAAtK0h//U4d/d9nVtlZiskrRjqdgAAAACg1Q32HawNZra/JFW+bqw20N1XuvtSd186yG0BAAAAQFsY7DtYqyRdJOnTla+3ZjYjAADGELP4d51dnT3DPJP20795R5L1rv5xOLZw6KIk6zpgRuZzGuv6t25NslsvPC8ce/gJr+6hJi3+28/HN1yzbxvQOmq+g2VmX5P0/yQdamZrzexilQur083sCUmnVS4DAAAAwJhW8x0sd7+gylWnZjwXAAAAAGhrgz0HCwAAAADwKhRYAAAAAJARCiwAAAAAyMiQ/w4WAADASPCt6V+JufP3Lg3HHrP8nCQ78OpPxDdMx7pB65w8McnO+tQl4dj8uLSzI16l2l+a5THa0ngHCwAAAAAyQoEFAAAAABmhwAIAAACAjFBgAQAAAEBGzL3a2XNN2JhZ3RsrlUrNnAoqcrn6a2zWZHiwJq2nkTWRWJfhMJrWxL0YXxGcxG7KN3cyQzASa+LF9L7rve3fwrG5185Pss7DFg55Dq2upZ9ToleFY6B5QyNrsnPb9jC3p36aZF0LD4vHjp9Q9/bGqkbWxN1rPkp5BwsAAAAAMkKBBQAAAAAZocACAAAAgIxQYAEAAABARiiwAAAAACAjdBEc41q6u1DD0oeXhy2KJGvh3y2MrjVJlTyes5d2hXk+H3U/Gt42U6OpY12kv7g7vsLjvFCY1sTZ1KfV18SD7a1d9/1w7JrnvhDmxx714SSbPvGkoU2siVp9TehYV1u7HbvaVSNr8sJjPwvzR957RpId94fvD8eOP+fKurc3VtFFEAAAAABaFAUWAAAAAGSEAgsAAAAAMkKBBQAAAAAZKdQaYGY3SDpL0kZ3X1TJ/kzSByS9VBl2lbv/a7MmORr1l3bEV/j2MC7kZwZpPrsJjQI7+n6aZOs3xQ/Lg2Z8IMny+UmZzwmpTTs3hPnDT1wS5kceenGS7dedntxbNgbOWG+Cex68Nsx7i/8e5m9d+g9Jljf2n1cIHordk6aEQzsmRcd3aXfYEKZaryge+zVxF6ENzTxgfpjnPp42rvDXHR3fSNTQztghmqmed7C+LGlZkF/j7osr/yiuAAAAAIx5NQssd79H0qZhmAsAAAAAtLWhnIN1iZk9ZGY3mNnUzGYEAAAAAG1qsAXWdZIOlrRY0npJf1VtoJmtMLPVZrZ6kNsCAAAAgLYwqALL3Te4e9HdS5K+KOnYfYxd6e5L3X3pYCcJAAAAAO2gZhfBiJnt7+7rKxffIenh7KY0+njQCeqlXfeFY9c+8ZkwP2zhx5JsYs/pQ5tYmyqFnbWk7XseSLLv/vzmcOy7Jp6cZNMmHFNli3TayVLO4u6XW7wvzLfvTbsOTqty26zU4MyYfnCYb9j7WJh72JEqyxm1P7P095f7TV4Sjj1t0efCvKRidMtDmRaANpMbH79Un7ns/WlIk9GWUU+b9q9JOlnSdDNbK+njkk42s8UqL+Uzkj7YxDkCAAAAQFuoWWC5+wVBfH0T5gIAAAAAbW0oXQQBAAAAAANQYAEAAABARiiwAAAAACAjFnaDatbGzOreWKkUd4prR3tLvUm2o/f5cOwDz9wS5lN6jkiyI18TdxEs5DvrnlsuV3+N3Spr4ornsae4LcnW7XkmHDszPzvJejqnh2NzuUE12xy0dlyTRhS9P8x3F7eGeS5of9SVnxKOzQed2xpVDO7TjkJjj4F2W5ei7w3z/ip5h6XHmJw1bz+Jnqfy+bgbZTXttiaS5EFLMGvhdmCNHLuk9lyTdjTan1Pa0XCvSXFv1JE0fkme7xje1zytopE1cfeaB2LewQIAAACAjFBgAQAAAEBGKLAAAAAAICMUWAAAAACQkZZtcgEAAAAArYQmFwAAAAAwjCiwAAAAACAjFFgAAAAAkBEKLAAAAADICAUWAAAAAGSEAgsAAAAAMkKBBQAAAAAZocACAAAAgIxQYAEAAABARiiwAAAAACAjNQssM5tnZneb2aNm9oiZXVrJp5nZXWb2ROXr1OZPFwAAAABal7n7vgeY7S9pf3e/38wmSrpP0jmS3itpk7t/2syukDTV3f+wxm3te2MD9BeLce6lJNu9Z3c4Nqd8mE8YNy4dm7N6pzaq5HL1v4l547/8XZgfOiWurY868sQk6+reLxxruXitxqJG1qRvT1+Yr/nJi2H+8rpNSXbKmUeGY/NdY3OfiDSyJpJUKqXHKWRrVK1JtWfGNtsFR9WajCKNrAtrMjwaWZM9u+LXuDtLLyVZT2f8GqujML7u7Y1VjayJu9c8Ote8NXdf7+73V77fLukxSXMkLZd0Y2XYjSoXXQAAAAAwZjX06yYzmy9piaR7Jc1y9/WVq16UNCvTmQEAAABAmynUO9DMeiR9U9Jl7r7N7Ffvjrm7V/v4n5mtkLRiqBMFAAAAgFZX1ztYZtahcnH1VXe/pRJvqJyf9cvztDZGP+vuK919qbsvzWLCAAAAANCqar6DZeW3qq6X9Ji7f3bAVaskXSTp05Wvt2Y7tfj8sReDhha3P/NwOPYd844I84ljtKHFUPUc/uYw33+/+NOhnRMmJZkZzSyylMvH9+faJ3eF+e6Nm9PbqNp7hv1ksPpL/UlWyNX9gQGMNexqAKpYt/bnYf6Baz+YZJf/zhXh2DMOOjPTOaG2ep7xj5d0oaQ1ZvZAJbtK5cLqJjO7WNKzks5rzhQBAAAAoD3ULLDc/Qeq/vu1U7OdDgAAAAC0r8b+aAUAAAAAoCoKLAAAAADICAUWAAAAAGSkZdtaFUulMP/u808n2bPr1wcjpfELjsp0TmPdcTMWhPm0cZ1hnjNaYzWbVemIefoZB4V5cVva8bHabWDw/uGB7ybZ8sPfGI6dNm5Ks6cDSdFTyvZte8OxPRPSp8Z8B/tJK9pTKiZZfyle1+58R5Ll6Gw7aO5xB9q1O3YmWaE/Hjt7ck+SWbXXDmN0Fyzk9oT59NnpfddXmByOLQZ3f36M3p/DhXewAAAAACAjFFgAAAAAkBEKLAAAAADICAUWAAAAAGSEAgsAAAAAMmLVusA0ZWNmdW9sd+/uMH9i0/NJtl/XuHDs7Clz4nmM1VY0gVyu/hp709ZtYd7X3x/mnR1pJ67J3d3h2FLwOMxXm9so707YyJoUi3G3zWp3kZfS+9mqbm5038+NaGRNJOmS7/9Nkl18xJnh2COnHphur8oCRvuJFK9U1U5co0Sja/LTDVuS7Orf/edw7IlHH5ZkKy4/Phw7yu/mhjS6JqUq3YIj1V6qPLr1pST785v/Khx7yVuWJ9lxB8XdPUfT/tPIujSyJi+8tDnMz/2T9Pg3f/5rw7HXXXZukk3qijsTj6IlaWhN+vvirphFpTtFLh/fbr76Ez0qGlkTd6/5aOQeBwAAAICMUGABAAAAQEYosAAAAAAgIxRYAAAAAJCRtAtBizCPa7+Na/8jyXZN6gjHzpz462Gez8fjsW/bXtwQ5pf9/gfC/JA5M5Ps/BUfCcfeftuqJDvvvR8Mxx40Oz5ZFr+ye28xzLdseSHJunLbw7FTp6Un+hsnytbliiXvSTLvjA+3/UHjEfd4/T71xS+G+bzX9SbZxSddGo4dTSfvN2LXjk1JdthRM8Kxs2dMTLItW9L7WJImTYlPyM+P0fu5WardndOC5heP3n5nOPamKfOS7PiD3zSUaY1pHfn4sX/WMScl2RFvnB+O7QkaWrDrvFKukI/zYZ4HGsP6AAAAAEBGKLAAAAAAICMUWAAAAACQEQosAAAAAMhIzQLLzOaZ2d1m9qiZPWJml1byPzOzdWb2QOXf25s/XQAAAABoXfV0EeyXdLm7329mEyXdZ2Z3Va67xt3/sikTy8W13+xJs5Ps+q99JRw7Z8WhcT771wY/sTFs9tz5YX7lJZ8J8+lT0s43HZ194die6WnboN2/2FZlInE8FrkHLbQkPfTSc2H+2x9/f5KduGxBOPYzZ1+XZF0dXQ3MTopmNxYaRJW27k6yn72wPhz77I40m3NI3N3uwdV3hPmL8yYn2fstfmzYmFiBVE8ufex+YMWycGxncNfd8cC3w7GF/p1h/o63/EaS5fON7T+obb8J6WP/vKXLw7GLFp7e7OmMKTOmTgjz37vohCQrVjke5cfm4QhjQM0Cy93XS1pf+X67mT0maU6zJwYAAAAA7aahc7DMbL6kJZLurUSXmNlDZnaDmU3NeG4AAAAA0FbqLrDMrEfSNyVd5u7bJF0n6WBJi1V+h+uvqvzcCjNbbWarM5gvAAAAALSsugosM+tQubj6qrvfIknuvsHdi+5ekvRFScdGP+vuK919qbsvzWrSAAAAANCKap6DZWYm6XpJj7n7Zwfk+1fOz5Kkd0h6OMuJ5XLxmY9zZh2VZFMP6gjHPrT95TB/TdAkgfMsa+scnzatkKTXn/b6Id/2Rw57w5BvYywqleITh3+xa3OYT1qQPviPOebscGxHoXPwE6sYq/tVdyH93dWdN8dNEja98GiSffKvV4Zjv3LtP4V5Z2e6Vjn+CscrrL7tR0mWmxA3E3nDmw9OsoceXxOO3bJhbZifc8q7G5jd2FTsLyZZPl/lcWvx0aSjI33+v+wjH47Hjp9S/+QwaFu3pE1+vnvP/w3HHnvaSUm2YMrEcGyVl4VAS6qni+Dxki6UtMbMHqhkV0m6wMwWq9wo7BlJH2zKDAEAAACgTdTTRfAHin8R/a/ZTwcAAAAA2hefIQEAAACAjFBgAQAAAEBGKLAAAAAAICPmHncha8rGzOreWKlYCvOi702ytdufDsdO6poc5lPHzYxmV+/URpVcrv4au1SK1wTZamRN+vv64tz6w7xP6S7YnR8XzyODfSLa4dtxT2tkTSSp2Jcep55b+3w4dvfebUl26MK0W6rUnvddszS6Jh/+7WuSrDg17pT55797XpJ198RdVDty8W0UCt0NzG50aHRN7vjPO5OsuzO+jeOWnBzmFv2emB3lFYb7ef6FtRuT7OOf/1Q49tTj3pNkv372MeHYag0m21FDz/P98fN59Di3ag/+oAtnoy//R3sXx0bWxN1r3huj6OEKAAAAACOLAgsAAAAAMkKBBQAAAAAZocACAAAAgIxQYAEAAABARlq3i2ADnWyq3egob3iSCboItp5G1mTP5pfDPD8p7qCZs7QTGvtJbY12R2Nfab5G12TjE79IsslzJ4VjO7rijoHYt0bX5NyLL0yyWSfNC8d+/t3/I8wt6I6GVxru5/noZeWePWlnVSmeW9cY2P8aWZOnX4g7Zd++5ptJ9pZDzgzHLpj32iT76v0/Csf6nv3C/KLjDkmyBnf5lkYXQQAAAABoURRYAAAAAJARCiwAAAAAyAgFFgAAAABkpDDSE8gCp7hirNqy9akwnz5pSZizr2Csmn7w1JGeAl7lQ5d+LMmOmHVgOJZmFsMjahrmpbiV2O5dfWGeC353P647frlpOda1lu89/WSY33Dz95PsiEtODcfOK6ZreMst3wnHjreFYX7R8WmTC1THO1gAAAAAkBEKLAAAAADICAUWAAAAAGSEAgsAAAAAMlKzwDKzcWb2IzN70MweMbOrK/kCM7vXzJ40s2+YWWfzpwsAAAAArcvc4+4w/zWg3LpngrvvMLMOST+QdKmk35V0i7t/3cy+IOlBd7+uxm3te2MDlEqleodiCHK5+t/EZE2GRyNr8r3vXBbmb37b1WFeyE8c1JzGukbWRGJfGQ6sSetpdE2KxXRNaBaYvUbWpT9Yk9U/fzYce+0XPhfm737nRUl22rFHx3PLj80Fb2RNtu3uDfPe4u4k6+kcF44t5DqS7KWdO8Ox3VXeL5nUM7rfR2lkTdy95gO35q152Y7KxY7KP5d0iqSbK/mNks6pe2YAAAAAMArVVa6ZWd7MHpC0UdJdkn4uaYu791eGrJU0pzlTBAAAAID2UFeB5e5Fd18saa6kYyUdVu8GzGyFma02s9WDnCMAAAAAtIWGPjDt7lsk3S3pTZKmmNkv/zT3XEnrqvzMSndf6u5LhzRTAAAAAGhx9XQRnGFmUyrfj5d0uqTHVC60zq0Mu0jSrc2aJAAAAAC0g0LtIdpf0o1mlle5ILvJ3b9jZo9K+rqZ/bmkn0i6vonzRAuo1nCSrk8jp2NXvCj9vWl3IUkqdNNFEPiVagevuhveYgh47mg9Vkof+/Mnxp3pjpg5Psz3PyDtNjdWuwVmoacr7QAoST2K83rNntgzpJ/HvtUssNz9IUlLgvwplc/HAgAAAACowXOwAAAAAADVUWABAAAAQEYosAAAAAAgI+bVOhc0Y2NmdW+sVCo1cyqoyOXqr7E3PLw+zGccPiur6UCNrUnvnm1h3tExIf4BzioflEbWROL4NRyyWROaXGSJ/aQ1NbIupWKwJlV2k1LQEKMszRt9bIx2Da0J+8mwaGRN3L3miyke8QAAAACQEQosAAAAAMgIBRYAAAAAZIQCCwAAAAAyQoEFAAAAABkpjPQEqtn1ws4w735Nle5oaLqvferGMP/IDZeHeb4z38zpQFJHZ89ITwGBXRvT41f3TI5drYdugSPJgy501ltlTcZV+X0wjVEz5Z52rDOL7/tcrtqdz6IAvIMFAAAAABmhwAIAAACAjFBgAQAAAEBGKLAAAAAAICMt2+TiM+/5izD/41UfT7KO7o5mTweSTnrrSWGe66BOBwa66ZPfTLKLrrkwHGtVTxRHlkr9xTTc1BuOzU0dl4Yc5zK35gcPJdmOP0if4yXpTbfGTZZs1uRM5zTW7djyYpJNmDorHJszGlkNh+0vbw3znmmTkoznk9bBMwYAAAAAZIQCCwAAAAAyQoEFAAAAABmhwAIAAACAjNQssMxsnJn9yMweNLNHzOzqSv5lM3vazB6o/Fvc/OkCAAAAQOuqp4tgr6RT3H2HmXVI+oGZ3Va57vfd/eZmTOzs974tzPOddK0ZKUe865gwN6NrDTDQW97x+iRjPxlZ655bm2SPfv4L4dgjTlmeZHOWHRuOtU4+CDJYtuUXSfbIxHg/ed3al8N86sygiyC72qCtuv+mJDvxmHPCsbMmzQnzzgKdnbP0j3/z12H+7o9cmmSTov0BI6JmgeXuLmlH5WJH5Z83c1IAAAAA0I7q+tWbmeXN7AFJGyXd5e73Vq76pJk9ZGbXmFlX02YJAAAAAG2grgLL3YvuvljSXEnHmtkiSVdKOkzS6yVNk/SH0c+a2QozW21mqzOaMwAAAAC0pIY+PO7uWyTdLWmZu6/3sl5JX5IUfkDd3Ve6+1J3Xzr06QIAAABA66qbrwi1AAAGeklEQVSni+AMM5tS+X68pNMl/dTM9q9kJukcSQ83c6IAAAAA0Oqs3MNiHwPMjpJ0o6S8ygXZTe7+CTP7N0kzVO7X84CkD7n7juq3JJkZzTEAAAAAtCV3r9mrtGaBlSUKLAAAAADtqp4Ciz/gAQAAAAAZocACAAAAgIxQYAEAAABARiiwAAAAACAjFFgAAAAAkBEKLAAAAADICAUWAAAAAGSEAgsAAAAAMkKBBQAAAAAZKQzz9l6W9Gzl++mVy2hPrF97Y/3aG+vX/ljD9sb6tTfWr72N5PodWM8gc/dmTyTesNlqd186IhvHkLF+7Y31a2+sX/tjDdsb69feWL/21g7rx0cEAQAAACAjFFgAAAAAkJGRLLBWjuC2MXSsX3tj/dob69f+WMP2xvq1N9avvbX8+o3YOVgAAAAAMNrwEUEAAAAAyMiwF1hmtszMHjezJ83siuHePhpjZvPM7G4ze9TMHjGzSyv5NDO7y8yeqHydOtJzRXVmljezn5jZdyqXF5jZvZX98Btm1jnSc0R1ZjbFzG42s5+a2WNm9ib2wfZhZh+rHD8fNrOvmdk49sHWZmY3mNlGM3t4QBbuc1b2+cpaPmRmx4zczCFVXb//VTmGPmRm3zKzKQOuu7Kyfo+b2dtGZtb4pWj9Blx3uZm5mU2vXG7J/W9YCywzy0u6VtIZkg6XdIGZHT6cc0DD+iVd7u6HS3qjpI9U1uwKSd9z94WSvle5jNZ1qaTHBlz+jKRr3P21kjZLunhEZoV6/bWk2939MElHq7yW7INtwMzmSPqopKXuvkhSXtL5Yh9sdV+WtOxVWbV97gxJCyv/Vki6bpjmiOq+rHT97pK0yN2PkvQzSVdKUuU1zfmSjqj8zN9WXq9i5HxZ6frJzOZJequk5wbELbn/Dfc7WMdKetLdn3L3Pklfl7R8mOeABrj7ene/v/L9dpVf2M1Red1urAy7UdI5IzND1GJmcyWdKenvK5dN0imSbq4MYf1amJlNlnSipOslyd373H2L2AfbSUHSeDMrSOqWtF7sgy3N3e+RtOlVcbV9brmkr3jZDyVNMbP9h2emiETr5+53unt/5eIPJc2tfL9c0tfdvdfdn5b0pMqvVzFCqux/knSNpD+QNLCBREvuf8NdYM2R9PyAy2srGdqAmc2XtETSvZJmufv6ylUvSpo1QtNCbZ9T+YBUqlzeT9KWAU807IetbYGklyR9qfIxz783swliH2wL7r5O0l+q/BvX9ZK2SrpP7IPtqNo+x2ub9vN+SbdVvmf92oCZLZe0zt0ffNVVLbl+NLlAXcysR9I3JV3m7tsGXuflVpS0o2xBZnaWpI3uft9IzwWDVpB0jKTr3H2JpJ161ccB2QdbV+U8neUqF8qvkTRBwUdf0F7Y59qXmf2Ryqc/fHWk54L6mFm3pKsk/elIz6Vew11grZM0b8DluZUMLczMOlQurr7q7rdU4g2/fAu28nXjSM0P+3S8pLPN7BmVP5J7isrn80ypfFxJYj9sdWslrXX3eyuXb1a54GIfbA+nSXra3V9y972SblF5v2QfbD/V9jle27QJM3uvpLMkvdt/9XeKWL/Wd7DKv6R6sPJ6Zq6k+81stlp0/Ya7wPqxpIWV7kmdKp9UuGqY54AGVM7XuV7SY+7+2QFXrZJ0UeX7iyTdOtxzQ23ufqW7z3X3+Srvb//m7u+WdLekcyvDWL8W5u4vSnrezA6tRKdKelTsg+3iOUlvNLPuyvH0l+vHPth+qu1zqyS9p9LN7I2Stg74KCFahJktU/nj8me7+64BV62SdL6ZdZnZApWbJfxoJOaImLuvcfeZ7j6/8npmraRjKs+PLbn/DfsfGjazt6t8Tkhe0g3u/slhnQAaYmYnSPp3SWv0q3N4rlL5PKybJB0g6VlJ57l7dEIiWoSZnSzp99z9LDM7SOV3tKZJ+omk33T33pGcH6ozs8UqNynplPSUpPep/Asy9sE2YGZXS3qXyh9L+omk31L5HAH2wRZlZl+TdLKk6ZI2SPq4pG8r2OcqhfP/Vvmjn7skvc/dV4/EvFFWZf2ulNQl6ReVYT909w9Vxv+Ryudl9at8KsRtr75NDJ9o/dz9+gHXP6NyZ9aXW3X/G/YCCwAAAABGK5pcAAAAAEBGKLAAAAAAICMUWAAAAACQEQosAAAAAMgIBRYAAAAAZIQCCwAAAAAyQoEFAAAAABmhwAIAAACAjPx/ii2M6Oo9jHkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(tutils.make_grid((x_hat[:16].cpu())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nice so autoencoding definitely works.\n",
    "# Now to train end-to-end with a flow model. \n",
    "# we just need a very simple linear flow  & then constrain '\n",
    "# # latent space with mmd\n",
    "# Should first do it on CIFAR, and make sure that CIFAR generation makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel(x, y):\n",
    "    x_size = x.size(0)\n",
    "    y_size = y.size(0)\n",
    "    dim = x.size(1)\n",
    "    x = x.unsqueeze(1) # (x_size, 1, dim)\n",
    "    y = y.unsqueeze(0) # (1, y_size, dim)\n",
    "    tiled_x = x.expand(x_size, y_size, dim)\n",
    "    tiled_y = y.expand(x_size, y_size, dim)\n",
    "    kernel_input = (tiled_x - tiled_y).pow(2).mean(2)/float(dim)\n",
    "    return torch.exp(-kernel_input) # (x_size, y_size)\n",
    "\n",
    "def compute_mmd(x, y):\n",
    "    x_kernel = compute_kernel(x, x)\n",
    "    y_kernel = compute_kernel(y, y)\n",
    "    xy_kernel = compute_kernel(x, y)\n",
    "    mmd = x_kernel.mean() + y_kernel.mean() - 2*xy_kernel.mean()\n",
    "    return mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _, _, _ = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [4, 1, 3, 3], expected input[1000, 2, 16, 16] to have 1 channels, but got 2 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-e78239ed2830>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/crl/pytrev/iRevNet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0mout_bij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_bij\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/crl/pytrev/iRevNet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mFx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottleneck_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [4, 1, 3, 3], expected input[1000, 2, 16, 16] to have 1 channels, but got 2 channels instead"
     ]
    }
   ],
   "source": [
    "_, z = model(F.pad(x, (0,0,0,0,0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 128, 4, 4])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*4*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "# ------------------------------------------------------------------------------\n",
    "for epoch in range(start_epoch, args.n_epochs):\n",
    "  print('epoch %s' % epoch)\n",
    "  t = time.time()\n",
    "  model.train()\n",
    "  num_batches = len(train_loader)\n",
    "  for i, (img, _, _, _) in enumerate(train_loader):\n",
    "    # if i > 3 : break\n",
    "\n",
    "    img = img.cuda() \n",
    "    _, z = model(img)\n",
    "    true_samples = torch.randn(args.batch_size, z.shape)\n",
    "\n",
    "    # Generative loss\n",
    "    nobj = torch.mean(nll)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    nobj.backward()\n",
    "    torch.nn.utils.clip_grad_value_(model.parameters(), 5)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 100)\n",
    "    opt.step()\n",
    "    avg_train_bits_x += nobj.item()\n",
    "\n",
    "    # update learning rate\n",
    "    new_lr = float(args.lr * min(1., (i + epoch * num_batches) / (args.n_warmup * num_batches)))\n",
    "    for pg in opt.param_groups: pg['lr'] = new_lr\n",
    "\n",
    "    if (i + 1) % args.print_every == 0: \n",
    "      print('avg train bits per pixel {:.4f}'.format(avg_train_bits_x / args.print_every))\n",
    "      avg_train_bits_x = 0.\n",
    "      sample = (model.module.sample())\n",
    "      grid = utils.make_grid(sample)\n",
    "      utils.save_image(grid, './glow/rl_samples/rl_Test_{}_{}.png'.format(epoch, i // args.print_every))\n",
    "    print('.',end='',flush=True)\n",
    "  print('')\n",
    "  print('training epoch took {:.4f}'.format(time.time() - t))\n",
    "\n",
    "  # test loop\n",
    "  # --------------------------------------------------------------------------\n",
    "  if (epoch + 1) % args.test_every == 0:\n",
    "    model.eval()\n",
    "    avg_test_bits_x = 0.\n",
    "    with torch.no_grad():\n",
    "      for i, (img, _, _, _) in enumerate(test_loader): \n",
    "        # if i > 10 : break\n",
    "        img = img.cuda() \n",
    "        objective = torch.zeros_like(img[:, 0, 0, 0])\n",
    "\n",
    "        # discretizing cost \n",
    "        objective += float(-np.log(args.n_bins) * np.prod(img.shape[1:]))\n",
    "\n",
    "        # log_det_jacobian cost (and some prior from Split OP)\n",
    "        z, objective = model(img, objective)\n",
    "        last_img = img\n",
    "\n",
    "        nll = (-objective) / float(np.log(2.) * np.prod(img.shape[1:]))\n",
    "\n",
    "        # Generative loss\n",
    "        nobj = torch.mean(nll)\n",
    "        avg_test_bits_x += nobj.item()\n",
    "\n",
    "      print('avg test bits per pixel {:.4f}'.format(avg_test_bits_x / i))\n",
    "\n",
    "      sample = (model.module.sample())\n",
    "      utils.save_image(sample, './glow/rl_samples/rl_Test_{}.png'.format(epoch))\n",
    "\n",
    "      # reconstruct\n",
    "      x_hat = (model.module.reverse_(z, objective)[0])\n",
    "      utils.save_image(x_hat, './glow/rl_samples/rl_Test_Recon{}.png'.format(epoch))\n",
    "\n",
    "      utils.save_image((last_img), './glow/rl_samples/rl_Test_Target.png')\n",
    "\n",
    "\n",
    "\n",
    "  if (epoch + 1) % args.save_every == 0: \n",
    "    save_session(model, opt, args, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model and ship to GPU\n",
    "# model = Glow_((args.batch_size, 3, IMAGEDIM, IMAGEDIM), args).cuda()\n",
    "# print(model)\n",
    "# print(\"number of model parameters:\", sum([np.prod(p.size()) for p in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the optimizer\n",
    "opt = optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=45, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data dependant init\n",
    "init_loader = torch.utils.data.DataLoader(tr, batch_size=args.batch_size, shuffle=True, num_workers=1, drop_last=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "  model.eval()\n",
    "  for (img, _, _, _) in iter(init_loader):\n",
    "    img = img.cuda()\n",
    "    objective = torch.zeros_like(img[:, 0, 0, 0])\n",
    "    _ = model(img, objective)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "model = nn.DataParallel(model).cuda()\n",
    "\n",
    "# load trained model if necessary (must be done after DataParallel)\n",
    "#if args.load_dir is not None: \n",
    "#    model, opt, start_epoch = load_session(model, opt, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "..................................................\n",
      "training epoch took 23.6813\n",
      "epoch 1\n",
      "..................................................\n",
      "training epoch took 23.6226\n",
      "epoch 2\n",
      "..................................................\n",
      "training epoch took 23.6804\n",
      "epoch 3\n",
      "..................................................\n",
      "training epoch took 23.6950\n",
      "epoch 4\n",
      "..................................................\n",
      "training epoch took 23.7230\n",
      "epoch 5\n",
      "..................................................\n",
      "training epoch took 23.7687\n",
      "epoch 6\n",
      "..................................................\n",
      "training epoch took 22.8972\n",
      "epoch 7\n",
      "..................................................\n",
      "training epoch took 23.8966\n",
      "epoch 8\n",
      "..................................................\n",
      "training epoch took 23.7964\n",
      "epoch 9\n",
      "..................................................\n",
      "training epoch took 23.8329\n",
      "epoch 10\n",
      "..................................................\n",
      "training epoch took 23.3122\n",
      "epoch 11\n",
      "..................................................\n",
      "training epoch took 22.5486\n",
      "epoch 12\n",
      "..................................................\n",
      "training epoch took 23.7663\n",
      "epoch 13\n",
      "..................................................\n",
      "training epoch took 23.9304\n",
      "epoch 14\n",
      "..................................................\n",
      "training epoch took 24.0061\n",
      "epoch 15\n",
      "..................................................\n",
      "training epoch took 23.6011\n",
      "epoch 16\n",
      "..................................................\n",
      "training epoch took 22.5680\n",
      "epoch 17\n",
      "..................................................\n",
      "training epoch took 22.7026\n",
      "epoch 18\n",
      "..................................................\n",
      "training epoch took 22.6933\n",
      "epoch 19\n",
      "..................................................\n",
      "training epoch took 23.9802\n",
      "epoch 20\n",
      "..................................................\n",
      "training epoch took 23.9745\n",
      "epoch 21\n",
      "..................................................\n",
      "training epoch took 23.8390\n",
      "epoch 22\n",
      "..................................................\n",
      "training epoch took 23.9262\n",
      "epoch 23\n",
      "..................................................\n",
      "training epoch took 23.9582\n",
      "epoch 24\n",
      "..................................................\n",
      "training epoch took 23.8163\n",
      "avg test bits per pixel 0.3472\n",
      "Successfully saved model\n",
      "epoch 25\n",
      "..................................................\n",
      "training epoch took 23.9860\n",
      "epoch 26\n",
      "..................................................\n",
      "training epoch took 23.9760\n",
      "epoch 27\n",
      "..................................................\n",
      "training epoch took 23.7593\n",
      "epoch 28\n",
      "..................................................\n",
      "training epoch took 23.8976\n",
      "epoch 29\n",
      "..................................................\n",
      "training epoch took 23.9090\n",
      "epoch 30\n",
      "..................................................\n",
      "training epoch took 23.9708\n",
      "epoch 31\n",
      "..................................................\n",
      "training epoch took 23.9110\n",
      "epoch 32\n",
      "..................................................\n",
      "training epoch took 22.5645\n",
      "epoch 33\n",
      "..................................................\n",
      "training epoch took 24.0265\n",
      "epoch 34\n",
      "..................................................\n",
      "training epoch took 23.7244\n",
      "epoch 35\n",
      "..................................................\n",
      "training epoch took 24.0192\n",
      "epoch 36\n",
      "..................................................\n",
      "training epoch took 24.0112\n",
      "epoch 37\n",
      "..................................................\n",
      "training epoch took 24.0932\n",
      "epoch 38\n",
      "..................................................\n",
      "training epoch took 24.0132\n",
      "epoch 39\n",
      "..................................................\n",
      "training epoch took 24.1042\n",
      "epoch 40\n",
      "..................................................\n",
      "training epoch took 23.8502\n",
      "epoch 41\n",
      "..................................................\n",
      "training epoch took 23.8461\n",
      "epoch 42\n",
      "..................................................\n",
      "training epoch took 23.9125\n",
      "epoch 43\n",
      "..................................................\n",
      "training epoch took 22.6772\n",
      "epoch 44\n",
      "..................................................\n",
      "training epoch took 23.9167\n",
      "epoch 45\n",
      "..................................................\n",
      "training epoch took 23.3390\n",
      "epoch 46\n",
      "..................................................\n",
      "training epoch took 23.2796\n",
      "epoch 47\n",
      "..................................................\n",
      "training epoch took 24.0512\n",
      "epoch 48\n",
      "..................................................\n",
      "training epoch took 23.9394\n",
      "epoch 49\n",
      "..................................................\n",
      "training epoch took 23.9916\n",
      "avg test bits per pixel -0.1855\n",
      "Successfully saved model\n",
      "epoch 50\n",
      "..................................................\n",
      "training epoch took 24.0561\n",
      "epoch 51\n",
      "..................................................\n",
      "training epoch took 23.8943\n",
      "epoch 52\n",
      "..................................................\n",
      "training epoch took 23.9279\n",
      "epoch 53\n",
      "..................................................\n",
      "training epoch took 23.7703\n",
      "epoch 54\n",
      "..................................................\n",
      "training epoch took 23.9557\n",
      "epoch 55\n",
      "..................................................\n",
      "training epoch took 23.9623\n",
      "epoch 56\n",
      "..................................................\n",
      "training epoch took 24.0027\n",
      "epoch 57\n",
      "..................................................\n",
      "training epoch took 24.0538\n",
      "epoch 58\n",
      "..................................................\n",
      "training epoch took 24.0086\n",
      "epoch 59\n",
      "..................................................\n",
      "training epoch took 24.0336\n",
      "epoch 60\n",
      "..................................................\n",
      "training epoch took 24.0322\n",
      "epoch 61\n",
      "..................................................\n",
      "training epoch took 23.9675\n",
      "epoch 62\n",
      "..................................................\n",
      "training epoch took 24.0141\n",
      "epoch 63\n",
      "..................................................\n",
      "training epoch took 24.0822\n",
      "epoch 64\n",
      "..................................................\n",
      "training epoch took 24.0613\n",
      "epoch 65\n",
      "..................................................\n",
      "training epoch took 24.0349\n",
      "epoch 66\n",
      "..................................................\n",
      "training epoch took 24.0948\n",
      "epoch 67\n",
      "..................................................\n",
      "training epoch took 24.0292\n",
      "epoch 68\n",
      "..................................................\n",
      "training epoch took 24.1309\n",
      "epoch 69\n",
      "..................................................\n",
      "training epoch took 24.0148\n",
      "epoch 70\n",
      "..................................................\n",
      "training epoch took 23.6964\n",
      "epoch 71\n",
      "..................................................\n",
      "training epoch took 24.0849\n",
      "epoch 72\n",
      "..................................................\n",
      "training epoch took 24.0567\n",
      "epoch 73\n",
      "..................................................\n",
      "training epoch took 22.9297\n",
      "epoch 74\n",
      "..................................................\n",
      "training epoch took 24.0386\n",
      "avg test bits per pixel -0.5582\n",
      "Successfully saved model\n",
      "epoch 75\n",
      "..................................................\n",
      "training epoch took 24.0200\n",
      "epoch 76\n",
      "..................................................\n",
      "training epoch took 24.1460\n",
      "epoch 77\n",
      "..................................................\n",
      "training epoch took 24.0250\n",
      "epoch 78\n",
      "..................................................\n",
      "training epoch took 23.9317\n",
      "epoch 79\n",
      "..................................................\n",
      "training epoch took 24.1567\n",
      "epoch 80\n",
      "..................................................\n",
      "training epoch took 23.9999\n",
      "epoch 81\n",
      "..................................................\n",
      "training epoch took 24.0377\n",
      "epoch 82\n",
      "..................................................\n",
      "training epoch took 24.0720\n",
      "epoch 83\n",
      "..................................................\n",
      "training epoch took 24.0735\n",
      "epoch 84\n",
      "..................................................\n",
      "training epoch took 24.1490\n",
      "epoch 85\n",
      "..................................................\n",
      "training epoch took 23.2802\n",
      "epoch 86\n",
      "..................................................\n",
      "training epoch took 24.1826\n",
      "epoch 87\n",
      "..................................................\n",
      "training epoch took 24.1009\n",
      "epoch 88\n",
      "..................................................\n",
      "training epoch took 24.0295\n",
      "epoch 89\n",
      "..................................................\n",
      "training epoch took 23.9854\n",
      "epoch 90\n",
      "..................................................\n",
      "training epoch took 24.1496\n",
      "epoch 91\n",
      "..................................................\n",
      "training epoch took 24.1571\n",
      "epoch 92\n",
      "..................................................\n",
      "training epoch took 22.7702\n",
      "epoch 93\n",
      "..................................................\n",
      "training epoch took 24.0695\n",
      "epoch 94\n",
      "..................................................\n",
      "training epoch took 24.0652\n",
      "epoch 95\n",
      "..................................................\n",
      "training epoch took 24.1383\n",
      "epoch 96\n",
      "..................................................\n",
      "training epoch took 23.9331\n",
      "epoch 97\n",
      "..................................................\n",
      "training epoch took 23.7266\n",
      "epoch 98\n",
      "..................................................\n",
      "training epoch took 24.0963\n",
      "epoch 99\n",
      "..................................................\n",
      "training epoch took 24.0563\n",
      "avg test bits per pixel -0.6799\n",
      "Successfully saved model\n",
      "epoch 100\n",
      "..................................................\n",
      "training epoch took 24.1303\n",
      "epoch 101\n",
      "..................................................\n",
      "training epoch took 22.8299\n",
      "epoch 102\n",
      "..................................................\n",
      "training epoch took 24.0847\n",
      "epoch 103\n",
      "..................................................\n",
      "training epoch took 24.0757\n",
      "epoch 104\n",
      "..................................................\n",
      "training epoch took 24.0987\n",
      "epoch 105\n",
      "..................................................\n",
      "training epoch took 24.0569\n",
      "epoch 106\n",
      "..................................................\n",
      "training epoch took 24.0046\n",
      "epoch 107\n",
      "..................................................\n",
      "training epoch took 24.0230\n",
      "epoch 108\n",
      "..................................................\n",
      "training epoch took 24.0947\n",
      "epoch 109\n",
      "..................................................\n",
      "training epoch took 24.1151\n",
      "epoch 110\n",
      "..................................................\n",
      "training epoch took 23.7420\n",
      "epoch 111\n",
      "..................................................\n",
      "training epoch took 24.0541\n",
      "epoch 112\n",
      "..................................................\n",
      "training epoch took 24.2047\n",
      "epoch 113\n",
      "..................................................\n",
      "training epoch took 24.1024\n",
      "epoch 114\n",
      "..................................................\n",
      "training epoch took 22.9124\n",
      "epoch 115\n",
      "..................................................\n",
      "training epoch took 22.8190\n",
      "epoch 116\n",
      "..................................................\n",
      "training epoch took 24.3088\n",
      "epoch 117\n",
      "..................................................\n",
      "training epoch took 22.9130\n",
      "epoch 118\n",
      "..................................................\n",
      "training epoch took 24.1689\n",
      "epoch 119\n",
      "..................................................\n",
      "training epoch took 24.1575\n",
      "epoch 120\n",
      "..................................................\n",
      "training epoch took 24.1044\n",
      "epoch 121\n",
      "..................................................\n",
      "training epoch took 24.1223\n",
      "epoch 122\n",
      "..................................................\n",
      "training epoch took 24.0153\n",
      "epoch 123\n",
      "..................................................\n",
      "training epoch took 24.0317\n",
      "epoch 124\n",
      "..................................................\n",
      "training epoch took 24.1314\n",
      "avg test bits per pixel -0.7088\n",
      "Successfully saved model\n",
      "epoch 125\n",
      "..................................................\n",
      "training epoch took 24.1904\n",
      "epoch 126\n",
      "..................................................\n",
      "training epoch took 24.2130\n",
      "epoch 127\n",
      "..................................................\n",
      "training epoch took 24.1028\n",
      "epoch 128\n",
      "..................................................\n",
      "training epoch took 24.1768\n",
      "epoch 129\n",
      "..................................................\n",
      "training epoch took 24.0854\n",
      "epoch 130\n",
      "..................................................\n",
      "training epoch took 24.1673\n",
      "epoch 131\n",
      "..................................................\n",
      "training epoch took 24.1862\n",
      "epoch 132\n",
      "..................................................\n",
      "training epoch took 24.0372\n",
      "epoch 133\n",
      "..................................................\n",
      "training epoch took 24.0639\n",
      "epoch 134\n",
      "..................................................\n",
      "training epoch took 24.1709\n",
      "epoch 135\n",
      "..................................................\n",
      "training epoch took 24.1935\n",
      "epoch 136\n",
      "..................................................\n",
      "training epoch took 24.1048\n",
      "epoch 137\n",
      "..................................................\n",
      "training epoch took 24.1781\n",
      "epoch 138\n",
      "..................................................\n",
      "training epoch took 24.1059\n",
      "epoch 139\n",
      "..................................................\n",
      "training epoch took 24.1613\n",
      "epoch 140\n",
      "..................................................\n",
      "training epoch took 22.8361\n",
      "epoch 141\n",
      "..................................................\n",
      "training epoch took 24.1645\n",
      "epoch 142\n",
      "..................................................\n",
      "training epoch took 24.2888\n",
      "epoch 143\n",
      "..................................................\n",
      "training epoch took 24.1972\n",
      "epoch 144\n",
      "..................................................\n",
      "training epoch took 24.2104\n",
      "epoch 145\n",
      "..................................................\n",
      "training epoch took 24.1692\n",
      "epoch 146\n",
      "..................................................\n",
      "training epoch took 24.2595\n",
      "epoch 147\n",
      "..................................................\n",
      "training epoch took 24.1652\n",
      "epoch 148\n",
      "..................................................\n",
      "training epoch took 24.0811\n",
      "epoch 149\n",
      "..................................................\n",
      "training epoch took 23.9638\n",
      "avg test bits per pixel -0.5702\n",
      "Successfully saved model\n",
      "epoch 150\n",
      "..................................................\n",
      "training epoch took 24.0468\n",
      "epoch 151\n",
      "..................................................\n",
      "training epoch took 24.1760\n",
      "epoch 152\n",
      "..................................................\n",
      "training epoch took 24.2692\n",
      "epoch 153\n",
      "..................................................\n",
      "training epoch took 24.1025\n",
      "epoch 154\n",
      "..................................................\n",
      "training epoch took 24.1045\n",
      "epoch 155\n",
      "..................................................\n",
      "training epoch took 24.0738\n",
      "epoch 156\n",
      "..................................................\n",
      "training epoch took 24.2351\n",
      "epoch 157\n",
      "..................................................\n",
      "training epoch took 24.1727\n",
      "epoch 158\n",
      "..................................................\n",
      "training epoch took 24.0517\n",
      "epoch 159\n",
      "..................................................\n",
      "training epoch took 24.1294\n",
      "epoch 160\n",
      "..................................................\n",
      "training epoch took 24.2284\n",
      "epoch 161\n",
      "..................................................\n",
      "training epoch took 24.0962\n",
      "epoch 162\n",
      "..................................................\n",
      "training epoch took 24.0862\n",
      "epoch 163\n",
      "..................................................\n",
      "training epoch took 24.0266\n",
      "epoch 164\n",
      "..................................................\n",
      "training epoch took 22.9322\n",
      "epoch 165\n",
      "..................................................\n",
      "training epoch took 23.1391\n",
      "epoch 166\n",
      "..................................................\n",
      "training epoch took 24.1654\n",
      "epoch 167\n",
      "..................................................\n",
      "training epoch took 23.1649\n",
      "epoch 168\n",
      "..................................................\n",
      "training epoch took 23.6220\n",
      "epoch 169\n",
      "..................................................\n",
      "training epoch took 24.0953\n",
      "epoch 170\n",
      "..................................................\n",
      "training epoch took 24.1838\n",
      "epoch 171\n",
      "..................................................\n",
      "training epoch took 24.1301\n",
      "epoch 172\n",
      "..................................................\n",
      "training epoch took 24.2622\n",
      "epoch 173\n",
      "..................................................\n",
      "training epoch took 24.0734\n",
      "epoch 174\n",
      "..................................................\n",
      "training epoch took 23.7857\n",
      "avg test bits per pixel -0.6681\n",
      "Successfully saved model\n",
      "epoch 175\n",
      "..................................................\n",
      "training epoch took 24.1627\n",
      "epoch 176\n",
      "..................................................\n",
      "training epoch took 24.1752\n",
      "epoch 177\n",
      "..................................................\n",
      "training epoch took 24.1329\n",
      "epoch 178\n",
      "..................................................\n",
      "training epoch took 24.1960\n",
      "epoch 179\n",
      "..................................................\n",
      "training epoch took 24.2657\n",
      "epoch 180\n",
      "..................................................\n",
      "training epoch took 24.1665\n",
      "epoch 181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "training epoch took 24.1063\n",
      "epoch 182\n",
      "..................................................\n",
      "training epoch took 24.1228\n",
      "epoch 183\n",
      "..................................................\n",
      "training epoch took 24.2095\n",
      "epoch 184\n",
      "..................................................\n",
      "training epoch took 24.0773\n",
      "epoch 185\n",
      "..................................................\n",
      "training epoch took 24.1440\n",
      "epoch 186\n",
      "..................................................\n",
      "training epoch took 23.7716\n",
      "epoch 187\n",
      "..................................................\n",
      "training epoch took 24.1767\n",
      "epoch 188\n",
      "..................................................\n",
      "training epoch took 22.9028\n",
      "epoch 189\n",
      "..................................................\n",
      "training epoch took 23.1986\n",
      "epoch 190\n",
      "..................................................\n",
      "training epoch took 23.9354\n",
      "epoch 191\n",
      "..................................................\n",
      "training epoch took 24.2519\n",
      "epoch 192\n",
      "..................................................\n",
      "training epoch took 24.3452\n",
      "epoch 193\n",
      "..................................................\n",
      "training epoch took 24.0943\n",
      "epoch 194\n",
      "..................................................\n",
      "training epoch took 24.1130\n",
      "epoch 195\n",
      "..................................................\n",
      "training epoch took 24.2674\n",
      "epoch 196\n",
      "..................................................\n",
      "training epoch took 24.1377\n",
      "epoch 197\n",
      "..................................................\n",
      "training epoch took 24.2593\n",
      "epoch 198\n",
      "..................................................\n",
      "training epoch took 23.3270\n",
      "epoch 199\n",
      "..................................................\n",
      "training epoch took 23.6361\n",
      "avg test bits per pixel -0.7672\n",
      "Successfully saved model\n",
      "epoch 200\n",
      "..................................................\n",
      "training epoch took 24.0954\n",
      "epoch 201\n",
      "..................................................\n",
      "training epoch took 24.2271\n",
      "epoch 202\n",
      "..................................................\n",
      "training epoch took 23.6291\n",
      "epoch 203\n",
      "..................................................\n",
      "training epoch took 24.2703\n",
      "epoch 204\n",
      "..................................................\n",
      "training epoch took 24.2936\n",
      "epoch 205\n",
      "..................................................\n",
      "training epoch took 23.6865\n",
      "epoch 206\n",
      "..................................................\n",
      "training epoch took 24.1732\n",
      "epoch 207\n",
      "..................................................\n",
      "training epoch took 24.2850\n",
      "epoch 208\n",
      "..................................................\n",
      "training epoch took 24.0818\n",
      "epoch 209\n",
      "..................................................\n",
      "training epoch took 23.0084\n",
      "epoch 210\n",
      "..................................................\n",
      "training epoch took 22.9699\n",
      "epoch 211\n",
      "..................................................\n",
      "training epoch took 23.0780\n",
      "epoch 212\n",
      "..................................................\n",
      "training epoch took 24.1796\n",
      "epoch 213\n",
      "..................................................\n",
      "training epoch took 24.2095\n",
      "epoch 214\n",
      "..................................................\n",
      "training epoch took 24.2101\n",
      "epoch 215\n",
      "..................................................\n",
      "training epoch took 23.1394\n",
      "epoch 216\n",
      "..................................................\n",
      "training epoch took 24.2975\n",
      "epoch 217\n",
      "..................................................\n",
      "training epoch took 24.2427\n",
      "epoch 218\n",
      "..................................................\n",
      "training epoch took 22.9075\n",
      "epoch 219\n",
      "..................................................\n",
      "training epoch took 24.1556\n",
      "epoch 220\n",
      "..................................................\n",
      "training epoch took 24.2062\n",
      "epoch 221\n",
      "..................................................\n",
      "training epoch took 24.2933\n",
      "epoch 222\n",
      "..................................................\n",
      "training epoch took 24.3649\n",
      "epoch 223\n",
      "..................................................\n",
      "training epoch took 24.2323\n",
      "epoch 224\n",
      "..................................................\n",
      "training epoch took 24.1151\n",
      "avg test bits per pixel -1.0726\n",
      "Successfully saved model\n",
      "epoch 225\n",
      "..................................................\n",
      "training epoch took 24.2712\n",
      "epoch 226\n",
      "..................................................\n",
      "training epoch took 23.6114\n",
      "epoch 227\n",
      "..................................................\n",
      "training epoch took 24.2963\n",
      "epoch 228\n",
      "..................................................\n",
      "training epoch took 24.1847\n",
      "epoch 229\n",
      "..................................................\n",
      "training epoch took 24.0682\n",
      "epoch 230\n",
      "..................................................\n",
      "training epoch took 24.1581\n",
      "epoch 231\n",
      "..................................................\n",
      "training epoch took 24.2932\n",
      "epoch 232\n",
      "..................................................\n",
      "training epoch took 23.8238\n",
      "epoch 233\n",
      "..................................................\n",
      "training epoch took 23.2173\n",
      "epoch 234\n",
      "..................................................\n",
      "training epoch took 24.2294\n",
      "epoch 235\n",
      "..................................................\n",
      "training epoch took 24.2956\n",
      "epoch 236\n",
      "..................................................\n",
      "training epoch took 24.2938\n",
      "epoch 237\n",
      "..................................................\n",
      "training epoch took 23.5450\n",
      "epoch 238\n",
      "..................................................\n",
      "training epoch took 24.2291\n",
      "epoch 239\n",
      "..................................................\n",
      "training epoch took 24.1511\n",
      "epoch 240\n",
      "..................................................\n",
      "training epoch took 23.1083\n",
      "epoch 241\n",
      "..................................................\n",
      "training epoch took 24.3606\n",
      "epoch 242\n",
      "..................................................\n",
      "training epoch took 24.2393\n",
      "epoch 243\n",
      "..................................................\n",
      "training epoch took 24.1908\n",
      "epoch 244\n",
      "..................................................\n",
      "training epoch took 24.1212\n",
      "epoch 245\n",
      "..................................................\n",
      "training epoch took 24.1754\n",
      "epoch 246\n",
      "..................................................\n",
      "training epoch took 23.5909\n",
      "epoch 247\n",
      "..................................................\n",
      "training epoch took 24.3653\n",
      "epoch 248\n",
      "..................................................\n",
      "training epoch took 24.1349\n",
      "epoch 249\n",
      "..................................................\n",
      "training epoch took 24.2637\n",
      "avg test bits per pixel -1.1636\n",
      "Successfully saved model\n",
      "epoch 250\n",
      "..................................................\n",
      "training epoch took 24.3302\n",
      "epoch 251\n",
      "..................................................\n",
      "training epoch took 22.9593\n",
      "epoch 252\n",
      "..................................................\n",
      "training epoch took 24.0045\n",
      "epoch 253\n",
      "..................................................\n",
      "training epoch took 24.1991\n",
      "epoch 254\n",
      "..................................................\n",
      "training epoch took 24.1586\n",
      "epoch 255\n",
      "..................................................\n",
      "training epoch took 24.2492\n",
      "epoch 256\n",
      "..................................................\n",
      "training epoch took 24.3701\n",
      "epoch 257\n",
      "..................................................\n",
      "training epoch took 24.3115\n",
      "epoch 258\n",
      "..................................................\n",
      "training epoch took 24.0856\n",
      "epoch 259\n",
      "..................................................\n",
      "training epoch took 24.2413\n",
      "epoch 260\n",
      "..................................................\n",
      "training epoch took 24.2619\n",
      "epoch 261\n",
      "..................................................\n",
      "training epoch took 23.5417\n",
      "epoch 262\n",
      "..................................................\n",
      "training epoch took 24.2809\n",
      "epoch 263\n",
      "..................................................\n",
      "training epoch took 24.2779\n",
      "epoch 264\n",
      "..................................................\n",
      "training epoch took 22.9959\n",
      "epoch 265\n",
      "..................................................\n",
      "training epoch took 23.9650\n",
      "epoch 266\n",
      "..................................................\n",
      "training epoch took 24.2651\n",
      "epoch 267\n",
      "..................................................\n",
      "training epoch took 24.3665\n",
      "epoch 268\n",
      "..................................................\n",
      "training epoch took 24.3714\n",
      "epoch 269\n",
      "..................................................\n",
      "training epoch took 23.8256\n",
      "epoch 270\n",
      "..................................................\n",
      "training epoch took 24.3651\n",
      "epoch 271\n",
      "..................................................\n",
      "training epoch took 24.2284\n",
      "epoch 272\n",
      "..................................................\n",
      "training epoch took 24.2645\n",
      "epoch 273\n",
      "..................................................\n",
      "training epoch took 24.2968\n",
      "epoch 274\n",
      "..................................................\n",
      "training epoch took 24.2918\n",
      "avg test bits per pixel -0.8831\n",
      "Successfully saved model\n",
      "epoch 275\n",
      "..................................................\n",
      "training epoch took 24.2258\n",
      "epoch 276\n",
      "..................................................\n",
      "training epoch took 24.2309\n",
      "epoch 277\n",
      "..................................................\n",
      "training epoch took 24.2365\n",
      "epoch 278\n",
      "..................................................\n",
      "training epoch took 24.1450\n",
      "epoch 279\n",
      "..................................................\n",
      "training epoch took 24.2987\n",
      "epoch 280\n",
      "..................................................\n",
      "training epoch took 24.3273\n",
      "epoch 281\n",
      "..................................................\n",
      "training epoch took 24.2235\n",
      "epoch 282\n",
      "..................................................\n",
      "training epoch took 24.3452\n",
      "epoch 283\n",
      "..................................................\n",
      "training epoch took 24.2634\n",
      "epoch 284\n",
      "..................................................\n",
      "training epoch took 24.2020\n",
      "epoch 285\n",
      "..................................................\n",
      "training epoch took 22.9497\n",
      "epoch 286\n",
      "..................................................\n",
      "training epoch took 23.0732\n",
      "epoch 287\n",
      "..................................................\n",
      "training epoch took 24.0931\n",
      "epoch 288\n",
      "..................................................\n",
      "training epoch took 24.3198\n",
      "epoch 289\n",
      "..................................................\n",
      "training epoch took 24.3495\n",
      "epoch 290\n",
      "..................................................\n",
      "training epoch took 24.3290\n",
      "epoch 291\n",
      "..................................................\n",
      "training epoch took 24.1181\n",
      "epoch 292\n",
      "..................................................\n",
      "training epoch took 24.2506\n",
      "epoch 293\n",
      "..................................................\n",
      "training epoch took 24.2757\n",
      "epoch 294\n",
      "..................................................\n",
      "training epoch took 24.3357\n",
      "epoch 295\n",
      "..................................................\n",
      "training epoch took 24.2163\n",
      "epoch 296\n",
      "..................................................\n",
      "training epoch took 23.2994\n",
      "epoch 297\n",
      "..................................................\n",
      "training epoch took 24.1329\n",
      "epoch 298\n",
      "..................................................\n",
      "training epoch took 24.1428\n",
      "epoch 299\n",
      "..................................................\n",
      "training epoch took 24.2387\n",
      "avg test bits per pixel -1.1920\n",
      "Successfully saved model\n",
      "epoch 300\n",
      "..................................................\n",
      "training epoch took 24.3392\n",
      "epoch 301\n",
      "..................................................\n",
      "training epoch took 23.2191\n",
      "epoch 302\n",
      "..................................................\n",
      "training epoch took 24.1070\n",
      "epoch 303\n",
      "..................................................\n",
      "training epoch took 23.5054\n",
      "epoch 304\n",
      "..................................................\n",
      "training epoch took 24.2493\n",
      "epoch 305\n",
      "..................................................\n",
      "training epoch took 24.3185\n",
      "epoch 306\n",
      "..................................................\n",
      "training epoch took 24.3008\n",
      "epoch 307\n",
      "..................................................\n",
      "training epoch took 22.9847\n",
      "epoch 308\n",
      "..................................................\n",
      "training epoch took 23.0149\n",
      "epoch 309\n",
      "..................................................\n",
      "training epoch took 23.2201\n",
      "epoch 310\n",
      "..................................................\n",
      "training epoch took 24.2909\n",
      "epoch 311\n",
      "..................................................\n",
      "training epoch took 23.8768\n",
      "epoch 312\n",
      "..................................................\n",
      "training epoch took 24.3685\n",
      "epoch 313\n",
      "..................................................\n",
      "training epoch took 24.3185\n",
      "epoch 314\n",
      "..................................................\n",
      "training epoch took 24.3027\n",
      "epoch 315\n",
      "..................................................\n",
      "training epoch took 24.2473\n",
      "epoch 316\n",
      "..................................................\n",
      "training epoch took 24.1489\n",
      "epoch 317\n",
      "..................................................\n",
      "training epoch took 22.9396\n",
      "epoch 318\n",
      "..................................................\n",
      "training epoch took 24.3854\n",
      "epoch 319\n",
      "..................................................\n",
      "training epoch took 24.4397\n",
      "epoch 320\n",
      "..................................................\n",
      "training epoch took 24.3130\n",
      "epoch 321\n",
      "..................................................\n",
      "training epoch took 24.4172\n",
      "epoch 322\n",
      "..................................................\n",
      "training epoch took 23.6562\n",
      "epoch 323\n",
      "..................................................\n",
      "training epoch took 24.3678\n",
      "epoch 324\n",
      "..................................................\n",
      "training epoch took 24.2888\n",
      "avg test bits per pixel -0.9160\n",
      "Successfully saved model\n",
      "epoch 325\n",
      "..................................................\n",
      "training epoch took 24.4485\n",
      "epoch 326\n",
      "..................................................\n",
      "training epoch took 24.3762\n",
      "epoch 327\n",
      "..................................................\n",
      "training epoch took 24.3668\n",
      "epoch 328\n",
      "..................................................\n",
      "training epoch took 24.3522\n",
      "epoch 329\n",
      "..................................................\n",
      "training epoch took 24.2911\n",
      "epoch 330\n",
      "..................................................\n",
      "training epoch took 22.9391\n",
      "epoch 331\n",
      "..................................................\n",
      "training epoch took 24.2926\n",
      "epoch 332\n",
      "..................................................\n",
      "training epoch took 24.1766\n",
      "epoch 333\n",
      "..................................................\n",
      "training epoch took 24.3718\n",
      "epoch 334\n",
      "..................................................\n",
      "training epoch took 24.4859\n",
      "epoch 335\n",
      "..................................................\n",
      "training epoch took 24.3703\n",
      "epoch 336\n",
      "..................................................\n",
      "training epoch took 24.2628\n",
      "epoch 337\n",
      "..................................................\n",
      "training epoch took 24.4260\n",
      "epoch 338\n",
      "..................................................\n",
      "training epoch took 24.3528\n",
      "epoch 339\n",
      "..................................................\n",
      "training epoch took 24.2420\n",
      "epoch 340\n",
      "..................................................\n",
      "training epoch took 24.4205\n",
      "epoch 341\n",
      "..................................................\n",
      "training epoch took 24.2218\n",
      "epoch 342\n",
      "..................................................\n",
      "training epoch took 23.9882\n",
      "epoch 343\n",
      "..................................................\n",
      "training epoch took 24.3359\n",
      "epoch 344\n",
      "..................................................\n",
      "training epoch took 24.2905\n",
      "epoch 345\n",
      "..................................................\n",
      "training epoch took 24.4118\n",
      "epoch 346\n",
      "..................................................\n",
      "training epoch took 24.3535\n",
      "epoch 347\n",
      "..................................................\n",
      "training epoch took 24.3914\n",
      "epoch 348\n",
      "..................................................\n",
      "training epoch took 23.5704\n",
      "epoch 349\n",
      "..................................................\n",
      "training epoch took 23.2365\n",
      "avg test bits per pixel -1.0251\n",
      "Successfully saved model\n",
      "epoch 350\n",
      "..................................................\n",
      "training epoch took 24.1931\n",
      "epoch 351\n",
      "..................................................\n",
      "training epoch took 24.3277\n",
      "epoch 352\n",
      "..................................................\n",
      "training epoch took 24.2447\n",
      "epoch 353\n",
      "..................................................\n",
      "training epoch took 24.1927\n",
      "epoch 354\n",
      "..................................................\n",
      "training epoch took 24.4486\n",
      "epoch 355\n",
      "..................................................\n",
      "training epoch took 24.4335\n",
      "epoch 356\n",
      "..................................................\n",
      "training epoch took 24.2959\n",
      "epoch 357\n",
      "..................................................\n",
      "training epoch took 24.3084\n",
      "epoch 358\n",
      "..................................................\n",
      "training epoch took 24.3521\n",
      "epoch 359\n",
      "..................................................\n",
      "training epoch took 24.4166\n",
      "epoch 360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "training epoch took 24.3187\n",
      "epoch 361\n",
      "..................................................\n",
      "training epoch took 24.3237\n",
      "epoch 362\n",
      "..................................................\n",
      "training epoch took 24.4297\n",
      "epoch 363\n",
      "..................................................\n",
      "training epoch took 24.3556\n",
      "epoch 364\n",
      "..................................................\n",
      "training epoch took 24.3670\n",
      "epoch 365\n",
      "..................................................\n",
      "training epoch took 23.5211\n",
      "epoch 366\n",
      "..................................................\n",
      "training epoch took 24.3819\n",
      "epoch 367\n",
      "..................................................\n",
      "training epoch took 24.3569\n",
      "epoch 368\n",
      "..................................................\n",
      "training epoch took 24.2853\n",
      "epoch 369\n",
      "..................................................\n",
      "training epoch took 24.4117\n",
      "epoch 370\n",
      "..................................................\n",
      "training epoch took 24.3028\n",
      "epoch 371\n",
      "..................................................\n",
      "training epoch took 24.3690\n",
      "epoch 372\n",
      "..................................................\n",
      "training epoch took 24.4079\n",
      "epoch 373\n",
      "..................................................\n",
      "training epoch took 24.2462\n",
      "epoch 374\n",
      "..................................................\n",
      "training epoch took 24.3819\n",
      "avg test bits per pixel -1.1070\n",
      "Successfully saved model\n",
      "epoch 375\n",
      "..................................................\n",
      "training epoch took 24.4461\n",
      "epoch 376\n",
      "..................................................\n",
      "training epoch took 24.4565\n",
      "epoch 377\n",
      "..................................................\n",
      "training epoch took 24.5585\n",
      "epoch 378\n",
      "..................................................\n",
      "training epoch took 24.4897\n",
      "epoch 379\n",
      "..................................................\n",
      "training epoch took 24.5678\n",
      "epoch 380\n",
      "..................................................\n",
      "training epoch took 24.4540\n",
      "epoch 381\n",
      "..................................................\n",
      "training epoch took 22.9645\n",
      "epoch 382\n",
      "..................................................\n",
      "training epoch took 24.3219\n",
      "epoch 383\n",
      "..................................................\n",
      "training epoch took 24.3423\n",
      "epoch 384\n",
      "..................................................\n",
      "training epoch took 24.2396\n",
      "epoch 385\n",
      "..................................................\n",
      "training epoch took 24.3210\n",
      "epoch 386\n",
      "..................................................\n",
      "training epoch took 24.3585\n",
      "epoch 387\n",
      "..................................................\n",
      "training epoch took 24.3593\n",
      "epoch 388\n",
      "..................................................\n",
      "training epoch took 24.3714\n",
      "epoch 389\n",
      "..................................................\n",
      "training epoch took 24.4249\n",
      "epoch 390\n",
      "..................................................\n",
      "training epoch took 24.4964\n",
      "epoch 391\n",
      "..................................................\n",
      "training epoch took 24.5056\n",
      "epoch 392\n",
      "..................................................\n",
      "training epoch took 24.4058\n",
      "epoch 393\n",
      "..................................................\n",
      "training epoch took 24.2097\n",
      "epoch 394\n",
      "..................................................\n",
      "training epoch took 24.4962\n",
      "epoch 395\n",
      "..................................................\n",
      "training epoch took 24.4236\n",
      "epoch 396\n",
      "..................................................\n",
      "training epoch took 24.4083\n",
      "epoch 397\n",
      "..................................................\n",
      "training epoch took 24.4428\n",
      "epoch 398\n",
      "..................................................\n",
      "training epoch took 24.0768\n",
      "epoch 399\n",
      "..................................................\n",
      "training epoch took 24.4695\n",
      "avg test bits per pixel -0.9774\n",
      "Successfully saved model\n",
      "epoch 400\n",
      "..................................................\n",
      "training epoch took 24.5045\n",
      "epoch 401\n",
      "..................................................\n",
      "training epoch took 24.4522\n",
      "epoch 402\n",
      "..................................................\n",
      "training epoch took 24.4334\n",
      "epoch 403\n",
      "..................................................\n",
      "training epoch took 24.1600\n",
      "epoch 404\n",
      "..................................................\n",
      "training epoch took 24.4456\n",
      "epoch 405\n",
      "..................................................\n",
      "training epoch took 23.7727\n",
      "epoch 406\n",
      "..................................................\n",
      "training epoch took 24.3924\n",
      "epoch 407\n",
      "..................................................\n",
      "training epoch took 24.3458\n",
      "epoch 408\n",
      "..................................................\n",
      "training epoch took 24.1792\n",
      "epoch 409\n",
      "..................................................\n",
      "training epoch took 24.3556\n",
      "epoch 410\n",
      "..................................................\n",
      "training epoch took 24.3435\n",
      "epoch 411\n",
      "..................................................\n",
      "training epoch took 24.3740\n",
      "epoch 412\n",
      "..................................................\n",
      "training epoch took 23.2645\n",
      "epoch 413\n",
      "..................................................\n",
      "training epoch took 24.4754\n",
      "epoch 414\n",
      "..................................................\n",
      "training epoch took 23.8714\n",
      "epoch 415\n",
      "..................................................\n",
      "training epoch took 24.4521\n",
      "epoch 416\n",
      "..................................................\n",
      "training epoch took 24.5235\n",
      "epoch 417\n",
      "..................................................\n",
      "training epoch took 24.2867\n",
      "epoch 418\n",
      "..................................................\n",
      "training epoch took 24.2842\n",
      "epoch 419\n",
      "..................................................\n",
      "training epoch took 24.4635\n",
      "epoch 420\n",
      "..................................................\n",
      "training epoch took 24.4566\n",
      "epoch 421\n",
      "..................................................\n",
      "training epoch took 24.4957\n",
      "epoch 422\n",
      "..................................................\n",
      "training epoch took 24.4648\n",
      "epoch 423\n",
      "..................................................\n",
      "training epoch took 24.2993\n",
      "epoch 424\n",
      "..................................................\n",
      "training epoch took 24.2842\n",
      "avg test bits per pixel -0.7668\n",
      "Successfully saved model\n",
      "epoch 425\n",
      "..................................................\n",
      "training epoch took 23.0245\n",
      "epoch 426\n",
      "..................................................\n",
      "training epoch took 24.4179\n",
      "epoch 427\n",
      "..................................................\n",
      "training epoch took 24.2830\n",
      "epoch 428\n",
      "..................................................\n",
      "training epoch took 24.1920\n",
      "epoch 429\n",
      "..................................................\n",
      "training epoch took 24.3791\n",
      "epoch 430\n",
      "..................................................\n",
      "training epoch took 24.2981\n",
      "epoch 431\n",
      "..................................................\n",
      "training epoch took 24.4935\n",
      "epoch 432\n",
      "..................................................\n",
      "training epoch took 23.4179\n",
      "epoch 433\n",
      "..................................................\n",
      "training epoch took 23.4128\n",
      "epoch 434\n",
      "..................................................\n",
      "training epoch took 24.4571\n",
      "epoch 435\n",
      "..................................................\n",
      "training epoch took 24.3498\n",
      "epoch 436\n",
      "..................................................\n",
      "training epoch took 24.3294\n",
      "epoch 437\n",
      "..................................................\n",
      "training epoch took 24.4553\n",
      "epoch 438\n",
      "..................................................\n",
      "training epoch took 24.4464\n",
      "epoch 439\n",
      "..................................................\n",
      "training epoch took 24.3420\n",
      "epoch 440\n",
      "..................................................\n",
      "training epoch took 24.4623\n",
      "epoch 441\n",
      "..................................................\n",
      "training epoch took 24.4413\n",
      "epoch 442\n",
      "..................................................\n",
      "training epoch took 24.4548\n",
      "epoch 443\n",
      "..................................................\n",
      "training epoch took 24.2977\n",
      "epoch 444\n",
      "..................................................\n",
      "training epoch took 24.3507\n",
      "epoch 445\n",
      "..................................................\n",
      "training epoch took 23.4717\n",
      "epoch 446\n",
      "..................................................\n",
      "training epoch took 24.4698\n",
      "epoch 447\n",
      "..................................................\n",
      "training epoch took 24.3236\n",
      "epoch 448\n",
      "..................................................\n",
      "training epoch took 24.5257\n",
      "epoch 449\n",
      "..................................................\n",
      "training epoch took 24.4231\n",
      "avg test bits per pixel -1.3393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model\n",
      "epoch 450\n",
      "..................................................\n",
      "training epoch took 24.4918\n",
      "epoch 451\n",
      "..................................................\n",
      "training epoch took 24.3377\n",
      "epoch 452\n",
      "..................................................\n",
      "training epoch took 23.2048\n",
      "epoch 453\n",
      "..................................................\n",
      "training epoch took 24.3015\n",
      "epoch 454\n",
      "..................................................\n",
      "training epoch took 24.5050\n",
      "epoch 455\n",
      "..................................................\n",
      "training epoch took 24.2992\n",
      "epoch 456\n",
      "..................................................\n",
      "training epoch took 24.3980\n",
      "epoch 457\n",
      "..................................................\n",
      "training epoch took 24.3456\n",
      "epoch 458\n",
      "..................................................\n",
      "training epoch took 24.2220\n",
      "epoch 459\n",
      "..................................................\n",
      "training epoch took 24.4176\n",
      "epoch 460\n",
      "..................................................\n",
      "training epoch took 24.4205\n",
      "epoch 461\n",
      "..................................................\n",
      "training epoch took 24.3959\n",
      "epoch 462\n",
      "..................................................\n",
      "training epoch took 24.2113\n",
      "epoch 463\n",
      "..................................................\n",
      "training epoch took 24.4132\n",
      "epoch 464\n",
      "..................................................\n",
      "training epoch took 24.2759\n",
      "epoch 465\n",
      "..................................................\n",
      "training epoch took 24.3417\n",
      "epoch 466\n",
      "..................................................\n",
      "training epoch took 24.4216\n",
      "epoch 467\n",
      "..................................................\n",
      "training epoch took 24.4843\n",
      "epoch 468\n",
      "..................................................\n",
      "training epoch took 24.3035\n",
      "epoch 469\n",
      "..................................................\n",
      "training epoch took 24.5768\n",
      "epoch 470\n",
      "..................................................\n",
      "training epoch took 24.5678\n",
      "epoch 471\n",
      "..................................................\n",
      "training epoch took 24.3532\n",
      "epoch 472\n",
      "..................................................\n",
      "training epoch took 24.3486\n",
      "epoch 473\n",
      "..................................................\n",
      "training epoch took 24.5437\n",
      "epoch 474\n",
      "..................................................\n",
      "training epoch took 24.4800\n",
      "avg test bits per pixel -1.1392\n",
      "Successfully saved model\n",
      "epoch 475\n",
      "..................................................\n",
      "training epoch took 24.4320\n",
      "epoch 476\n",
      "..................................................\n",
      "training epoch took 24.0260\n",
      "epoch 477\n",
      "..................................................\n",
      "training epoch took 24.4297\n",
      "epoch 478\n",
      "..................................................\n",
      "training epoch took 24.2622\n",
      "epoch 479\n",
      "..................................................\n",
      "training epoch took 24.5132\n",
      "epoch 480\n",
      "..................................................\n",
      "training epoch took 24.4362\n",
      "epoch 481\n",
      "..................................................\n",
      "training epoch took 24.2745\n",
      "epoch 482\n",
      "..................................................\n",
      "training epoch took 24.3960\n",
      "epoch 483\n",
      "..................................................\n",
      "training epoch took 24.4085\n",
      "epoch 484\n",
      "..................................................\n",
      "training epoch took 24.2965\n",
      "epoch 485\n",
      "..................................................\n",
      "training epoch took 24.3059\n",
      "epoch 486\n",
      "..................................................\n",
      "training epoch took 24.2867\n",
      "epoch 487\n",
      "..................................................\n",
      "training epoch took 23.0651\n",
      "epoch 488\n",
      "..................................................\n",
      "training epoch took 24.3090\n",
      "epoch 489\n",
      "..................................................\n",
      "training epoch took 23.0316\n",
      "epoch 490\n",
      "..................................................\n",
      "training epoch took 24.2575\n",
      "epoch 491\n",
      "..................................................\n",
      "training epoch took 24.4586\n",
      "epoch 492\n",
      "..................................................\n",
      "training epoch took 23.1538\n",
      "epoch 493\n",
      "..................................................\n",
      "training epoch took 24.3087\n",
      "epoch 494\n",
      "..................................................\n",
      "training epoch took 24.4942\n",
      "epoch 495\n",
      "..................................................\n",
      "training epoch took 24.4320\n",
      "epoch 496\n",
      "..................................................\n",
      "training epoch took 24.2718\n",
      "epoch 497\n",
      "..................................................\n",
      "training epoch took 24.4521\n",
      "epoch 498\n",
      "..................................................\n",
      "training epoch took 24.5435\n",
      "epoch 499\n",
      "..................................................\n",
      "training epoch took 24.4005\n",
      "avg test bits per pixel -1.0610\n",
      "Successfully saved model\n",
      "epoch 500\n",
      "..................................................\n",
      "training epoch took 24.4545\n",
      "epoch 501\n",
      "..................................................\n",
      "training epoch took 24.3740\n",
      "epoch 502\n",
      "..................................................\n",
      "training epoch took 24.2827\n",
      "epoch 503\n",
      "..................................................\n",
      "training epoch took 24.5258\n",
      "epoch 504\n",
      "..................................................\n",
      "training epoch took 24.4641\n",
      "epoch 505\n",
      "..................................................\n",
      "training epoch took 24.3712\n",
      "epoch 506\n",
      "..................................................\n",
      "training epoch took 23.4487\n",
      "epoch 507\n",
      "..................................................\n",
      "training epoch took 24.4798\n",
      "epoch 508\n",
      "..................................................\n",
      "training epoch took 24.4329\n",
      "epoch 509\n",
      "..................................................\n",
      "training epoch took 24.4569\n",
      "epoch 510\n",
      "..................................................\n",
      "training epoch took 24.4311\n",
      "epoch 511\n",
      "..................................................\n",
      "training epoch took 24.4324\n",
      "epoch 512\n",
      "..................................................\n",
      "training epoch took 24.5475\n",
      "epoch 513\n",
      "..................................................\n",
      "training epoch took 24.3739\n",
      "epoch 514\n",
      "..................................................\n",
      "training epoch took 24.3273\n",
      "epoch 515\n",
      "..................................................\n",
      "training epoch took 24.3709\n",
      "epoch 516\n",
      "..................................................\n",
      "training epoch took 24.2955\n",
      "epoch 517\n",
      "..................................................\n",
      "training epoch took 24.3780\n",
      "epoch 518\n",
      "..................................................\n",
      "training epoch took 24.4915\n",
      "epoch 519\n",
      "..................................................\n",
      "training epoch took 24.5223\n",
      "epoch 520\n",
      "..................................................\n",
      "training epoch took 24.1972\n",
      "epoch 521\n",
      "..................................................\n",
      "training epoch took 24.3678\n",
      "epoch 522\n",
      "..................................................\n",
      "training epoch took 24.5476\n",
      "epoch 523\n",
      "..................................................\n",
      "training epoch took 24.5686\n",
      "epoch 524\n",
      "..................................................\n",
      "training epoch took 24.5169\n",
      "avg test bits per pixel -0.6321\n",
      "Successfully saved model\n",
      "epoch 525\n",
      "..................................................\n",
      "training epoch took 24.4993\n",
      "epoch 526\n",
      "..................................................\n",
      "training epoch took 24.5009\n",
      "epoch 527\n",
      "..................................................\n",
      "training epoch took 24.4212\n",
      "epoch 528\n",
      "..................................................\n",
      "training epoch took 24.4352\n",
      "epoch 529\n",
      "..................................................\n",
      "training epoch took 24.5198\n",
      "epoch 530\n",
      "..................................................\n",
      "training epoch took 24.4773\n",
      "epoch 531\n",
      "..................................................\n",
      "training epoch took 24.4508\n",
      "epoch 532\n",
      "..................................................\n",
      "training epoch took 23.0588\n",
      "epoch 533\n",
      "..................................................\n",
      "training epoch took 24.2640\n",
      "epoch 534\n",
      "..................................................\n",
      "training epoch took 24.4993\n",
      "epoch 535\n",
      "..................................................\n",
      "training epoch took 24.3341\n",
      "epoch 536\n",
      "..................................................\n",
      "training epoch took 24.2928\n",
      "epoch 537\n",
      "..................................................\n",
      "training epoch took 24.3635\n",
      "epoch 538\n",
      "..................................................\n",
      "training epoch took 24.4704\n",
      "epoch 539\n",
      "..................................................\n",
      "training epoch took 24.5594\n",
      "epoch 540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "training epoch took 24.4107\n",
      "epoch 541\n",
      "..................................................\n",
      "training epoch took 24.3913\n",
      "epoch 542\n",
      "..................................................\n",
      "training epoch took 24.4417\n",
      "epoch 543\n",
      "..................................................\n",
      "training epoch took 24.5275\n",
      "epoch 544\n",
      "..................................................\n",
      "training epoch took 23.5149\n",
      "epoch 545\n",
      "..................................................\n",
      "training epoch took 24.4539\n",
      "epoch 546\n",
      "..................................................\n",
      "training epoch took 24.4503\n",
      "epoch 547\n",
      "..................................................\n",
      "training epoch took 24.0472\n",
      "epoch 548\n",
      "..................................................\n",
      "training epoch took 24.5977\n",
      "epoch 549\n",
      "..................................................\n",
      "training epoch took 24.3349\n",
      "avg test bits per pixel -0.8969\n",
      "Successfully saved model\n",
      "epoch 550\n",
      "..................................................\n",
      "training epoch took 24.2932\n",
      "epoch 551\n",
      "..................................................\n",
      "training epoch took 24.2987\n",
      "epoch 552\n",
      "..................................................\n",
      "training epoch took 24.4902\n",
      "epoch 553\n",
      "..................................................\n",
      "training epoch took 24.4558\n",
      "epoch 554\n",
      "..................................................\n",
      "training epoch took 24.5832\n",
      "epoch 555\n",
      "..................................................\n",
      "training epoch took 24.5648\n",
      "epoch 556\n",
      "..................................................\n",
      "training epoch took 24.4281\n",
      "epoch 557\n",
      "..................................................\n",
      "training epoch took 23.8359\n",
      "epoch 558\n",
      "..................................................\n",
      "training epoch took 24.2847\n",
      "epoch 559\n",
      "..................................................\n",
      "training epoch took 24.5529\n",
      "epoch 560\n",
      "..................................................\n",
      "training epoch took 24.5691\n",
      "epoch 561\n",
      "..................................................\n",
      "training epoch took 24.4987\n",
      "epoch 562\n",
      "..................................................\n",
      "training epoch took 24.2672\n",
      "epoch 563\n",
      "..................................................\n",
      "training epoch took 24.5215\n",
      "epoch 564\n",
      "..................................................\n",
      "training epoch took 24.5400\n",
      "epoch 565\n",
      "..................................................\n",
      "training epoch took 24.8540\n",
      "epoch 566\n",
      "..................................................\n",
      "training epoch took 24.2909\n",
      "epoch 567\n",
      "..................................................\n",
      "training epoch took 24.5589\n",
      "epoch 568\n",
      "..................................................\n",
      "training epoch took 24.4348\n",
      "epoch 569\n",
      "..................................................\n",
      "training epoch took 24.7826\n",
      "epoch 570\n",
      "..................................................\n",
      "training epoch took 24.5839\n",
      "epoch 571\n",
      "..................................................\n",
      "training epoch took 24.6187\n",
      "epoch 572\n",
      "..................................................\n",
      "training epoch took 24.5468\n",
      "epoch 573\n",
      "..................................................\n",
      "training epoch took 24.8296\n",
      "epoch 574\n",
      "..................................................\n",
      "training epoch took 24.5607\n",
      "avg test bits per pixel -1.0456\n",
      "Successfully saved model\n",
      "epoch 575\n",
      "..................................................\n",
      "training epoch took 23.9218\n",
      "epoch 576\n",
      "..................................................\n",
      "training epoch took 24.0282\n",
      "epoch 577\n",
      "..................................................\n",
      "training epoch took 24.0302\n",
      "epoch 578\n",
      "..................................................\n",
      "training epoch took 23.9694\n",
      "epoch 579\n",
      "..................................................\n",
      "training epoch took 23.9847\n",
      "epoch 580\n",
      "..................................................\n",
      "training epoch took 23.9440\n",
      "epoch 581\n",
      "..................................................\n",
      "training epoch took 24.0070\n",
      "epoch 582\n",
      "..................................................\n",
      "training epoch took 23.9402\n",
      "epoch 583\n",
      "..................................................\n",
      "training epoch took 23.9943\n",
      "epoch 584\n",
      "..................................................\n",
      "training epoch took 24.0408\n",
      "epoch 585\n",
      "..................................................\n",
      "training epoch took 23.8966\n",
      "epoch 586\n",
      "..................................................\n",
      "training epoch took 24.0033\n",
      "epoch 587\n",
      "..................................................\n",
      "training epoch took 24.0255\n",
      "epoch 588\n",
      "..................................................\n",
      "training epoch took 23.9269\n",
      "epoch 589\n",
      "..................................................\n",
      "training epoch took 23.9680\n",
      "epoch 590\n",
      "..................................................\n",
      "training epoch took 23.9816\n",
      "epoch 591\n",
      "..................................................\n",
      "training epoch took 23.9739\n",
      "epoch 592\n",
      "..................................................\n",
      "training epoch took 22.6575\n",
      "epoch 593\n",
      "..................................................\n",
      "training epoch took 23.9345\n",
      "epoch 594\n",
      "..................................................\n",
      "training epoch took 24.0032\n",
      "epoch 595\n",
      "..................................................\n",
      "training epoch took 22.7632\n",
      "epoch 596\n",
      "..................................................\n",
      "training epoch took 24.0014\n",
      "epoch 597\n",
      "..................................................\n",
      "training epoch took 24.0373\n",
      "epoch 598\n",
      "..................................................\n",
      "training epoch took 24.0365\n",
      "epoch 599\n",
      "..................................................\n",
      "training epoch took 24.0173\n",
      "avg test bits per pixel -0.9960\n",
      "Successfully saved model\n",
      "epoch 600\n",
      "..................................................\n",
      "training epoch took 23.9760\n",
      "epoch 601\n",
      "..................................................\n",
      "training epoch took 24.0121\n",
      "epoch 602\n",
      "..................................................\n",
      "training epoch took 23.9068\n",
      "epoch 603\n",
      "..................................................\n",
      "training epoch took 23.9447\n",
      "epoch 604\n",
      "..................................................\n",
      "training epoch took 22.9832\n",
      "epoch 605\n",
      "..................................................\n",
      "training epoch took 24.0534\n",
      "epoch 606\n",
      "..................................................\n",
      "training epoch took 24.0314\n",
      "epoch 607\n",
      "..................................................\n",
      "training epoch took 22.7070\n",
      "epoch 608\n",
      "..................................................\n",
      "training epoch took 23.9651\n",
      "epoch 609\n",
      "..................................................\n",
      "training epoch took 23.9835\n",
      "epoch 610\n",
      "..................................................\n",
      "training epoch took 23.9423\n",
      "epoch 611\n",
      "..................................................\n",
      "training epoch took 23.6859\n",
      "epoch 612\n",
      "..................................................\n",
      "training epoch took 24.0119\n",
      "epoch 613\n",
      "..................................................\n",
      "training epoch took 24.0063\n",
      "epoch 614\n",
      "..................................................\n",
      "training epoch took 24.0069\n",
      "epoch 615\n",
      "..................................................\n",
      "training epoch took 24.0915\n",
      "epoch 616\n",
      "..................................................\n",
      "training epoch took 22.8335\n",
      "epoch 617\n",
      "..................................................\n",
      "training epoch took 24.0000\n",
      "epoch 618\n",
      "..................................................\n",
      "training epoch took 24.0013\n",
      "epoch 619\n",
      "..................................................\n",
      "training epoch took 24.0773\n",
      "epoch 620\n",
      "..................................................\n",
      "training epoch took 24.0332\n",
      "epoch 621\n",
      "..................................................\n",
      "training epoch took 24.0411\n",
      "epoch 622\n",
      "..................................................\n",
      "training epoch took 24.0487\n",
      "epoch 623\n",
      "..................................................\n",
      "training epoch took 23.9836\n",
      "epoch 624\n",
      "..................................................\n",
      "training epoch took 23.9428\n",
      "avg test bits per pixel -1.0306\n",
      "Successfully saved model\n",
      "epoch 625\n",
      "..................................................\n",
      "training epoch took 24.0180\n",
      "epoch 626\n",
      "..................................................\n",
      "training epoch took 24.0226\n",
      "epoch 627\n",
      "..................................................\n",
      "training epoch took 24.0079\n",
      "epoch 628\n",
      "..................................................\n",
      "training epoch took 24.0029\n",
      "epoch 629\n",
      "..................................................\n",
      "training epoch took 23.7300\n",
      "epoch 630\n",
      "..................................................\n",
      "training epoch took 24.0273\n",
      "epoch 631\n",
      "..................................................\n",
      "training epoch took 22.5926\n",
      "epoch 632\n",
      "..................................................\n",
      "training epoch took 22.6575\n",
      "epoch 633\n",
      "..................................................\n",
      "training epoch took 24.0871\n",
      "epoch 634\n",
      "..................................................\n",
      "training epoch took 23.9589\n",
      "epoch 635\n",
      "..................................................\n",
      "training epoch took 23.9669\n",
      "epoch 636\n",
      "..................................................\n",
      "training epoch took 24.0522\n",
      "epoch 637\n",
      "..................................................\n",
      "training epoch took 23.9410\n",
      "epoch 638\n",
      "..................................................\n",
      "training epoch took 24.0178\n",
      "epoch 639\n",
      "..................................................\n",
      "training epoch took 24.0655\n",
      "epoch 640\n",
      "..................................................\n",
      "training epoch took 23.9201\n",
      "epoch 641\n",
      "..................................................\n",
      "training epoch took 23.9828\n",
      "epoch 642\n",
      "..................................................\n",
      "training epoch took 23.9843\n",
      "epoch 643\n",
      "..................................................\n",
      "training epoch took 23.9679\n",
      "epoch 644\n",
      "..................................................\n",
      "training epoch took 23.9990\n",
      "epoch 645\n",
      "..................................................\n",
      "training epoch took 23.9621\n",
      "epoch 646\n",
      "..................................................\n",
      "training epoch took 23.9956\n",
      "epoch 647\n",
      "..................................................\n",
      "training epoch took 23.9918\n",
      "epoch 648\n",
      "..................................................\n",
      "training epoch took 24.0228\n",
      "epoch 649\n",
      "..................................................\n",
      "training epoch took 24.0508\n",
      "avg test bits per pixel -0.9923\n",
      "Successfully saved model\n",
      "epoch 650\n",
      "..................................................\n",
      "training epoch took 23.9968\n",
      "epoch 651\n",
      "..................................................\n",
      "training epoch took 23.0201\n",
      "epoch 652\n",
      "..................................................\n",
      "training epoch took 23.8850\n",
      "epoch 653\n",
      "..................................................\n",
      "training epoch took 24.0258\n",
      "epoch 654\n",
      "..................................................\n",
      "training epoch took 24.0322\n",
      "epoch 655\n",
      "..................................................\n",
      "training epoch took 22.5734\n",
      "epoch 656\n",
      "..................................................\n",
      "training epoch took 24.0240\n",
      "epoch 657\n",
      "..................................................\n",
      "training epoch took 24.0106\n",
      "epoch 658\n",
      "..................................................\n",
      "training epoch took 24.0196\n",
      "epoch 659\n",
      "..................................................\n",
      "training epoch took 24.0477\n",
      "epoch 660\n",
      "..................................................\n",
      "training epoch took 24.0881\n",
      "epoch 661\n",
      "..................................................\n",
      "training epoch took 24.0570\n",
      "epoch 662\n",
      "..................................................\n",
      "training epoch took 24.0035\n",
      "epoch 663\n",
      "..................................................\n",
      "training epoch took 23.9338\n",
      "epoch 664\n",
      "..................................................\n",
      "training epoch took 24.0445\n",
      "epoch 665\n",
      "..................................................\n",
      "training epoch took 23.9256\n",
      "epoch 666\n",
      "..................................................\n",
      "training epoch took 23.9389\n",
      "epoch 667\n",
      "..................................................\n",
      "training epoch took 24.0214\n",
      "epoch 668\n",
      "..................................................\n",
      "training epoch took 22.6557\n",
      "epoch 669\n",
      "..................................................\n",
      "training epoch took 23.1307\n",
      "epoch 670\n",
      "..................................................\n",
      "training epoch took 22.7337\n",
      "epoch 671\n",
      "..................................................\n",
      "training epoch took 24.0332\n",
      "epoch 672\n",
      "..................................................\n",
      "training epoch took 24.0180\n",
      "epoch 673\n",
      "..................................................\n",
      "training epoch took 24.0006\n",
      "epoch 674\n",
      "..................................................\n",
      "training epoch took 23.0577\n",
      "avg test bits per pixel -1.2488\n",
      "Successfully saved model\n",
      "epoch 675\n",
      "..................................................\n",
      "training epoch took 24.0205\n",
      "epoch 676\n",
      "..................................................\n",
      "training epoch took 24.0468\n",
      "epoch 677\n",
      "..................................................\n",
      "training epoch took 24.0393\n",
      "epoch 678\n",
      "..................................................\n",
      "training epoch took 24.0161\n",
      "epoch 679\n",
      "..................................................\n",
      "training epoch took 24.0132\n",
      "epoch 680\n",
      "..................................................\n",
      "training epoch took 24.0541\n",
      "epoch 681\n",
      "..................................................\n",
      "training epoch took 23.9315\n",
      "epoch 682\n",
      "..................................................\n",
      "training epoch took 24.0260\n",
      "epoch 683\n",
      "..................................................\n",
      "training epoch took 23.2076\n",
      "epoch 684\n",
      "..................................................\n",
      "training epoch took 24.0391\n",
      "epoch 685\n",
      "..................................................\n",
      "training epoch took 24.0112\n",
      "epoch 686\n",
      "..................................................\n",
      "training epoch took 23.9959\n",
      "epoch 687\n",
      "..................................................\n",
      "training epoch took 24.0320\n",
      "epoch 688\n",
      "..................................................\n",
      "training epoch took 23.6053\n",
      "epoch 689\n",
      "..................................................\n",
      "training epoch took 23.9799\n",
      "epoch 690\n",
      "..................................................\n",
      "training epoch took 23.9627\n",
      "epoch 691\n",
      "..................................................\n",
      "training epoch took 23.9769\n",
      "epoch 692\n",
      "..................................................\n",
      "training epoch took 23.9224\n",
      "epoch 693\n",
      "..................................................\n",
      "training epoch took 23.4787\n",
      "epoch 694\n",
      "..................................................\n",
      "training epoch took 23.9818\n",
      "epoch 695\n",
      "..................................................\n",
      "training epoch took 24.0191\n",
      "epoch 696\n",
      "..................................................\n",
      "training epoch took 23.9263\n",
      "epoch 697\n",
      "..................................................\n",
      "training epoch took 24.0443\n",
      "epoch 698\n",
      "..................................................\n",
      "training epoch took 23.9757\n",
      "epoch 699\n",
      "..................................................\n",
      "training epoch took 23.9584\n",
      "avg test bits per pixel -1.1454\n",
      "Successfully saved model\n",
      "epoch 700\n",
      "..................................................\n",
      "training epoch took 23.9742\n",
      "epoch 701\n",
      "..................................................\n",
      "training epoch took 23.9844\n",
      "epoch 702\n",
      "..................................................\n",
      "training epoch took 24.0147\n",
      "epoch 703\n",
      "..................................................\n",
      "training epoch took 23.9230\n",
      "epoch 704\n",
      "..................................................\n",
      "training epoch took 23.9222\n",
      "epoch 705\n",
      "..................................................\n",
      "training epoch took 23.9133\n",
      "epoch 706\n",
      "..................................................\n",
      "training epoch took 23.9067\n",
      "epoch 707\n",
      "..................................................\n",
      "training epoch took 24.0135\n",
      "epoch 708\n",
      "..................................................\n",
      "training epoch took 22.9662\n",
      "epoch 709\n",
      "..................................................\n",
      "training epoch took 23.9164\n",
      "epoch 710\n",
      "..................................................\n",
      "training epoch took 23.8621\n",
      "epoch 711\n",
      "..................................................\n",
      "training epoch took 23.9762\n",
      "epoch 712\n",
      "..................................................\n",
      "training epoch took 23.9623\n",
      "epoch 713\n",
      "..................................................\n",
      "training epoch took 23.9246\n",
      "epoch 714\n",
      "..................................................\n",
      "training epoch took 23.9832\n",
      "epoch 715\n",
      "..................................................\n",
      "training epoch took 23.9520\n",
      "epoch 716\n",
      "..................................................\n",
      "training epoch took 23.9626\n",
      "epoch 717\n",
      "..................................................\n",
      "training epoch took 24.0311\n",
      "epoch 718\n",
      "..................................................\n",
      "training epoch took 23.5775\n",
      "epoch 719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "training epoch took 23.8438\n",
      "epoch 720\n",
      "..................................................\n",
      "training epoch took 24.0090\n",
      "epoch 721\n",
      "..................................................\n",
      "training epoch took 23.9825\n",
      "epoch 722\n",
      "..................................................\n",
      "training epoch took 24.0322\n",
      "epoch 723\n",
      "..................................................\n",
      "training epoch took 22.9929\n",
      "epoch 724\n",
      "..................................................\n",
      "training epoch took 23.9126\n",
      "avg test bits per pixel -0.9702\n",
      "Successfully saved model\n",
      "epoch 725\n",
      "..................................................\n",
      "training epoch took 23.9326\n",
      "epoch 726\n",
      "..................................................\n",
      "training epoch took 23.9665\n",
      "epoch 727\n",
      "..................................................\n",
      "training epoch took 24.0361\n",
      "epoch 728\n",
      "..................................................\n",
      "training epoch took 23.9295\n",
      "epoch 729\n",
      "..................................................\n",
      "training epoch took 23.9570\n",
      "epoch 730\n",
      "..................................................\n",
      "training epoch took 22.7561\n",
      "epoch 731\n",
      "..................................................\n",
      "training epoch took 24.0032\n",
      "epoch 732\n",
      "..................................................\n",
      "training epoch took 22.6310\n",
      "epoch 733\n",
      "..................................................\n",
      "training epoch took 24.0120\n",
      "epoch 734\n",
      "..................................................\n",
      "training epoch took 24.0021\n",
      "epoch 735\n",
      "..................................................\n",
      "training epoch took 23.9969\n",
      "epoch 736\n",
      "..................................................\n",
      "training epoch took 22.6648\n",
      "epoch 737\n",
      "..................................................\n",
      "training epoch took 24.1139\n",
      "epoch 738\n",
      "..................................................\n",
      "training epoch took 23.9871\n",
      "epoch 739\n",
      "..................................................\n",
      "training epoch took 23.9819\n",
      "epoch 740\n",
      "..................................................\n",
      "training epoch took 24.0203\n",
      "epoch 741\n",
      "..................................................\n",
      "training epoch took 23.9839\n",
      "epoch 742\n",
      "..................................................\n",
      "training epoch took 23.9953\n",
      "epoch 743\n",
      "..................................................\n",
      "training epoch took 23.9293\n",
      "epoch 744\n",
      "..................................................\n",
      "training epoch took 24.0103\n",
      "epoch 745\n",
      "..................................................\n",
      "training epoch took 23.9501\n",
      "epoch 746\n",
      "..................................................\n",
      "training epoch took 23.2169\n",
      "epoch 747\n",
      "..................................................\n",
      "training epoch took 22.5995\n",
      "epoch 748\n",
      "..................................................\n",
      "training epoch took 24.0231\n",
      "epoch 749\n",
      "..................................................\n",
      "training epoch took 23.1367\n",
      "avg test bits per pixel -1.2133\n",
      "Successfully saved model\n",
      "epoch 750\n",
      "..................................................\n",
      "training epoch took 23.8343\n",
      "epoch 751\n",
      "..................................................\n",
      "training epoch took 23.9453\n",
      "epoch 752\n",
      "..................................................\n",
      "training epoch took 23.9102\n",
      "epoch 753\n",
      "..................................................\n",
      "training epoch took 23.9201\n",
      "epoch 754\n",
      "..................................................\n",
      "training epoch took 23.8937\n",
      "epoch 755\n",
      "..................................................\n",
      "training epoch took 24.0325\n",
      "epoch 756\n",
      "..................................................\n",
      "training epoch took 23.9969\n",
      "epoch 757\n",
      "..................................................\n",
      "training epoch took 23.9920\n",
      "epoch 758\n",
      "..................................................\n",
      "training epoch took 23.9760\n",
      "epoch 759\n",
      "..................................................\n",
      "training epoch took 24.0435\n",
      "epoch 760\n",
      "..................................................\n",
      "training epoch took 23.2754\n",
      "epoch 761\n",
      "..................................................\n",
      "training epoch took 22.6357\n",
      "epoch 762\n",
      "..................................................\n",
      "training epoch took 23.6929\n",
      "epoch 763\n",
      "..................................................\n",
      "training epoch took 23.9549\n",
      "epoch 764\n",
      "..................................................\n",
      "training epoch took 23.9924\n",
      "epoch 765\n",
      "..................................................\n",
      "training epoch took 23.9326\n",
      "epoch 766\n",
      "..................................................\n",
      "training epoch took 22.6248\n",
      "epoch 767\n",
      "..................................................\n",
      "training epoch took 22.7549\n",
      "epoch 768\n",
      "..................................................\n",
      "training epoch took 22.6152\n",
      "epoch 769\n",
      "..................................................\n",
      "training epoch took 22.6866\n",
      "epoch 770\n",
      "..................................................\n",
      "training epoch took 24.0190\n",
      "epoch 771\n",
      "..................................................\n",
      "training epoch took 22.9717\n",
      "epoch 772\n",
      "..................................................\n",
      "training epoch took 23.9036\n",
      "epoch 773\n",
      "..................................................\n",
      "training epoch took 23.9536\n",
      "epoch 774\n",
      "..................................................\n",
      "training epoch took 24.0472\n",
      "avg test bits per pixel -1.1576\n",
      "Successfully saved model\n",
      "epoch 775\n",
      "..................................................\n",
      "training epoch took 23.9490\n",
      "epoch 776\n",
      "..................................................\n",
      "training epoch took 24.0366\n",
      "epoch 777\n",
      "..................................................\n",
      "training epoch took 24.0356\n",
      "epoch 778\n",
      "..................................................\n",
      "training epoch took 24.0509\n",
      "epoch 779\n",
      "..................................................\n",
      "training epoch took 23.9149\n",
      "epoch 780\n",
      "..................................................\n",
      "training epoch took 24.0075\n",
      "epoch 781\n",
      "..................................................\n",
      "training epoch took 23.7686\n",
      "epoch 782\n",
      "..................................................\n",
      "training epoch took 22.9363\n",
      "epoch 783\n",
      "..................................................\n",
      "training epoch took 24.0354\n",
      "epoch 784\n",
      "..................................................\n",
      "training epoch took 23.9504\n",
      "epoch 785\n",
      "..................................................\n",
      "training epoch took 24.0693\n",
      "epoch 786\n",
      "..................................................\n",
      "training epoch took 22.8949\n",
      "epoch 787\n",
      "..................................................\n",
      "training epoch took 24.0044\n",
      "epoch 788\n",
      "..................................................\n",
      "training epoch took 23.9852\n",
      "epoch 789\n",
      "..................................................\n",
      "training epoch took 24.0341\n",
      "epoch 790\n",
      "..................................................\n",
      "training epoch took 23.0480\n",
      "epoch 791\n",
      "..................................................\n",
      "training epoch took 23.9700\n",
      "epoch 792\n",
      "..................................................\n",
      "training epoch took 23.9713\n",
      "epoch 793\n",
      "..................................................\n",
      "training epoch took 23.9568\n",
      "epoch 794\n",
      "..................................................\n",
      "training epoch took 23.9707\n",
      "epoch 795\n",
      "..................................................\n",
      "training epoch took 23.9748\n",
      "epoch 796\n",
      "..................................................\n",
      "training epoch took 23.9692\n",
      "epoch 797\n",
      "..................................................\n",
      "training epoch took 23.9454\n",
      "epoch 798\n",
      "..................................................\n",
      "training epoch took 23.9828\n",
      "epoch 799\n",
      "..................................................\n",
      "training epoch took 24.0123\n",
      "avg test bits per pixel -1.0366\n",
      "Successfully saved model\n",
      "epoch 800\n",
      "..................................................\n",
      "training epoch took 24.0580\n",
      "epoch 801\n",
      "..................................................\n",
      "training epoch took 24.0446\n",
      "epoch 802\n",
      "..................................................\n",
      "training epoch took 23.9574\n",
      "epoch 803\n",
      "..................................................\n",
      "training epoch took 23.9532\n",
      "epoch 804\n",
      "..................................................\n",
      "training epoch took 23.4323\n",
      "epoch 805\n",
      "..................................................\n",
      "training epoch took 23.8848\n",
      "epoch 806\n",
      "..................................................\n",
      "training epoch took 23.9074\n",
      "epoch 807\n",
      "..................................................\n",
      "training epoch took 23.9234\n",
      "epoch 808\n",
      "..................................................\n",
      "training epoch took 23.8727\n",
      "epoch 809\n",
      "..................................................\n",
      "training epoch took 22.7107\n",
      "epoch 810\n",
      "..................................................\n",
      "training epoch took 23.8902\n",
      "epoch 811\n",
      "..................................................\n",
      "training epoch took 24.0466\n",
      "epoch 812\n",
      "..................................................\n",
      "training epoch took 22.7824\n",
      "epoch 813\n",
      "..................................................\n",
      "training epoch took 24.0152\n",
      "epoch 814\n",
      "..................................................\n",
      "training epoch took 23.9592\n",
      "epoch 815\n",
      "..................................................\n",
      "training epoch took 23.9342\n",
      "epoch 816\n",
      "..................................................\n",
      "training epoch took 23.9490\n",
      "epoch 817\n",
      "..................................................\n",
      "training epoch took 23.9795\n",
      "epoch 818\n",
      "..................................................\n",
      "training epoch took 23.9307\n",
      "epoch 819\n",
      "..................................................\n",
      "training epoch took 23.9860\n",
      "epoch 820\n",
      "..................................................\n",
      "training epoch took 24.0115\n",
      "epoch 821\n",
      "..................................................\n",
      "training epoch took 23.3825\n",
      "epoch 822\n",
      "..................................................\n",
      "training epoch took 23.9304\n",
      "epoch 823\n",
      "..................................................\n",
      "training epoch took 23.9936\n",
      "epoch 824\n",
      "..................................................\n",
      "training epoch took 22.5777\n",
      "avg test bits per pixel -0.5865\n",
      "Successfully saved model\n",
      "epoch 825\n",
      "..................................................\n",
      "training epoch took 23.7073\n",
      "epoch 826\n",
      "..................................................\n",
      "training epoch took 24.0265\n",
      "epoch 827\n",
      "..................................................\n",
      "training epoch took 23.9954\n",
      "epoch 828\n",
      "..................................................\n",
      "training epoch took 23.9584\n",
      "epoch 829\n",
      "..................................................\n",
      "training epoch took 24.0186\n",
      "epoch 830\n",
      "..................................................\n",
      "training epoch took 23.9998\n",
      "epoch 831\n",
      "..................................................\n",
      "training epoch took 23.9918\n",
      "epoch 832\n",
      "..................................................\n",
      "training epoch took 23.9865\n",
      "epoch 833\n",
      "..................................................\n",
      "training epoch took 23.9762\n",
      "epoch 834\n",
      "..................................................\n",
      "training epoch took 24.0205\n",
      "epoch 835\n",
      "..................................................\n",
      "training epoch took 23.9172\n",
      "epoch 836\n",
      "..................................................\n",
      "training epoch took 24.0715\n",
      "epoch 837\n",
      "..................................................\n",
      "training epoch took 23.1247\n",
      "epoch 838\n",
      "..................................................\n",
      "training epoch took 24.0015\n",
      "epoch 839\n",
      "..................................................\n",
      "training epoch took 23.9792\n",
      "epoch 840\n",
      "..................................................\n",
      "training epoch took 24.0358\n",
      "epoch 841\n",
      "..................................................\n",
      "training epoch took 23.8104\n",
      "epoch 842\n",
      "..................................................\n",
      "training epoch took 22.6485\n",
      "epoch 843\n",
      "..................................................\n",
      "training epoch took 22.8705\n",
      "epoch 844\n",
      "..................................................\n",
      "training epoch took 23.9665\n",
      "epoch 845\n",
      "..................................................\n",
      "training epoch took 23.9735\n",
      "epoch 846\n",
      "..................................................\n",
      "training epoch took 23.9614\n",
      "epoch 847\n",
      "..................................................\n",
      "training epoch took 24.0129\n",
      "epoch 848\n",
      "..................................................\n",
      "training epoch took 22.6376\n",
      "epoch 849\n",
      "..................................................\n",
      "training epoch took 23.9692\n",
      "avg test bits per pixel -1.0149\n",
      "Successfully saved model\n",
      "epoch 850\n",
      "..................................................\n",
      "training epoch took 23.8828\n",
      "epoch 851\n",
      "..................................................\n",
      "training epoch took 22.6038\n",
      "epoch 852\n",
      "..................................................\n",
      "training epoch took 23.7669\n",
      "epoch 853\n",
      "..................................................\n",
      "training epoch took 23.8570\n",
      "epoch 854\n",
      "..................................................\n",
      "training epoch took 23.9766\n",
      "epoch 855\n",
      "..................................................\n",
      "training epoch took 23.2109\n",
      "epoch 856\n",
      "..................................................\n",
      "training epoch took 24.0267\n",
      "epoch 857\n",
      "..................................................\n",
      "training epoch took 23.9902\n",
      "epoch 858\n",
      "..................................................\n",
      "training epoch took 23.9771\n",
      "epoch 859\n",
      "..................................................\n",
      "training epoch took 24.0041\n",
      "epoch 860\n",
      "..................................................\n",
      "training epoch took 23.8363\n",
      "epoch 861\n",
      "..................................................\n",
      "training epoch took 23.8408\n",
      "epoch 862\n",
      "..................................................\n",
      "training epoch took 23.9273\n",
      "epoch 863\n",
      "..................................................\n",
      "training epoch took 22.6493\n",
      "epoch 864\n",
      "..................................................\n",
      "training epoch took 23.9495\n",
      "epoch 865\n",
      "..................................................\n",
      "training epoch took 23.7000\n",
      "epoch 866\n",
      "..................................................\n",
      "training epoch took 23.9274\n",
      "epoch 867\n",
      "..................................................\n",
      "training epoch took 24.0227\n",
      "epoch 868\n",
      "..................................................\n",
      "training epoch took 23.8733\n",
      "epoch 869\n",
      "..................................................\n",
      "training epoch took 22.9017\n",
      "epoch 870\n",
      "..................................................\n",
      "training epoch took 23.9970\n",
      "epoch 871\n",
      "..................................................\n",
      "training epoch took 23.4845\n",
      "epoch 872\n",
      "..................................................\n",
      "training epoch took 24.0263\n",
      "epoch 873\n",
      "..................................................\n",
      "training epoch took 23.9099\n",
      "epoch 874\n",
      "..................................................\n",
      "training epoch took 23.3868\n",
      "avg test bits per pixel -1.0915\n",
      "Successfully saved model\n",
      "epoch 875\n",
      "..................................................\n",
      "training epoch took 22.6014\n",
      "epoch 876\n",
      "..................................................\n",
      "training epoch took 22.6140\n",
      "epoch 877\n",
      "..................................................\n",
      "training epoch took 22.6711\n",
      "epoch 878\n",
      "..................................................\n",
      "training epoch took 23.9885\n",
      "epoch 879\n",
      "..................................................\n",
      "training epoch took 24.0187\n",
      "epoch 880\n",
      "..................................................\n",
      "training epoch took 23.2395\n",
      "epoch 881\n",
      "..................................................\n",
      "training epoch took 24.0380\n",
      "epoch 882\n",
      "..................................................\n",
      "training epoch took 24.0462\n",
      "epoch 883\n",
      "..................................................\n",
      "training epoch took 23.9604\n",
      "epoch 884\n",
      "..................................................\n",
      "training epoch took 24.0223\n",
      "epoch 885\n",
      "..................................................\n",
      "training epoch took 23.9471\n",
      "epoch 886\n",
      "..................................................\n",
      "training epoch took 23.9789\n",
      "epoch 887\n",
      "..................................................\n",
      "training epoch took 23.9328\n",
      "epoch 888\n",
      "..................................................\n",
      "training epoch took 23.8531\n",
      "epoch 889\n",
      "..................................................\n",
      "training epoch took 24.0142\n",
      "epoch 890\n",
      "..................................................\n",
      "training epoch took 24.0473\n",
      "epoch 891\n",
      "..................................................\n",
      "training epoch took 23.9254\n",
      "epoch 892\n",
      "..................................................\n",
      "training epoch took 23.9062\n",
      "epoch 893\n",
      "..................................................\n",
      "training epoch took 23.9665\n",
      "epoch 894\n",
      "..................................................\n",
      "training epoch took 23.9017\n",
      "epoch 895\n",
      "..................................................\n",
      "training epoch took 24.0287\n",
      "epoch 896\n",
      "..................................................\n",
      "training epoch took 23.9823\n",
      "epoch 897\n",
      "..................................................\n",
      "training epoch took 23.9911\n",
      "epoch 898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "training epoch took 24.0344\n",
      "epoch 899\n",
      "..................................................\n",
      "training epoch took 23.9889\n",
      "avg test bits per pixel -1.0964\n",
      "Successfully saved model\n",
      "epoch 900\n",
      "..................................................\n",
      "training epoch took 24.0345\n",
      "epoch 901\n",
      "..................................................\n",
      "training epoch took 23.9794\n",
      "epoch 902\n",
      "..................................................\n",
      "training epoch took 23.9888\n",
      "epoch 903\n",
      "..................................................\n",
      "training epoch took 24.0949\n",
      "epoch 904\n",
      "..................................................\n",
      "training epoch took 24.0402\n",
      "epoch 905\n",
      "..................................................\n",
      "training epoch took 23.6249\n",
      "epoch 906\n",
      "..................................................\n",
      "training epoch took 23.9944\n",
      "epoch 907\n",
      "..................................................\n",
      "training epoch took 24.0027\n",
      "epoch 908\n",
      "..................................................\n",
      "training epoch took 24.0119\n",
      "epoch 909\n",
      "..................................................\n",
      "training epoch took 24.0228\n",
      "epoch 910\n",
      "..................................................\n",
      "training epoch took 23.9870\n",
      "epoch 911\n",
      "..................................................\n",
      "training epoch took 23.3726\n",
      "epoch 912\n",
      "..................................................\n",
      "training epoch took 23.9566\n",
      "epoch 913\n",
      "..................................................\n",
      "training epoch took 23.9768\n",
      "epoch 914\n",
      "..................................................\n",
      "training epoch took 23.9746\n",
      "epoch 915\n",
      "..................................................\n",
      "training epoch took 24.0228\n",
      "epoch 916\n",
      "..................................................\n",
      "training epoch took 24.0041\n",
      "epoch 917\n",
      "..................................................\n",
      "training epoch took 23.9421\n",
      "epoch 918\n",
      "..................................................\n",
      "training epoch took 24.0971\n",
      "epoch 919\n",
      "..................................................\n",
      "training epoch took 23.9828\n",
      "epoch 920\n",
      "..................................................\n",
      "training epoch took 23.9723\n",
      "epoch 921\n",
      "..................................................\n",
      "training epoch took 22.8777\n",
      "epoch 922\n",
      "..................................................\n",
      "training epoch took 22.8277\n",
      "epoch 923\n",
      "..................................................\n",
      "training epoch took 24.0024\n",
      "epoch 924\n",
      "..................................................\n",
      "training epoch took 23.9256\n",
      "avg test bits per pixel -1.0814\n",
      "Successfully saved model\n",
      "epoch 925\n",
      "..................................................\n",
      "training epoch took 24.0032\n",
      "epoch 926\n",
      "..................................................\n",
      "training epoch took 23.8778\n",
      "epoch 927\n",
      "..................................................\n",
      "training epoch took 23.9011\n",
      "epoch 928\n",
      "..................................................\n",
      "training epoch took 24.0123\n",
      "epoch 929\n",
      "..................................................\n",
      "training epoch took 24.0154\n",
      "epoch 930\n",
      "..................................................\n",
      "training epoch took 23.9853\n",
      "epoch 931\n",
      "..................................................\n",
      "training epoch took 24.0259\n",
      "epoch 932\n",
      "..................................................\n",
      "training epoch took 24.0303\n",
      "epoch 933\n",
      "..................................................\n",
      "training epoch took 23.8535\n",
      "epoch 934\n",
      "..................................................\n",
      "training epoch took 22.6545\n",
      "epoch 935\n",
      "..................................................\n",
      "training epoch took 23.9561\n",
      "epoch 936\n",
      "..................................................\n",
      "training epoch took 23.9025\n",
      "epoch 937\n",
      "..................................................\n",
      "training epoch took 23.8734\n",
      "epoch 938\n",
      "..................................................\n",
      "training epoch took 24.0110\n",
      "epoch 939\n",
      "..................................................\n",
      "training epoch took 24.0173\n",
      "epoch 940\n",
      "..................................................\n",
      "training epoch took 24.0366\n",
      "epoch 941\n",
      "..................................................\n",
      "training epoch took 23.8821\n",
      "epoch 942\n",
      "..................................................\n",
      "training epoch took 23.9188\n",
      "epoch 943\n",
      "..................................................\n",
      "training epoch took 23.7923\n",
      "epoch 944\n",
      "..................................................\n",
      "training epoch took 23.9453\n",
      "epoch 945\n",
      "..................................................\n",
      "training epoch took 24.0365\n",
      "epoch 946\n",
      "..................................................\n",
      "training epoch took 24.0455\n",
      "epoch 947\n",
      "..................................................\n",
      "training epoch took 23.8731\n",
      "epoch 948\n",
      "..................................................\n",
      "training epoch took 24.0119\n",
      "epoch 949\n",
      "..................................................\n",
      "training epoch took 23.9061\n",
      "avg test bits per pixel -0.9345\n",
      "Successfully saved model\n",
      "epoch 950\n",
      "..................................................\n",
      "training epoch took 23.9569\n",
      "epoch 951\n",
      "..................................................\n",
      "training epoch took 24.0256\n",
      "epoch 952\n",
      "..................................................\n",
      "training epoch took 23.9866\n",
      "epoch 953\n",
      "..................................................\n",
      "training epoch took 24.0160\n",
      "epoch 954\n",
      "..................................................\n",
      "training epoch took 24.0177\n",
      "epoch 955\n",
      "..................................................\n",
      "training epoch took 24.0246\n",
      "epoch 956\n",
      "..................................................\n",
      "training epoch took 24.0292\n",
      "epoch 957\n",
      "..................................................\n",
      "training epoch took 23.9825\n",
      "epoch 958\n",
      "..................................................\n",
      "training epoch took 23.9970\n",
      "epoch 959\n",
      "..................................................\n",
      "training epoch took 24.0435\n",
      "epoch 960\n",
      "..................................................\n",
      "training epoch took 23.9774\n",
      "epoch 961\n",
      "..................................................\n",
      "training epoch took 24.0047\n",
      "epoch 962\n",
      "..................................................\n",
      "training epoch took 23.0302\n",
      "epoch 963\n",
      "..................................................\n",
      "training epoch took 24.0275\n",
      "epoch 964\n",
      "..................................................\n",
      "training epoch took 23.7959\n",
      "epoch 965\n",
      "..................................................\n",
      "training epoch took 23.9880\n",
      "epoch 966\n",
      "..................................................\n",
      "training epoch took 24.0148\n",
      "epoch 967\n",
      "..................................................\n",
      "training epoch took 24.0408\n",
      "epoch 968\n",
      "..................................................\n",
      "training epoch took 23.9919\n",
      "epoch 969\n",
      "..................................................\n",
      "training epoch took 23.9642\n",
      "epoch 970\n",
      "..................................................\n",
      "training epoch took 23.9816\n",
      "epoch 971\n",
      "..................................................\n",
      "training epoch took 23.8252\n",
      "epoch 972\n",
      "..................................................\n",
      "training epoch took 23.8731\n",
      "epoch 973\n",
      "..................................................\n",
      "training epoch took 23.8900\n",
      "epoch 974\n",
      "..................................................\n",
      "training epoch took 24.0217\n",
      "avg test bits per pixel -0.9822\n",
      "Successfully saved model\n",
      "epoch 975\n",
      "..................................................\n",
      "training epoch took 23.8349\n",
      "epoch 976\n",
      "..................................................\n",
      "training epoch took 22.8516\n",
      "epoch 977\n",
      "..................................................\n",
      "training epoch took 23.7397\n",
      "epoch 978\n",
      "..................................................\n",
      "training epoch took 23.9249\n",
      "epoch 979\n",
      "..................................................\n",
      "training epoch took 23.8168\n",
      "epoch 980\n",
      "..................................................\n",
      "training epoch took 23.9606\n",
      "epoch 981\n",
      "..................................................\n",
      "training epoch took 23.9775\n",
      "epoch 982\n",
      "..................................................\n",
      "training epoch took 22.9630\n",
      "epoch 983\n",
      "..................................................\n",
      "training epoch took 23.9847\n",
      "epoch 984\n",
      "..................................................\n",
      "training epoch took 24.0470\n",
      "epoch 985\n",
      "..................................................\n",
      "training epoch took 23.9448\n",
      "epoch 986\n",
      "..................................................\n",
      "training epoch took 23.9866\n",
      "epoch 987\n",
      "..................................................\n",
      "training epoch took 24.0110\n",
      "epoch 988\n",
      "..................................................\n",
      "training epoch took 23.8597\n",
      "epoch 989\n",
      "..................................................\n",
      "training epoch took 23.9706\n",
      "epoch 990\n",
      "..................................................\n",
      "training epoch took 23.0403\n",
      "epoch 991\n",
      "..................................................\n",
      "training epoch took 24.0381\n",
      "epoch 992\n",
      "..................................................\n",
      "training epoch took 24.0081\n",
      "epoch 993\n",
      "..................................................\n",
      "training epoch took 23.9926\n",
      "epoch 994\n",
      "..................................................\n",
      "training epoch took 23.0696\n",
      "epoch 995\n",
      "..................................................\n",
      "training epoch took 24.0036\n",
      "epoch 996\n",
      "..................................................\n",
      "training epoch took 24.0292\n",
      "epoch 997\n",
      "..................................................\n",
      "training epoch took 23.9446\n",
      "epoch 998\n",
      "..................................................\n",
      "training epoch took 23.9535\n",
      "epoch 999\n",
      "..................................................\n",
      "training epoch took 24.0265\n",
      "avg test bits per pixel -0.7240\n",
      "Successfully saved model\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "# ------------------------------------------------------------------------------\n",
    "for epoch in range(start_epoch, args.n_epochs):\n",
    "  print('epoch %s' % epoch)\n",
    "  t = time.time()\n",
    "  model.train()\n",
    "  avg_train_bits_x = 0.\n",
    "  num_batches = len(train_loader)\n",
    "  for i, (img, _, _, _) in enumerate(train_loader):\n",
    "    # if i > 3 : break\n",
    "\n",
    "    img = img.cuda() \n",
    "    objective = torch.zeros_like(img[:, 0, 0, 0])\n",
    "\n",
    "    # discretizing cost \n",
    "    objective += float(-np.log(args.n_bins) * np.prod(img.shape[1:]))\n",
    "\n",
    "    # log_det_jacobian cost (and some prior from Split OP)\n",
    "    z, objective = model(img, objective)\n",
    "\n",
    "    nll = (-objective) / float(np.log(2.) * np.prod(img.shape[1:]))\n",
    "\n",
    "    # Generative loss\n",
    "    nobj = torch.mean(nll)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    nobj.backward()\n",
    "    torch.nn.utils.clip_grad_value_(model.parameters(), 5)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 100)\n",
    "    opt.step()\n",
    "    avg_train_bits_x += nobj.item()\n",
    "\n",
    "    # update learning rate\n",
    "    new_lr = float(args.lr * min(1., (i + epoch * num_batches) / (args.n_warmup * num_batches)))\n",
    "    for pg in opt.param_groups: pg['lr'] = new_lr\n",
    "\n",
    "    if (i + 1) % args.print_every == 0: \n",
    "      print('avg train bits per pixel {:.4f}'.format(avg_train_bits_x / args.print_every))\n",
    "      avg_train_bits_x = 0.\n",
    "      sample = (model.module.sample())\n",
    "      grid = utils.make_grid(sample)\n",
    "      utils.save_image(grid, './glow/rl_samples/rl_Test_{}_{}.png'.format(epoch, i // args.print_every))\n",
    "    print('.',end='',flush=True)\n",
    "  print('')\n",
    "  print('training epoch took {:.4f}'.format(time.time() - t))\n",
    "\n",
    "  # test loop\n",
    "  # --------------------------------------------------------------------------\n",
    "  if (epoch + 1) % args.test_every == 0:\n",
    "    model.eval()\n",
    "    avg_test_bits_x = 0.\n",
    "    with torch.no_grad():\n",
    "      for i, (img, _, _, _) in enumerate(test_loader): \n",
    "        # if i > 10 : break\n",
    "        img = img.cuda() \n",
    "        objective = torch.zeros_like(img[:, 0, 0, 0])\n",
    "\n",
    "        # discretizing cost \n",
    "        objective += float(-np.log(args.n_bins) * np.prod(img.shape[1:]))\n",
    "\n",
    "        # log_det_jacobian cost (and some prior from Split OP)\n",
    "        z, objective = model(img, objective)\n",
    "        last_img = img\n",
    "\n",
    "        nll = (-objective) / float(np.log(2.) * np.prod(img.shape[1:]))\n",
    "\n",
    "        # Generative loss\n",
    "        nobj = torch.mean(nll)\n",
    "        avg_test_bits_x += nobj.item()\n",
    "\n",
    "      print('avg test bits per pixel {:.4f}'.format(avg_test_bits_x / i))\n",
    "\n",
    "      sample = (model.module.sample())\n",
    "      utils.save_image(sample, './glow/rl_samples/rl_Test_{}.png'.format(epoch))\n",
    "\n",
    "      # reconstruct\n",
    "      x_hat = (model.module.reverse_(z, objective)[0])\n",
    "      utils.save_image(x_hat, './glow/rl_samples/rl_Test_Recon{}.png'.format(epoch))\n",
    "\n",
    "      utils.save_image((last_img), './glow/rl_samples/rl_Test_Target.png')\n",
    "\n",
    "\n",
    "\n",
    "  if (epoch + 1) % args.save_every == 0: \n",
    "    save_session(model, opt, args, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(postprocess(last_img[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_image((1. - last_img), './glow/rl_samples/rl_Test_Target.png', padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
